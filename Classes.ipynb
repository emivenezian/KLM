{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Packages\n",
    "\"\"\"\n",
    "import collections\n",
    "import itertools\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import matplotlib\n",
    "import shutil\n",
    "import glob\n",
    "import traceback\n",
    "import statsmodels\n",
    "\n",
    "from gurobipy import *\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from matplotlib.patches import Patch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from scipy.stats import trim_mean\n",
    "from collections import Counter\n",
    "import functools as ft\n",
    "import seaborn as sns\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cargo_Item():\n",
    "    def __init__(self, index, serialnumber, number_of_pieces, weight, CRT, COL, dangerous, commodity):\n",
    "        self.index = index \n",
    "        self.serialnumber = serialnumber\n",
    "        self.prefix_serialnumber = str(serialnumber).split('-')[0] if '-' in str(serialnumber) else str(serialnumber)\n",
    "        self.number_of_pieces = number_of_pieces\n",
    "        self.weight = weight\n",
    "        self.volume = None\n",
    "        self.CRT = CRT\n",
    "        self.COL = COL\n",
    "        self.dangerous = dangerous\n",
    "        self.height = None\n",
    "        self.length = None\n",
    "        self.rotate = None\n",
    "        self.stack = None\n",
    "        self.width = None\n",
    "        self.position = None\n",
    "        self.density = None\n",
    "        self.commodity = commodity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ULD():\n",
    "    def __init__(self, index, type, serialnumber):\n",
    "        self.index = index\n",
    "        self.type = type\n",
    "        self.serialnumber = serialnumber\n",
    "        self.height = None\n",
    "        self.length = None\n",
    "        self.width = None\n",
    "        self.cost = None\n",
    "        self.cut_a = None\n",
    "        self.cut_b = None\n",
    "        self.a = None\n",
    "        self.weight = None\n",
    "        self.max_weight = None\n",
    "        self.weight = 0\n",
    "        self.isNeitherBAXnorBUPnorT = 'BAX' not in serialnumber and 'BUP' not in serialnumber and 'T' not in serialnumber\n",
    "        self.isBAXorBUPorT = 'BAX' in serialnumber or 'BUP' in serialnumber or 'T' in serialnumber\n",
    "        self.isBAX = 'BAX' in serialnumber\n",
    "        self.CRT = 0\n",
    "        self.COL = 0\n",
    "        self.actual_position_bax = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadLocations():\n",
    "    def __init__(self, index, location):\n",
    "        self.index = index\n",
    "        self.location = location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cargo():\n",
    "    def __init__(self):\n",
    "        self.piece_filename = None\n",
    "        self.cargo = []\n",
    "        self.items = None\n",
    "        self.uld = []\n",
    "        self.uld_cut = []\n",
    "        self.uld_nocut = []\n",
    "        self.uld_bpp = []\n",
    "        self.BUP_data = None\n",
    "        self.total_number_of_build_ULDs = None\n",
    "\n",
    "    def read_cargo_pieces(self, filename_cargo_pieces, filename_buildup_information, arrival_airport):\n",
    "        \"\"\"\n",
    "        Reads and processes the cargo pieces from a csv file, removing the duplicates and creating a list of Cargo_Item objects.\n",
    "        Making invidual items for serialnumber with multiple pieces\n",
    "        Assigning the dimensions and characteristics of the cargo items to the Cargo_Item objects.\n",
    "\n",
    "        Args:\n",
    "            filename (str): The path to the CSV file containing cargo data.\n",
    "        \"\"\"\n",
    "        data_analysis = Data_Analysis()\n",
    "        #Reading the file and removing duplicates\n",
    "        self.piece_filename = filename_cargo_pieces\n",
    "        data = pd.read_csv(filename_cargo_pieces)\n",
    "        data_deindividualize = data.copy()\n",
    "        data.drop_duplicates(inplace = True)\n",
    "        self.BUP_data = data[data['IsBUP'] == 1]\n",
    "        data = data[data['IsBUP'] != 1]\n",
    "\n",
    "        '''Removing items if airwaybill both not in buildup and pieceinfo [TEST --> WOUTER]'''\n",
    "        data_buildup_information = pd.read_csv(filename_buildup_information) \n",
    "        build_up_serialnumbers = {re.sub(r'^74[0]*|-.*$', '', str(row['AirWaybillNumber']))\n",
    "                          for _, row in data_buildup_information.iterrows()}\n",
    "        str_airwaybillserialnumber = data['BookingAirWaybillSerialNumber'].astype(str)\n",
    "        data = data[str_airwaybillserialnumber.isin(build_up_serialnumbers)]\n",
    "\n",
    "        #Removing the items that are part of a T-ULD\n",
    "        df_T_uld = data_buildup_information.groupby('ULD').filter(lambda x: not x['IsBuildUpInVG3'].any())\n",
    "        short_serials = [re.sub(r'^74[0]*|-.*$', '', str(row['AirWaybillNumber'])) for _, row in df_T_uld.iterrows()]\n",
    "        str_airwaybillserialnumber = data['BookingAirWaybillSerialNumber'].astype(str)\n",
    "        data = data[~str_airwaybillserialnumber.isin(short_serials)]\n",
    "\n",
    "\n",
    "        #Grouping the data by the serial number and aggregating the characteristics of the cargo items\n",
    "        grouped_data = data.groupby('BookingAirWaybillSerialNumber').agg({\n",
    "            'BookingSegmentPieceCount': 'first',\n",
    "            'BookingSegmentWeight': 'first',\n",
    "            'IsCRT': 'max',\n",
    "            'IsCOL': 'max',\n",
    "            'IsDangerousGoods': 'max', \n",
    "            'BookingCommodityCode': 'first'\n",
    "        }).reset_index()\n",
    "\n",
    "        #Creating a list of Cargo_Item objects\n",
    "        for key, row in grouped_data.iterrows():\n",
    "                self.cargo.append(Cargo_Item(key, int(row.BookingAirWaybillSerialNumber), int(row.BookingSegmentPieceCount), float(row.BookingSegmentWeight), \n",
    "                                        row.IsCRT, row.IsCOL, row.IsDangerousGoods, row.BookingCommodityCode))\n",
    "\n",
    "        #Creating individual items for serialnumber with multiple pieces and assigning them with a new serialnumber\n",
    "        individual_items = []\n",
    "        key = 0\n",
    "        for i in self.cargo: \n",
    "            if i.number_of_pieces > 1:\n",
    "                individual_weight = float(i.weight / i.number_of_pieces)\n",
    "                for n in range(i.number_of_pieces):\n",
    "                    new_serial = f\"{i.serialnumber}-{n+1}\"\n",
    "                    individual_item = Cargo_Item(i.index, new_serial, 1, individual_weight, i.CRT, i.COL, i.dangerous, i.commodity)\n",
    "                    individual_items.append(individual_item)\n",
    "            else:\n",
    "                individual_items.append(i)\n",
    "\n",
    "        individual = []\n",
    "        for key, i in enumerate(individual_items):\n",
    "            indivi = Cargo_Item(key, i.serialnumber, i.number_of_pieces, i.weight, i.CRT, i.COL, i.dangerous, i.commodity)\n",
    "            individual.append(indivi)\n",
    "        self.items = individual\n",
    "\n",
    "        data['BookingLinePieceHeight'] = pd.to_numeric(data['BookingLinePieceHeight'], errors='coerce')\n",
    "        data['BookingLinePieceWidth'] = pd.to_numeric(data['BookingLinePieceWidth'], errors='coerce')\n",
    "        data['BookingLinePieceLength'] = pd.to_numeric(data['BookingLinePieceLength'], errors='coerce')\n",
    "\n",
    "        #Assigning the dimensions and characteristics of the cargo items to the Cargo_Item objects\n",
    "        for i in self.items:\n",
    "            serial_str = str(i.serialnumber)\n",
    "            if '-' in serial_str:\n",
    "                index_piece = int(serial_str.split('-')[1]) - 1\n",
    "            else:\n",
    "                index_piece = 0\n",
    "            short_serial = re.sub(r'^74[0]*|-.*$', '', serial_str)\n",
    "\n",
    "            relevant_rows = data[data['BookingAirWaybillSerialNumber'] == int(short_serial)]\n",
    "\n",
    "            filtered_rows = relevant_rows[relevant_rows['BookingLinePieceIsInformational'] == True]\n",
    "\n",
    "            if not filtered_rows.empty:\n",
    "                heights = []\n",
    "                widths = []\n",
    "                lengths = []\n",
    "                rotatables = []\n",
    "                stackables = []\n",
    "\n",
    "                for _, row in filtered_rows.iterrows():\n",
    "                    n = int(row['BookingSegmentPiecesCount'])\n",
    "                    heights += n * [row['BookingLinePieceHeight']]\n",
    "                    widths += n * [row['BookingLinePieceWidth']]\n",
    "                    lengths += n * [row['BookingLinePieceLength']]\n",
    "                    rotatables += n * [row['BookingSegmentPiecesTurnable']]\n",
    "                    stackables += n * [row['BookingSegmentPiecesStackable']]\n",
    "\n",
    "                if index_piece < len(heights):\n",
    "                    i.height = int(heights[index_piece])\n",
    "                    i.width = int(widths[index_piece])\n",
    "                    i.length = int(lengths[index_piece])\n",
    "                    i.volume = i.height * i.length * i.width\n",
    "                    i.density = i.weight / i.volume\n",
    "                    if rotatables[index_piece] == True:\n",
    "                        i.rotate = 1\n",
    "                    else:\n",
    "                        i.rotate = 0\n",
    "                    if stackables[index_piece] == True:\n",
    "                        i.stack = 0\n",
    "                    else:\n",
    "                        i.stack = 1\n",
    "\n",
    "            else:\n",
    "                if not relevant_rows.empty:\n",
    "                    row = relevant_rows.iloc[0]\n",
    "                    i.volume = int((row['BookingSegmentVolume'] * 1000000) / row['BookingSegmentPieceCount'])\n",
    "                    i.height = int((i.volume ** (1/3)) * data_analysis.dimensions_proportions_per_commodity(arrival_airport, i.commodity, 'HeightProportion'))\n",
    "                    i.width = int((i.volume ** (1/3)) * data_analysis.dimensions_proportions_per_commodity(arrival_airport, i.commodity, 'WidthProportion'))\n",
    "                    i.length = int((i.volume ** (1/3)) * data_analysis.dimensions_proportions_per_commodity(arrival_airport, i.commodity, 'LengthProportion'))\n",
    "                    i.density = i.weight / i.volume\n",
    "                    i.rotate = 1\n",
    "                    i.stack = 0\n",
    "\n",
    "        corrected_data = []\n",
    "        for i in self.items:\n",
    "            if i.height is not None:\n",
    "                corrected_data.append(i)\n",
    "        self.items = corrected_data\n",
    "\n",
    "        return\n",
    "    \n",
    "\n",
    "\n",
    "    def define_parameters_ULD(self):\n",
    "        \"\"\"\n",
    "        Define the parameters of the ULD types\n",
    "        \"\"\"\n",
    "        for i in self.uld:\n",
    "            if i.type == 'PMC':\n",
    "                i.max_weight = int(5102)\n",
    "                i.volume = int(12.5 * 1000000)\n",
    "                i.height = int(1.62 * 100)\n",
    "                i.length = int(3.18 * 100)\n",
    "                i.width = int(2.44 * 100)\n",
    "                i.a = 0\n",
    "                i.b = 0\n",
    "                i.cut_a = 0\n",
    "\n",
    "            if i.type == 'AKE':\n",
    "                i.max_weight = int(1587)\n",
    "                i.volume = int(2.8 * 1000000)\n",
    "                i.height = int(1.62 * 100)\n",
    "                i.length = int(1.56 * 100)\n",
    "                i.width = int(1.53 * 100)\n",
    "                i.a = 42\n",
    "                i.b = 53\n",
    "                i.cut_a = i.b / i.a\n",
    "\n",
    "            if i.type == 'PAG':\n",
    "                i.max_weight = int(4676)\n",
    "                i.volume = int(11.4 * 1000000)\n",
    "                i.height = int(1.62 * 100)\n",
    "                i.length = int(3.18 * 100)\n",
    "                i.width = int(2.24 * 100)\n",
    "                i.a = 0\n",
    "                i.b = 0\n",
    "                i.cut_a = 0\n",
    "\n",
    "\n",
    "    def define_uld_cut_sets(self):\n",
    "        \"\"\"\n",
    "        Define the set of ULDs that have a cut and the set of ULDs that do not have a cut\n",
    "        \"\"\"\n",
    "        for i in self.uld:\n",
    "            if i.type == 'PMC' or i.type == 'PAG':\n",
    "                self.uld_nocut.append(i)\n",
    "            if i.type == 'AKE':\n",
    "                self.uld_cut.append(i)\n",
    "\n",
    "\n",
    "    def define_ulds_used_flight(self, filename_load_locations, filename_buildup_information):\n",
    "        \"\"\"\n",
    "        Define the ULDs used in the flight\n",
    "\n",
    "        Args:\n",
    "            filename (str): The path to the Excel file containing the ULD data.\n",
    "        \"\"\"\n",
    "        number_of_AKE = 0\n",
    "        number_of_PMC = 0\n",
    "        number_of_PAG = 0\n",
    "        filtered_set_of_ulds = []\n",
    "        weight_bax = []\n",
    "        positions_bax = []\n",
    "        serialnumber_list = []\n",
    "\n",
    "        #Reading the file and creating a list of ULD objects\n",
    "        data_loadlocations = pd.read_csv(filename_load_locations)\n",
    "        special_handling_filter = data_loadlocations['SpecialHandlingCode'].isin(['COL', 'CRT'])\n",
    "        serialnumber_with_special_handling = data_loadlocations[special_handling_filter][['SerialNumber', 'SpecialHandlingCode']]\n",
    "        special_handling_dict = serialnumber_with_special_handling.set_index('SerialNumber')['SpecialHandlingCode'].to_dict()\n",
    "\n",
    "        data_buildup_information = pd.read_csv(filename_buildup_information)\n",
    "        unique_buildup_information = data_buildup_information.drop_duplicates(subset=['ULD', 'AirWaybillNumber'])\n",
    "        df_T_uld = unique_buildup_information.groupby('ULD').filter(lambda x: not x['IsBuildUpInVG3'].any())\n",
    "        str_airwaybillserialnumber = df_T_uld['AirWaybillNumber'].astype(str)\n",
    "        df_T_uld = df_T_uld[~ str_airwaybillserialnumber.isin(self.BUP_data['BookingAirWaybillNumber'].astype(str))]\n",
    "        df_T_uld_information = pd.DataFrame()\n",
    "        df_T_uld_information['SerialNumber'] = df_T_uld['ULD'].astype(str)\n",
    "        df_T_uld_information = pd.merge(df_T_uld_information, data_loadlocations[['SerialNumber', 'Weight']], on='SerialNumber', how='left')\n",
    "        df_T_uld_information = df_T_uld_information.dropna(subset=['Weight'])\n",
    "\n",
    "        data_loadlocations = data_loadlocations[~data_loadlocations['SerialNumber'].isin(df_T_uld_information['SerialNumber'])]\n",
    "        self.data_loadlocations = data_loadlocations\n",
    "\n",
    "        for row_number, row in enumerate(data_loadlocations.itertuples(index=False), start=0):\n",
    "            serialnumber = row.SerialNumber\n",
    "            if pd.notnull(serialnumber):\n",
    "                if row.DeadloadType == 'C' and 'AKE' in serialnumber and serialnumber not in serialnumber_list:\n",
    "                    number_of_AKE += 1\n",
    "                    uld_type = 'AKE'\n",
    "                    serial = f'{uld_type}-{row_number}'\n",
    "                    filtered_set_of_ulds.append(ULD(row_number, uld_type, serial))\n",
    "                    serialnumber_list.append(serialnumber)\n",
    "\n",
    "                elif row.DeadloadType == 'C' and 'AKY' in serialnumber and serialnumber not in serialnumber_list:\n",
    "                    number_of_AKE += 1\n",
    "                    uld_type = 'AKE'\n",
    "                    serial = f'{uld_type}-{row_number}'\n",
    "                    filtered_set_of_ulds.append(ULD(row_number, uld_type, serial))\n",
    "                    serialnumber_list.append(serialnumber)\n",
    "\n",
    "                elif row.DeadloadType == 'C' and 'RKN' in serialnumber and serialnumber not in serialnumber_list:\n",
    "                    number_of_AKE += 1\n",
    "                    uld_type = 'AKE'\n",
    "                    serial = f'{uld_type}-{row_number}'\n",
    "                    filtered_set_of_ulds.append(ULD(row_number, uld_type, serial))\n",
    "                    serialnumber_list.append(serialnumber)\n",
    "                \n",
    "                elif row.DeadloadType == 'C' and 'AKN' in serialnumber and serialnumber not in serialnumber_list:\n",
    "                    number_of_AKE += 1\n",
    "                    uld_type = 'AKE'\n",
    "                    serial = f'{uld_type}-{row_number}'\n",
    "                    filtered_set_of_ulds.append(ULD(row_number, uld_type, serial))\n",
    "                    serialnumber_list.append(serialnumber)\n",
    "\n",
    "                elif row.DeadloadType == 'C' and 'PMC' in serialnumber and serialnumber not in serialnumber_list:\n",
    "                    number_of_PMC += 1\n",
    "                    uld_type = 'PMC'\n",
    "                    serial = f'{uld_type}-{row_number}'\n",
    "                    filtered_set_of_ulds.append(ULD(row_number, uld_type, serial))\n",
    "                    serialnumber_list.append(serialnumber)\n",
    "\n",
    "                elif row.DeadloadType == 'C' and 'AAP' in serialnumber and serialnumber not in serialnumber_list:\n",
    "                    number_of_PMC += 1\n",
    "                    uld_type = 'PMC'\n",
    "                    serial = f'{uld_type}-{row_number}'\n",
    "                    filtered_set_of_ulds.append(ULD(row_number, uld_type, serial))\n",
    "                    serialnumber_list.append(serialnumber)\n",
    "\n",
    "                elif row.DeadloadType == 'C' and 'PAG' in serialnumber and serialnumber not in serialnumber_list:\n",
    "                    number_of_PAG += 1\n",
    "                    uld_type = 'PAG'\n",
    "                    serial = f'{uld_type}-{row_number}'\n",
    "                    filtered_set_of_ulds.append(ULD(row_number, uld_type, serial))\n",
    "                    serialnumber_list.append(serialnumber)\n",
    "\n",
    "                elif row.DeadloadType == 'C' and 'PLB' in serialnumber and serialnumber not in serialnumber_list:\n",
    "                    number_of_PAG += 1\n",
    "                    uld_type = 'PAG'\n",
    "                    serial = f'{uld_type}-{row_number}'\n",
    "                    filtered_set_of_ulds.append(ULD(row_number, uld_type, serial))\n",
    "                    serialnumber_list.append(serialnumber)\n",
    "\n",
    "                elif row.DeadloadType == 'C' and 'PLA' in serialnumber and serialnumber not in serialnumber_list:\n",
    "                    number_of_PAG += 1\n",
    "                    uld_type = 'PAG'\n",
    "                    serial = f'{uld_type}-{row_number}'\n",
    "                    filtered_set_of_ulds.append(ULD(row_number, uld_type, serial))\n",
    "                    serialnumber_list.append(serialnumber)\n",
    "\n",
    "                elif row.DeadloadType == 'B' and 'AKE' in serialnumber and serialnumber not in serialnumber_list:\n",
    "                    uld_type = 'AKE'\n",
    "                    name_bax = 'BAX'\n",
    "                    serial = f'{name_bax}-{row_number}'\n",
    "                    filtered_set_of_ulds.append(ULD(row_number, uld_type, serial))\n",
    "                    weight_bax.append(row.UldGrossWeight)\n",
    "                    positions_bax.append(row.LoadLocation)\n",
    "                    serialnumber_list.append(serialnumber)\n",
    "\n",
    "        self.uld = filtered_set_of_ulds\n",
    "\n",
    "        #Assigning the weight of the BAX ULDs\n",
    "        bax_index = 0\n",
    "        for j in self.uld:\n",
    "            if 'BAX' in j.serialnumber:\n",
    "                j.weight = weight_bax[bax_index]\n",
    "                j.actual_position_bax = positions_bax[bax_index]\n",
    "                bax_index += 1\n",
    "\n",
    "        #Assigning the weight and number of the BUP ULDs\n",
    "        if len(self.BUP_data) > 0:\n",
    "            for key, row_bup in self.BUP_data.iterrows():\n",
    "                row_number = max(uld.index for uld in self.uld) + 1\n",
    "                uld_type = 'PMC'\n",
    "                name_bax = 'BUP'\n",
    "                serial = f'{name_bax}-{row_number}'\n",
    "                self.uld.append(ULD(row_number, uld_type, serial))\n",
    "\n",
    "        for j in self.uld:\n",
    "            if 'BUP' in j.serialnumber:\n",
    "                j.weight = self.BUP_data['BookingTotalWeight'].max()\n",
    "\n",
    "        #Assigning T-ULDs\n",
    "        serialnumber_list = []\n",
    "        if len(df_T_uld_information) > 0:\n",
    "            for index, row in df_T_uld_information.iterrows():\n",
    "                uld = row['SerialNumber']\n",
    "                weight = row['Weight']\n",
    "                COL = False\n",
    "                CRT = False\n",
    "\n",
    "                if uld not in serialnumber_list and ((str(uld[0]) != 'B') and (str(uld[0]) != 'K')):\n",
    "                    row_number = max(uld.index for uld in self.uld) + 1\n",
    "                    uld_type = str(uld[0:3])\n",
    "\n",
    "                    if uld in special_handling_dict:\n",
    "                        if special_handling_dict[uld] == 'COL':\n",
    "                            COL = True\n",
    "                        if special_handling_dict[uld] == 'CRT':\n",
    "                            CRT = True\n",
    "\n",
    "                    if uld_type not in ['PMC', 'PAG', 'AKE']:\n",
    "                        if uld_type == 'PLB':\n",
    "                            uld_type = 'PAG'\n",
    "                        elif uld_type == 'PLA':\n",
    "                            uld_type = 'PAG'\n",
    "                        elif uld_type == 'AAP':\n",
    "                            uld_type = 'PMC'\n",
    "                        elif uld_type == 'RKN':\n",
    "                            uld_type = 'AKE'\n",
    "                        elif uld_type == 'AKY':\n",
    "                            uld_type = 'AKE'\n",
    "                        elif uld_type == 'AKN':\n",
    "                            uld_type = 'AKE'\n",
    "                        else:\n",
    "                            uld_type = 'AKE'\n",
    "                        \n",
    "                    name_T = 'T'\n",
    "                    serial = f'{name_T}-{row_number}'\n",
    "                    T_uld = ULD(row_number, uld_type, serial)\n",
    "                    if COL:\n",
    "                        T_uld.COL = 1\n",
    "                    if CRT:\n",
    "                        T_uld.CRT = 1\n",
    "                    T_uld.weight = weight\n",
    "                    self.uld.append(T_uld)\n",
    "                    serialnumber_list.append(uld)\n",
    "\n",
    "    def filter_items_test(self, amount):\n",
    "        \"\"\"\n",
    "        Filter the items to a specific number of items\n",
    "\n",
    "        Args:\n",
    "            amount (int): The number of items to filter\n",
    "        \"\"\"\n",
    "        filter_items = random.sample(self.items, amount)\n",
    "        self.items = filter_items\n",
    "\n",
    "        # filter_items = self.items[:amount]\n",
    "        # self.items = filter_items\n",
    "\n",
    "\n",
    "    def get_prefix_groups(self):\n",
    "        \"\"\"\n",
    "        Get the serialnumber prefix groups of the items\n",
    "        \"\"\"\n",
    "        prefix_groups = {}\n",
    "        for i in self.items:\n",
    "            if i.prefix_serialnumber not in prefix_groups:\n",
    "                prefix_groups[i.prefix_serialnumber] = []\n",
    "            prefix_groups[i.prefix_serialnumber].append(i)\n",
    "\n",
    "        return prefix_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CargoActual():\n",
    "    def __init__(self):\n",
    "        self.piece_filename = None\n",
    "        self.cargo = []\n",
    "        self.items = None\n",
    "        self.uld = []\n",
    "        self.uld_cut = []\n",
    "        self.uld_nocut = []\n",
    "        self.uld_bpp = []\n",
    "        self.BUP_data = None\n",
    "        self.total_number_of_build_ULDs = None\n",
    "\n",
    "    def read_cargo_pieces(self, filename_cargo_pieces, filename_buildup_information, arrival_airport):\n",
    "        \"\"\"\n",
    "        Reads and processes the cargo pieces from a csv file, removing the duplicates and creating a list of Cargo_Item objects.\n",
    "        Making invidual items for serialnumber with multiple pieces\n",
    "        Assigning the dimensions and characteristics of the cargo items to the Cargo_Item objects.\n",
    "\n",
    "        Args:\n",
    "            filename (str): The path to the CSV file containing cargo data.\n",
    "        \"\"\"\n",
    "        data_analysis = Data_Analysis()\n",
    "        #Reading the file and removing duplicates\n",
    "        self.piece_filename = filename_cargo_pieces\n",
    "        data = pd.read_csv(filename_cargo_pieces)\n",
    "        data_deindividualize = data.copy()\n",
    "        data.drop_duplicates(inplace = True)\n",
    "        self.BUP_data = data[data['IsBUP'] == 1]\n",
    "        data = data[data['IsBUP'] != 1]\n",
    "\n",
    "        '''Removing items if airwaybill both not in buildup and pieceinfo [TEST --> WOUTER]'''\n",
    "        data_buildup_information = pd.read_csv(filename_buildup_information) \n",
    "        build_up_serialnumbers = {re.sub(r'^74[0]*|-.*$', '', str(row['AirWaybillNumber']))\n",
    "                          for _, row in data_buildup_information.iterrows()}\n",
    "        str_airwaybillserialnumber = data['BookingAirWaybillSerialNumber'].astype(str)\n",
    "        data = data[str_airwaybillserialnumber.isin(build_up_serialnumbers)]\n",
    "\n",
    "        #Removing the items that are part of a T-ULD\n",
    "        df_T_uld = data_buildup_information.groupby('ULD').filter(lambda x: not x['IsBuildUpInVG3'].any())\n",
    "        short_serials = [re.sub(r'^74[0]*|-.*$', '', str(row['AirWaybillNumber'])) for _, row in df_T_uld.iterrows()]\n",
    "        str_airwaybillserialnumber = data['BookingAirWaybillSerialNumber'].astype(str)\n",
    "        data = data[~str_airwaybillserialnumber.isin(short_serials)]\n",
    "\n",
    "\n",
    "        #Grouping the data by the serial number and aggregating the characteristics of the cargo items\n",
    "        grouped_data = data.groupby('BookingAirWaybillSerialNumber').agg({\n",
    "            'BookingSegmentPieceCount': 'first',\n",
    "            'BookingSegmentWeight': 'first',\n",
    "            'IsCRT': 'max',\n",
    "            'IsCOL': 'max',\n",
    "            'IsDangerousGoods': 'max', \n",
    "            'BookingCommodityCode': 'first'\n",
    "        }).reset_index()\n",
    "\n",
    "        #Creating a list of Cargo_Item objects\n",
    "        for key, row in grouped_data.iterrows():\n",
    "                self.cargo.append(Cargo_Item(key, int(row.BookingAirWaybillSerialNumber), int(row.BookingSegmentPieceCount), float(row.BookingSegmentWeight), \n",
    "                                        row.IsCRT, row.IsCOL, row.IsDangerousGoods, row.BookingCommodityCode))\n",
    "\n",
    "        #Creating individual items for serialnumber with multiple pieces and assigning them with a new serialnumber\n",
    "        individual_items = []\n",
    "        key = 0\n",
    "        for i in self.cargo: \n",
    "            if i.number_of_pieces > 1:\n",
    "                individual_weight = float(i.weight / i.number_of_pieces)\n",
    "                for n in range(i.number_of_pieces):\n",
    "                    new_serial = f\"{i.serialnumber}-{n+1}\"\n",
    "                    individual_item = Cargo_Item(i.index, new_serial, 1, individual_weight, i.CRT, i.COL, i.dangerous, i.commodity)\n",
    "                    individual_items.append(individual_item)\n",
    "            else:\n",
    "                individual_items.append(i)\n",
    "\n",
    "        individual = []\n",
    "        for key, i in enumerate(individual_items):\n",
    "            indivi = Cargo_Item(key, i.serialnumber, i.number_of_pieces, i.weight, i.CRT, i.COL, i.dangerous, i.commodity)\n",
    "            individual.append(indivi)\n",
    "        self.items = individual\n",
    "\n",
    "        data['BookingLinePieceHeight'] = pd.to_numeric(data['BookingLinePieceHeight'], errors='coerce')\n",
    "        data['BookingLinePieceWidth'] = pd.to_numeric(data['BookingLinePieceWidth'], errors='coerce')\n",
    "        data['BookingLinePieceLength'] = pd.to_numeric(data['BookingLinePieceLength'], errors='coerce')\n",
    "\n",
    "        #Assigning the dimensions and characteristics of the cargo items to the Cargo_Item objects\n",
    "        for i in self.items:\n",
    "            serial_str = str(i.serialnumber)\n",
    "            if '-' in serial_str:\n",
    "                index_piece = int(serial_str.split('-')[1]) - 1\n",
    "            else:\n",
    "                index_piece = 0\n",
    "            short_serial = re.sub(r'^74[0]*|-.*$', '', serial_str)\n",
    "\n",
    "            relevant_rows = data[data['BookingAirWaybillSerialNumber'] == int(short_serial)]\n",
    "\n",
    "            filtered_rows = relevant_rows[relevant_rows['BookingLinePieceIsInformational'] == True]\n",
    "\n",
    "            if not filtered_rows.empty:\n",
    "                heights = []\n",
    "                widths = []\n",
    "                lengths = []\n",
    "                rotatables = []\n",
    "                stackables = []\n",
    "\n",
    "                for _, row in filtered_rows.iterrows():\n",
    "                    n = int(row['BookingSegmentPiecesCount'])\n",
    "                    heights += n * [row['BookingLinePieceHeight']]\n",
    "                    widths += n * [row['BookingLinePieceWidth']]\n",
    "                    lengths += n * [row['BookingLinePieceLength']]\n",
    "                    rotatables += n * [row['BookingSegmentPiecesTurnable']]\n",
    "                    stackables += n * [row['BookingSegmentPiecesStackable']]\n",
    "\n",
    "                if index_piece < len(heights):\n",
    "                    i.height = int(heights[index_piece])\n",
    "                    i.width = int(widths[index_piece])\n",
    "                    i.length = int(lengths[index_piece])\n",
    "                    i.volume = i.height * i.length * i.width\n",
    "                    i.density = i.weight / i.volume\n",
    "                    if rotatables[index_piece] == True:\n",
    "                        i.rotate = 1\n",
    "                    else:\n",
    "                        i.rotate = 0\n",
    "                    if stackables[index_piece] == True:\n",
    "                        i.stack = 0\n",
    "                    else:\n",
    "                        i.stack = 1\n",
    "\n",
    "            else:\n",
    "                if not relevant_rows.empty:\n",
    "                    row = relevant_rows.iloc[0]\n",
    "                    i.volume = int((row['BookingSegmentVolume'] * 1000000) / row['BookingSegmentPieceCount'])\n",
    "                    i.height = int((i.volume ** (1/3)) * data_analysis.dimensions_proportions_per_commodity(arrival_airport, i.commodity, 'HeightProportion'))\n",
    "                    i.width = int((i.volume ** (1/3)) * data_analysis.dimensions_proportions_per_commodity(arrival_airport, i.commodity, 'WidthProportion'))\n",
    "                    i.length = int((i.volume ** (1/3)) * data_analysis.dimensions_proportions_per_commodity(arrival_airport, i.commodity, 'LengthProportion'))\n",
    "                    i.density = i.weight / i.volume\n",
    "                    i.rotate = 1\n",
    "                    i.stack = 0\n",
    "\n",
    "        corrected_data = []\n",
    "        for i in self.items:\n",
    "            if i.height is not None:\n",
    "                corrected_data.append(i)\n",
    "        self.items = corrected_data\n",
    "\n",
    "        return\n",
    "\n",
    "    \n",
    "    def define_parameters_ULD(self):\n",
    "        \"\"\"\n",
    "        Define the parameters of the ULD types\n",
    "        \"\"\"\n",
    "        for i in self.uld:\n",
    "            if i.type == 'PMC':\n",
    "                i.max_weight = int(5102)\n",
    "                i.volume = int(12.5 * 1000000)\n",
    "                i.height = int(1.62 * 100)\n",
    "                i.length = int(3.18 * 100)\n",
    "                i.width = int(2.44 * 100)\n",
    "                i.a = 0\n",
    "                i.b = 0\n",
    "                i.cut_a = 0\n",
    "\n",
    "            if i.type == 'AKE':\n",
    "                i.max_weight = int(1587)\n",
    "                i.volume = int(2.8 * 1000000)\n",
    "                i.height = int(1.62 * 100)\n",
    "                i.length = int(1.56 * 100)\n",
    "                i.width = int(1.53 * 100)\n",
    "                i.a = 42\n",
    "                i.b = 53\n",
    "                i.cut_a = i.b / i.a\n",
    "\n",
    "            if i.type == 'PAG':\n",
    "                i.max_weight = int(4676)\n",
    "                i.volume = int(11.4 * 1000000)\n",
    "                i.height = int(1.62 * 100)\n",
    "                i.length = int(3.18 * 100)\n",
    "                i.width = int(2.24 * 100)\n",
    "                i.a = 0\n",
    "                i.b = 0\n",
    "                i.cut_a = 0\n",
    "\n",
    "\n",
    "    def define_uld_cut_sets(self):\n",
    "        \"\"\"\n",
    "        Define the set of ULDs that have a cut and the set of ULDs that do not have a cut\n",
    "        \"\"\"\n",
    "        for i in self.uld:\n",
    "            if i.type == 'PMC' or i.type == 'PAG':\n",
    "                self.uld_nocut.append(i)\n",
    "            if i.type == 'AKE':\n",
    "                self.uld_cut.append(i)\n",
    "\n",
    "\n",
    "    def define_ulds_used_flight(self, filename_load_locations, filename_buildup_information):\n",
    "        \"\"\"\n",
    "        Define the ULDs used in the flight\n",
    "\n",
    "        Args:\n",
    "            filename (str): The path to the Excel file containing the ULD data.\n",
    "        \"\"\"\n",
    "        number_of_AKE = 0\n",
    "        number_of_PMC = 0\n",
    "        number_of_PAG = 0\n",
    "        filtered_set_of_ulds = []\n",
    "        weight_bax = []\n",
    "        serialnumber_list = []\n",
    "\n",
    "        #Reading the file and creating a list of ULD objects\n",
    "        data_loadlocations = pd.read_csv(filename_load_locations)\n",
    "        special_handling_filter = data_loadlocations['SpecialHandlingCode'].isin(['COL', 'CRT'])\n",
    "        serialnumber_with_special_handling = data_loadlocations[special_handling_filter][['SerialNumber', 'SpecialHandlingCode']]\n",
    "        special_handling_dict = serialnumber_with_special_handling.set_index('SerialNumber')['SpecialHandlingCode'].to_dict()\n",
    "\n",
    "\n",
    "        data_buildup_information = pd.read_csv(filename_buildup_information)\n",
    "        unique_buildup_information = data_buildup_information.drop_duplicates(subset=['ULD', 'AirWaybillNumber'])\n",
    "        df_T_uld = unique_buildup_information.groupby('ULD').filter(lambda x: not x['IsBuildUpInVG3'].any())\n",
    "        str_airwaybillserialnumber = df_T_uld['AirWaybillNumber'].astype(str)\n",
    "        df_T_uld = df_T_uld[~ str_airwaybillserialnumber.isin(self.BUP_data['BookingAirWaybillNumber'].astype(str))]\n",
    "        df_T_uld_information = pd.DataFrame()\n",
    "        df_T_uld_information['SerialNumber'] = df_T_uld['ULD'].astype(str)\n",
    "        df_T_uld_information = pd.merge(df_T_uld_information, data_loadlocations[['SerialNumber', 'Weight']], on='SerialNumber', how='left')\n",
    "        df_T_uld_information = df_T_uld_information.dropna(subset=['Weight'])\n",
    "\n",
    "        data_loadlocations = data_loadlocations[~data_loadlocations['SerialNumber'].isin(df_T_uld_information['SerialNumber'])]\n",
    "\n",
    "        for row_number, row in enumerate(data_loadlocations.itertuples(index=False), start=0):\n",
    "            serialnumber = row.SerialNumber\n",
    "\n",
    "            if pd.notnull(serialnumber):\n",
    "                if row.DeadloadType == 'C' and 'AKE' in serialnumber and serialnumber not in serialnumber_list:\n",
    "                    number_of_AKE += 1\n",
    "                    uld_type = 'AKE'\n",
    "                    serial = f'{uld_type}-{row_number}'\n",
    "                    uld = ULD(row_number, uld_type, serial)\n",
    "                    uld.weight = row.UldGrossWeight\n",
    "                    if (serialnumber in special_handling_dict.keys()) and (special_handling_dict[serialnumber] == 'COL'):\n",
    "                        uld.COL = 1\n",
    "                    if (serialnumber in special_handling_dict.keys()) and (special_handling_dict[serialnumber] == 'CRT'):\n",
    "                        uld.CRT = 1\n",
    "                    filtered_set_of_ulds.append(uld)\n",
    "                    serialnumber_list.append(serialnumber)\n",
    "\n",
    "                elif row.DeadloadType == 'C' and 'AKY' in serialnumber and serialnumber not in serialnumber_list:\n",
    "                    number_of_AKE += 1\n",
    "                    uld_type = 'AKE'\n",
    "                    serial = f'{uld_type}-{row_number}'\n",
    "                    uld = ULD(row_number, uld_type, serial)\n",
    "                    uld.weight = row.UldGrossWeight\n",
    "                    if (serialnumber in special_handling_dict.keys()) and (special_handling_dict[serialnumber] == 'COL'):\n",
    "                        uld.COL = 1\n",
    "                    if (serialnumber in special_handling_dict.keys()) and (special_handling_dict[serialnumber] == 'CRT'):\n",
    "                        uld.CRT = 1\n",
    "                    filtered_set_of_ulds.append(uld)\n",
    "                    serialnumber_list.append(serialnumber)\n",
    "\n",
    "                elif row.DeadloadType == 'C' and 'RKN' in serialnumber and serialnumber not in serialnumber_list:\n",
    "                    number_of_AKE += 1\n",
    "                    uld_type = 'AKE'\n",
    "                    serial = f'{uld_type}-{row_number}'\n",
    "                    uld = ULD(row_number, uld_type, serial)\n",
    "                    uld.weight = row.UldGrossWeight\n",
    "                    if (serialnumber in special_handling_dict.keys()) and (special_handling_dict[serialnumber] == 'COL'):\n",
    "                        uld.COL = 1\n",
    "                    if (serialnumber in special_handling_dict.keys()) and (special_handling_dict[serialnumber] == 'CRT'):\n",
    "                        uld.CRT = 1\n",
    "                    filtered_set_of_ulds.append(uld)\n",
    "                    serialnumber_list.append(serialnumber)\n",
    "                \n",
    "                elif row.DeadloadType == 'C' and 'AKN' in serialnumber and serialnumber not in serialnumber_list:\n",
    "                    number_of_AKE += 1\n",
    "                    uld_type = 'AKE'\n",
    "                    serial = f'{uld_type}-{row_number}'\n",
    "                    uld = ULD(row_number, uld_type, serial)\n",
    "                    uld.weight = row.UldGrossWeight\n",
    "                    if (serialnumber in special_handling_dict.keys()) and (special_handling_dict[serialnumber] == 'COL'):\n",
    "                        uld.COL = 1\n",
    "                    if (serialnumber in special_handling_dict.keys()) and (special_handling_dict[serialnumber] == 'CRT'):\n",
    "                        uld.CRT = 1\n",
    "                    filtered_set_of_ulds.append(uld)\n",
    "                    serialnumber_list.append(serialnumber)\n",
    "\n",
    "                elif row.DeadloadType == 'C' and 'PMC' in serialnumber and serialnumber not in serialnumber_list:\n",
    "                    number_of_PMC += 1\n",
    "                    uld_type = 'PMC'\n",
    "                    serial = f'{uld_type}-{row_number}'\n",
    "                    uld = ULD(row_number, uld_type, serial)\n",
    "                    uld.weight = row.UldGrossWeight\n",
    "                    if (serialnumber in special_handling_dict.keys()) and (special_handling_dict[serialnumber] == 'COL'):\n",
    "                        uld.COL = 1\n",
    "                    if (serialnumber in special_handling_dict.keys()) and (special_handling_dict[serialnumber] == 'CRT'):\n",
    "                        uld.CRT = 1\n",
    "                    filtered_set_of_ulds.append(uld)\n",
    "                    serialnumber_list.append(serialnumber)\n",
    "\n",
    "                elif row.DeadloadType == 'C' and 'AAP' in serialnumber and serialnumber not in serialnumber_list:\n",
    "                    number_of_PMC += 1\n",
    "                    uld_type = 'PMC'\n",
    "                    serial = f'{uld_type}-{row_number}'\n",
    "                    uld = ULD(row_number, uld_type, serial)\n",
    "                    uld.weight = row.UldGrossWeight\n",
    "                    if (serialnumber in special_handling_dict.keys()) and (special_handling_dict[serialnumber] == 'COL'):\n",
    "                        uld.COL = 1\n",
    "                    if (serialnumber in special_handling_dict.keys()) and (special_handling_dict[serialnumber] == 'CRT'):\n",
    "                        uld.CRT = 1\n",
    "                    filtered_set_of_ulds.append(uld)\n",
    "                    serialnumber_list.append(serialnumber)\n",
    "\n",
    "                elif row.DeadloadType == 'C' and 'PAG' in serialnumber and serialnumber not in serialnumber_list:\n",
    "                    number_of_PAG += 1\n",
    "                    uld_type = 'PAG'\n",
    "                    serial = f'{uld_type}-{row_number}'\n",
    "                    uld = ULD(row_number, uld_type, serial)\n",
    "                    uld.weight = row.UldGrossWeight\n",
    "                    if (serialnumber in special_handling_dict.keys()) and (special_handling_dict[serialnumber] == 'COL'):\n",
    "                        uld.COL = 1\n",
    "                    if (serialnumber in special_handling_dict.keys()) and (special_handling_dict[serialnumber] == 'CRT'):\n",
    "                        uld.CRT = 1\n",
    "                    filtered_set_of_ulds.append(uld)\n",
    "                    serialnumber_list.append(serialnumber)\n",
    "\n",
    "                elif row.DeadloadType == 'C' and 'PLB' in serialnumber and serialnumber not in serialnumber_list:\n",
    "                    number_of_PAG += 1\n",
    "                    uld_type = 'PAG'\n",
    "                    serial = f'{uld_type}-{row_number}'\n",
    "                    uld = ULD(row_number, uld_type, serial)\n",
    "                    uld.weight = row.UldGrossWeight\n",
    "                    if (serialnumber in special_handling_dict.keys()) and (special_handling_dict[serialnumber] == 'COL'):\n",
    "                        uld.COL = 1\n",
    "                    if (serialnumber in special_handling_dict.keys()) and (special_handling_dict[serialnumber] == 'CRT'):\n",
    "                        uld.CRT = 1\n",
    "                    filtered_set_of_ulds.append(uld)\n",
    "                    serialnumber_list.append(serialnumber)\n",
    "\n",
    "                elif row.DeadloadType == 'C' and 'PLA' in serialnumber and serialnumber not in serialnumber_list:\n",
    "                    number_of_PAG += 1\n",
    "                    uld_type = 'PAG'\n",
    "                    serial = f'{uld_type}-{row_number}'\n",
    "                    uld = ULD(row_number, uld_type, serial)\n",
    "                    uld.weight = row.UldGrossWeight\n",
    "                    if (serialnumber in special_handling_dict.keys()) and (special_handling_dict[serialnumber] == 'COL'):\n",
    "                        uld.COL = 1\n",
    "                    if (serialnumber in special_handling_dict.keys()) and (special_handling_dict[serialnumber] == 'CRT'):\n",
    "                        uld.CRT = 1\n",
    "                    filtered_set_of_ulds.append(uld)\n",
    "                    serialnumber_list.append(serialnumber)\n",
    "\n",
    "                elif row.DeadloadType == 'B' and 'AKE' in serialnumber and serialnumber not in serialnumber_list:\n",
    "                    uld_type = 'AKE'\n",
    "                    name_bax = 'BAX'\n",
    "                    serial = f'{name_bax}-{row_number}'\n",
    "                    filtered_set_of_ulds.append(ULD(row_number, uld_type, serial))\n",
    "                    weight_bax.append(row.UldGrossWeight)\n",
    "                    serialnumber_list.append(serialnumber)\n",
    "\n",
    "        self.uld = filtered_set_of_ulds\n",
    "\n",
    "        #Assigning the weight of the BAX ULDs\n",
    "        bax_index = 0\n",
    "        for j in self.uld:\n",
    "            if 'BAX' in j.serialnumber:\n",
    "                j.weight = weight_bax[bax_index]\n",
    "                bax_index += 1\n",
    "\n",
    "        #Assigning the weight and number of the BUP ULDs\n",
    "        if len(self.BUP_data) > 0:\n",
    "            for key, row_bup in self.BUP_data.iterrows():\n",
    "                row_number = max(uld.index for uld in self.uld) + 1\n",
    "                uld_type = 'PMC'\n",
    "                name_bax = 'BUP'\n",
    "                serial = f'{name_bax}-{row_number}'\n",
    "                self.uld.append(ULD(row_number, uld_type, serial))\n",
    "\n",
    "        for j in self.uld:\n",
    "            if 'BUP' in j.serialnumber:\n",
    "                j.weight = self.BUP_data['BookingTotalWeight'].max()\n",
    "\n",
    "        #Assigning T-ULDs\n",
    "        serialnumber_list = []\n",
    "        if len(df_T_uld_information) > 0:\n",
    "            for index, row in df_T_uld_information.iterrows():\n",
    "                uld = row['SerialNumber']\n",
    "                weight = row['Weight']\n",
    "                COL = False\n",
    "                CRT = False\n",
    "                \n",
    "                if uld not in serialnumber_list and ((str(uld[0]) != 'B') and (str(uld[0]) != 'K')):\n",
    "                    row_number = max(uld.index for uld in self.uld) + 1\n",
    "                    uld_type = str(uld[0:3])\n",
    "\n",
    "                    if uld in special_handling_dict:\n",
    "                        if special_handling_dict[uld] == 'COL':\n",
    "                            COL = True\n",
    "                        if special_handling_dict[uld] == 'CRT':\n",
    "                            CRT = True\n",
    "                    if uld_type not in ['PMC', 'PAG', 'AKE']:\n",
    "                        if uld_type == 'PLB':\n",
    "                            uld_type = 'PAG'\n",
    "                        elif uld_type == 'PLA':\n",
    "                            uld_type = 'PAG'\n",
    "                        elif uld_type == 'AAP':\n",
    "                            uld_type = 'PMC'\n",
    "                        elif uld_type == 'RKN':\n",
    "                            uld_type = 'AKE'\n",
    "                        elif uld_type == 'AKY':\n",
    "                            uld_type = 'AKE'\n",
    "                        elif uld_type == 'AKN':\n",
    "                            uld_type = 'AKE'\n",
    "                        else:\n",
    "                            uld_type = 'AKE'\n",
    "                        \n",
    "                    name_T = 'T'\n",
    "                    serial = f'{name_T}-{row_number}'\n",
    "                    T_uld = ULD(row_number, uld_type, serial)\n",
    "                    T_uld.weight = weight\n",
    "                    if COL:\n",
    "                        T_uld.COL = 1\n",
    "                    if CRT:\n",
    "                        T_uld.CRT = 1\n",
    "                    self.uld.append(T_uld)\n",
    "                    serialnumber_list.append(uld)\n",
    "\n",
    "    def filter_items_test(self, amount):\n",
    "        \"\"\"\n",
    "        Filter the items to a specific number of items\n",
    "\n",
    "        Args:\n",
    "            amount (int): The number of items to filter\n",
    "        \"\"\"\n",
    "        filter_items = random.sample(self.items, amount)\n",
    "        self.items = filter_items\n",
    "\n",
    "        # filter_items = self.items[:amount]\n",
    "        # self.items = filter_items\n",
    "\n",
    "\n",
    "    def get_prefix_groups(self):\n",
    "        \"\"\"\n",
    "        Get the serialnumber prefix groups of the items\n",
    "        \"\"\"\n",
    "        prefix_groups = {}\n",
    "        for i in self.items:\n",
    "            if i.prefix_serialnumber not in prefix_groups:\n",
    "                prefix_groups[i.prefix_serialnumber] = []\n",
    "            prefix_groups[i.prefix_serialnumber].append(i)\n",
    "\n",
    "        return prefix_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aircraft():\n",
    "    def __init__(self):\n",
    "        self.aircraft_filename = None\n",
    "        self.data_fuel_filename = None\n",
    "        self.main_filename = None\n",
    "\n",
    "        self.loadlocations = []\n",
    "        self.loadlocations_left = []\n",
    "        self.loadlocations_right = []\n",
    "        self.loadlocations_pallet = []\n",
    "        self.loadlocations_pairs = []\n",
    "        self.loadlocations_C1 = []\n",
    "        self.loadlocations_C2 = []\n",
    "        self.loadlocations_C3 = []\n",
    "        self.loadlocations_C4 = []\n",
    "        self.loadlocations_C1_C2 = []\n",
    "        self.loadlocations_C3_C4 = []\n",
    "\n",
    "        self.aircraft_type = None\n",
    "        self.aircraft_registration = None\n",
    "        self.flight_number = None\n",
    "        self.departure_airport = None\n",
    "        self.arrival_airport = None\n",
    "        self.date = None\n",
    "        self.MTOW = None\n",
    "        self.MLW = None\n",
    "        self.MZFW = None\n",
    "        self.AZFW = None\n",
    "        self.OEW = None\n",
    "        self.TOF = None\n",
    "        self.TripF = None\n",
    "        self.cost_index = None\n",
    "        self.DOI = None\n",
    "        self.fuel_index = None\n",
    "        self.ZFW = None\n",
    "        self.TOW = None\n",
    "        self.LW = None\n",
    "\n",
    "        self.max_weight_C1 = None\n",
    "        self.max_weight_C2 = None\n",
    "        self.max_weight_C3 = None\n",
    "        self.max_weight_C4 = None\n",
    "        self.max_weight_C1_C2 = None\n",
    "        self.max_weight_C3_C4 = None\n",
    "\n",
    "        self.actual_MAC_ZFW = None\n",
    "        self.C = None\n",
    "        self.K = None\n",
    "        self.reference_arm = None\n",
    "        self.lemac = None\n",
    "        self.mac_formula = None\n",
    "        self.delta_index_cargo_C1 = None\n",
    "        self.delta_index_cargo_C2 = None\n",
    "        self.delta_index_cargo_C3 = None\n",
    "        self.delta_index_cargo_C4 = None\n",
    "        self.delta_index_cargo_C5 = None\n",
    "        self.delta_index_pax_0A = None\n",
    "        self.delta_index_pax_0B = None\n",
    "        self.delta_index_pax_0C = None\n",
    "        self.delta_index_pax_0D = None\n",
    "        self.delta_index_pax_0E = None\n",
    "\n",
    "        self.pax_0A = None\n",
    "        self.pax_0B = None\n",
    "        self.pax_0C = None\n",
    "        self.pax_0D = None\n",
    "        self.pax_0E = None\n",
    "        self.pax_0F = None\n",
    "        self.pax_0G = None\n",
    "        self.total_PAX = None\n",
    "\n",
    "\n",
    "    def define_aircraft(self, filename, AC_type, restricted_locations):\n",
    "        \"\"\" \n",
    "        Define the aircraft type and the load locations of the aircraft\n",
    "\n",
    "        Args:\n",
    "            filename (str): The path to the CSV file containing the aircraft data.\n",
    "            AC_type (str): The aircraft type.\n",
    "        \"\"\"\n",
    "        #Reding the file and creating a list of LoadLocations objects\n",
    "        self.aircraft_filename = filename\n",
    "        data = pd.read_csv(filename)\n",
    "        data = data[data['ACType'] == str(AC_type)]\n",
    "        locations = data.LoadLocation\n",
    "        locations = locations[~locations.isin(restricted_locations)]\n",
    "        \n",
    "        for key, i in enumerate(locations):\n",
    "            self.loadlocations.append(LoadLocations(key, i.strip()))\n",
    "        \n",
    "        #Creating lists of load locations for the left, right and pallet positions\n",
    "        for i in self.loadlocations:\n",
    "            if 'L' in i.location:\n",
    "                self.loadlocations_left.append(i)\n",
    "            elif 'R' in i.location:\n",
    "                self.loadlocations_right.append(i)\n",
    "            elif 'P' in i.location:\n",
    "                self.loadlocations_pallet.append(i)\n",
    "        \n",
    "        #Creating lists of load locations for the cargo compartments\n",
    "        for i in self.loadlocations:\n",
    "            if '11' in i.location or '12' in i.location or '13' in i.location or '14' in i.location or '15' in i.location:\n",
    "                self.loadlocations_C1.append(i)\n",
    "                self.loadlocations_C1_C2.append(i)\n",
    "            if '21' in i.location or '22' in i.location or '23' in i.location or '24' in i.location or '25' in i.location or '26' in i.location or '27' in i.location or '28' in i.location:\n",
    "                self.loadlocations_C2.append(i)\n",
    "                self.loadlocations_C1_C2.append(i)\n",
    "            if '31' in i.location or '32' in i.location or '33' in i.location or '34' in i.location or '35' in i.location or '36' in i.location:\n",
    "                self.loadlocations_C3.append(i)\n",
    "                self.loadlocations_C3_C4.append(i)\n",
    "            if '41' in i.location or '42' in i.location or '43' in i.location or '44' in i.location or '45' in i.location:\n",
    "                self.loadlocations_C4.append(i)\n",
    "                self.loadlocations_C3_C4.append(i)\n",
    "\n",
    "        #Creating a list of pairs of load locations for the left and right positions\n",
    "        for i in range(len(self.loadlocations_left)):\n",
    "            self.loadlocations_pairs.append((self.loadlocations_left[i].location, self.loadlocations_right[i].location))\n",
    "        \n",
    "        \n",
    "    def define_overlapping_positions(self, position):\n",
    "        \"\"\"\n",
    "        Define the overlapping positions of a specific position\n",
    "\n",
    "        Args:\n",
    "            position (LoadLocations): The position for which the overlapping positions are defined.\n",
    "        \"\"\"\n",
    "        #Reading the file and creating a list of overlapping LoadLocations objects\n",
    "        overlapping = []\n",
    "        data = pd.read_csv(self.aircraft_filename, converters={'Overlapping': lambda x: x.split(',')})\n",
    "        data = data[data['ACType'] == str(self.aircraft_type)]\n",
    "        list_pos = data[data.LoadLocation == position.location]['Overlapping']\n",
    "        for overlapping_list in list_pos:\n",
    "            for overlapping_position in overlapping_list:\n",
    "                for i in self.loadlocations:\n",
    "                    if i.location == overlapping_position.strip():\n",
    "                        overlapping.append(i)\n",
    "\n",
    "        return overlapping\n",
    "    \n",
    "\n",
    "    def define_forbidden_positions_for_ULD(self, uld):\n",
    "        \"\"\"\n",
    "        Define the forbidden positions for a specific ULD type\n",
    "\n",
    "        Args:\n",
    "            uld (ULD): ULD class object.\n",
    "        \"\"\"\n",
    "        #Creating a list of forbidden LoadLocations objects for PMC ULDs\n",
    "        forbidden = []\n",
    "        if uld.type == 'PMC':\n",
    "            for i in self.loadlocations:\n",
    "                if i not in self.loadlocations_pallet:\n",
    "                    forbidden.append(i)\n",
    "\n",
    "        #Creating a list of forbidden LoadLocations objects for AKE ULDs\n",
    "        elif uld.type == 'AKE':\n",
    "            for i in self.loadlocations:\n",
    "                if i in self.loadlocations_pallet:\n",
    "                    forbidden.append(i)\n",
    "\n",
    "        #Creating a list of forbidden LoadLocations objects for PAG ULDs\n",
    "        elif uld.type == 'PAG':\n",
    "            for i in self.loadlocations:\n",
    "                if i not in self.loadlocations_pallet:\n",
    "                    forbidden.append(i)\n",
    "        return forbidden\n",
    "    \n",
    "\n",
    "    def define_positions_for_ULD(self, uld):\n",
    "        \"\"\"\n",
    "        Define the positions for a specific ULD type\n",
    "\n",
    "        Args:\n",
    "            uld (ULD): ULD class object.\n",
    "        \"\"\"\n",
    "        #Creating a list of LoadLocations objects for PMC ULDs\n",
    "        positions = []\n",
    "        if uld.type == 'PMC':\n",
    "            for i in self.loadlocations_pallet:\n",
    "                positions.append(i)\n",
    "\n",
    "        #Creating a list of LoadLocations objects for AKE ULDs\n",
    "        elif uld.type == 'AKE':\n",
    "            for i in self.loadlocations:\n",
    "                if i not in self.loadlocations_pallet:\n",
    "                    positions.append(i)\n",
    "\n",
    "        #Creating a list of LoadLocations objects for PAG ULDs\n",
    "        elif uld.type == 'PAG':\n",
    "            for i in self.loadlocations_pallet:\n",
    "                positions.append(i)\n",
    "        return positions\n",
    "    \n",
    "\n",
    "    def define_max_weight_postion(self, position):\n",
    "        \"\"\"\n",
    "        Define the maximum weight for a specific position\n",
    "\n",
    "        Args:\n",
    "            position (LoadLocations): The position for which the maximum weight is defined.\n",
    "        \"\"\"\n",
    "        if position in self.loadlocations_pallet:\n",
    "            return 5102\n",
    "        if position not in self.loadlocations_pallet:\n",
    "            return 1587\n",
    "        \n",
    "\n",
    "    def define_MPL(self):\n",
    "        \"\"\"\n",
    "        Define Maximum Payload for the aircraft\n",
    "        \"\"\" \n",
    "        limit_1 = self.MTOW - self.OEW - self.TOF\n",
    "        limit_2 = self.MLW - self.OEW - (self.TOF - self.TripF)\n",
    "        limit_3 = self.MZFW - self.OEW\n",
    "        MPL = min(limit_1, limit_2, limit_3)\n",
    "        return MPL\n",
    "        \n",
    "\n",
    "    def define_proximity_score_loadlocation(self, position):\n",
    "        \"\"\"\n",
    "        Define the proximity score for a specific position with respect of the door of its compartment\n",
    "\n",
    "        Args:\n",
    "            position (LoadLocations): The position for which the proximity score is defined.\n",
    "        \"\"\"\n",
    "        data = pd.read_csv(self.aircraft_filename)\n",
    "        data = data[data['ACType'] == str(self.aircraft_type)]\n",
    "\n",
    "        proximity_score = data[data.LoadLocation == position.location]['ProximityScore'].iloc[0]\n",
    "\n",
    "        return int(proximity_score)\n",
    "    \n",
    "\n",
    "    def define_flight_information(self, filename):\n",
    "        \"\"\"\n",
    "        Define the flight information of the aircraft\n",
    "\n",
    "        Args:\n",
    "            filename (str): The path to the Excel file containing the flight data.\n",
    "        \"\"\"\n",
    "        data = pd.read_csv(filename)\n",
    "\n",
    "        self.aircraft_type = data['AircraftType'].iloc[0]\n",
    "        self.aircraft_registration = data['AircraftRegistration'].iloc[0]\n",
    "        self.flight_number = str(data['Airline'].iloc[0]) + str(data['FlightNumber'].iloc[0])\n",
    "        self.departure_airport = data['DepartureAirport'].iloc[0]\n",
    "        self.arrival_airport = data['ArrivalAirport'].iloc[0]\n",
    "        self.date = pd.to_datetime(data['LegDepartureDateUtc'].iloc[0]).strftime(\"%d %b %y\").upper()\n",
    "        self.AZFW = data['ActualZeroFuelWeight'].iloc[0]\n",
    "        self.OEW = data['DryOperatingWeight'].iloc[0]\n",
    "        self.actual_MAC_ZFW = data['MacZFW'].iloc[0]\n",
    "        if 1 < float(self.actual_MAC_ZFW) < 10:\n",
    "            self.actual_MAC_ZFW = float(self.actual_MAC_ZFW) * 10\n",
    "        if float(self.actual_MAC_ZFW) < 1:\n",
    "            self.actual_MAC_ZFW = float(self.actual_MAC_ZFW) * 100\n",
    "        self.cost_index =data['CostIndex'].iloc[0]\n",
    "        self.TOF = data['TakeOffFuel'].iloc[0]\n",
    "        self.TripF = data['TripFuel'].iloc[0]\n",
    "        self.cost_index = data['CostIndex'].iloc[0]\n",
    "\n",
    "\n",
    "    def define_max_weight_information(self, filename, AC_type):\n",
    "        \"\"\"\n",
    "        Define the maximum weight information of the aircraft\n",
    "\n",
    "        Args:\n",
    "            filename (str): The path to the CSV file containing the maximum weight data.\n",
    "            AC_type (str): The aircraft type.\n",
    "        \"\"\"\n",
    "        data = pd.read_csv(filename)\n",
    "        self.main_filename = filename\n",
    "\n",
    "        self.MZFW = data[data['ACType'] == str(AC_type)]['MaxZeroFuelWeight'].max()\n",
    "        self.MTOW = data[data['ACType'] == str(AC_type)]['MaxTakeOffWeight'].max()\n",
    "        self.MLW = data[data['ACType'] == str(AC_type)]['MaxLandingWeight'].max()\n",
    "        self.max_weight_C1 = data[data['ACType'] == str(AC_type)]['MaxWeightC1'].max()\n",
    "        self.max_weight_C2 = data[data['ACType'] == str(AC_type)]['MaxWeightC2'].max()\n",
    "        self.max_weight_C3 = data[data['ACType'] == str(AC_type)]['MaxWeightC3'].max()\n",
    "        self.max_weight_C4 = data[data['ACType'] == str(AC_type)]['MaxWeightC4'].max()\n",
    "        self.max_weight_C1_C2 = data[data['ACType'] == str(AC_type)]['MaxWeightC1C2'].max()\n",
    "        self.max_weight_C3_C4 = data[data['ACType'] == str(AC_type)]['MaxWeightC3C4'].max()\n",
    "\n",
    "\n",
    "    def define_envelope_information(self, AC_type):\n",
    "        \"\"\"\n",
    "        Define the CG envelope information of the aircraft\n",
    "\n",
    "        Args:\n",
    "            AC_type (str): The aircraft type.\n",
    "        \"\"\"\n",
    "        data = pd.read_csv(self.main_filename)\n",
    "        data = data[data['ACType'] == str(AC_type)]\n",
    "\n",
    "\n",
    "        self.C = data['C'].iloc[0]\n",
    "        self.K = data['K'].iloc[0]\n",
    "        self.reference_arm = data['ReferenceArm'].iloc[0]\n",
    "        self.lemac = data['LEMAC'].iloc[0]\n",
    "        self.mac_formula = data['MACFormula'].iloc[0]\n",
    "        self.delta_index_cargo_C1 = data['DeltaIndexCargoC1'].iloc[0]\n",
    "        self.delta_index_cargo_C2 = data['DeltaIndexCargoC2'].iloc[0]\n",
    "        self.delta_index_cargo_C3 = data['DeltaIndexCargoC3'].iloc[0]\n",
    "        self.delta_index_cargo_C4 = data['DeltaIndexCargoC4'].iloc[0]\n",
    "        self.delta_index_cargo_C5 = data['DeltaIndexCargoC5'].iloc[0]\n",
    "        self.delta_index_pax_0A = data['DeltaIndexPax0A'].iloc[0]\n",
    "        self.delta_index_pax_0B = data['DeltaIndexPax0B'].iloc[0]\n",
    "        self.delta_index_pax_0C = data['DeltaIndexPax0C'].iloc[0]\n",
    "        self.delta_index_pax_0D = data['DeltaIndexPax0D'].iloc[0]\n",
    "        self.delta_index_pax_0E = data['DeltaIndexPax0E'].iloc[0]\n",
    "        self.delta_index_pax_0F = data['DeltaIndexPax0F'].iloc[0]\n",
    "        self.delta_index_pax_0G = data['DeltaIndexPax0G'].iloc[0]\n",
    "\n",
    "\n",
    "    def define_fuel_index(self, filename, AC_type):\n",
    "        \"\"\"\n",
    "        Define the fuel index of the aircraft\n",
    "\n",
    "        Args:\n",
    "            filename (str): The path to the CSV file containing the fuel index data.\n",
    "            AC_type (str): The aircraft type.\n",
    "        \"\"\"\n",
    "        #Reading the file and interpolating to find the closest fuel index\n",
    "        self.data_fuel_filename = filename\n",
    "        data_fuel_index = pd.read_csv(filename)\n",
    "        data_fuel_index = data_fuel_index[data_fuel_index['ACType'] == str(AC_type)]\n",
    "\n",
    "        closest_TOF =  (data_fuel_index['TakeOffFuel'] - self.TOF).abs().idxmin()\n",
    "        closest_TOF_row = data_fuel_index.loc[closest_TOF]\n",
    "        self.fuel_index = closest_TOF_row['FuelIndex']\n",
    "\n",
    "    def define_DOI(self, filename, AC_type):\n",
    "        \"\"\"\n",
    "        Define the DOI of the aircraft\n",
    "\n",
    "        Args:\n",
    "            filename (str): The path to the CSV file containing the DOI data.\n",
    "            AC_type (str): The aircraft type.\n",
    "        \"\"\"\n",
    "        #Reading the file and interpolating to find the closest DOI\n",
    "        data = pd.read_csv(filename)\n",
    "        data = data[(data['ACType'] == str(AC_type)) & (data['ACRegistration'] == str(self.aircraft_registration))]\n",
    "        self.DOI = data['DOI'].iloc[0]\n",
    "        # self.OEW = data['OEW'].iloc[0]\n",
    "\n",
    "\n",
    "    def define_INDEX_ZFW_fwd(self, AC_type):\n",
    "        \"\"\"\n",
    "        Define the forward ZFW index limit of the aircraft\n",
    "\n",
    "        Args:\n",
    "            AC_type (str): The aircraft type.\n",
    "        \"\"\"\n",
    "        #Reading the file and filtering the information needed\n",
    "        df = pd.read_csv(self.main_filename)\n",
    "        df = df[df['ACType'] == str(AC_type)][['ZFWWeightFwd', 'ZFWIndexFwd']].reset_index(drop=True)\n",
    "        df = df.dropna()\n",
    "\n",
    "        #Finding the range of the ZFW\n",
    "        pivot_index = df[df['ZFWWeightFwd'] <= self.ZFW].index[-1]\n",
    "\n",
    "        #If pivot index is the last index, the range is from the last index to 0\n",
    "        if pivot_index == df.index[-1]:\n",
    "            zero_row = pd.DataFrame([[0, 0]], columns=['ZFWWeightFwd', 'ZFWIndexFwd'])\n",
    "            pivot_row = df.iloc[[pivot_index]][['ZFWWeightFwd', 'ZFWIndexFwd']]\n",
    "            rows = pd.concat([pivot_row, zero_row], ignore_index=True)\n",
    "        #If pivot index is not the last index, the range is from the pivot index to the next index\n",
    "        else:\n",
    "            rows = df.iloc[[pivot_index, pivot_index + 1]][['ZFWWeightFwd', 'ZFWIndexFwd']]\n",
    "\n",
    "        #Calculating the ZFW fwt index limit\n",
    "        ZFW_fwt_limit = rows['ZFWIndexFwd'].iloc[0] + ((rows['ZFWIndexFwd'].iloc[1] - rows['ZFWIndexFwd'].iloc[0]) / (rows['ZFWWeightFwd'].iloc[1] - rows['ZFWWeightFwd'].iloc[0])) * (self.ZFW - rows['ZFWWeightFwd'].iloc[0])\n",
    "\n",
    "        return float(ZFW_fwt_limit)\n",
    "\n",
    "\n",
    "    def define_INDEX_ZFW_aft(self, AC_type):\n",
    "        \"\"\"\n",
    "        Define the aft ZFW index limit of the aircraft\n",
    "\n",
    "        Args:\n",
    "            AC_type (str): The aircraft type.\n",
    "        \"\"\"\n",
    "        #Reading the file and filtering the information needed\n",
    "        df = pd.read_csv(self.main_filename)\n",
    "        df = df[df['ACType'] == str(AC_type)][['ZFWWeightAft', 'ZFWIndexAft']].reset_index(drop=True)\n",
    "        df = df.dropna()\n",
    "\n",
    "        #Finding the range of the ZFW\n",
    "        pivot_index = df[df['ZFWWeightAft'] <= self.ZFW].index[-1]\n",
    "\n",
    "        #If pivot index is the last index, the range is from the last index to 0\n",
    "        if pivot_index == df.index[-1]:\n",
    "            zero_row = pd.DataFrame([[0, 0]], columns=['ZFWWeightAft', 'ZFWIndexAft'])\n",
    "            pivot_row = df.iloc[[pivot_index]][['ZFWWeightAft', 'ZFWIndexAft']]\n",
    "            rows = pd.concat([pivot_row, zero_row], ignore_index=True)\n",
    "        #If pivot index is not the last index, the range is from the pivot index to the next index\n",
    "        else:\n",
    "            rows = df.iloc[[pivot_index, pivot_index + 1]][['ZFWWeightAft', 'ZFWIndexAft']]\n",
    "\n",
    "        #Calculating the ZFW aft index limit\n",
    "        ZFW_aft_limit = rows['ZFWIndexAft'].iloc[0] + ((rows['ZFWIndexAft'].iloc[1] - rows['ZFWIndexAft'].iloc[0]) / (rows['ZFWWeightAft'].iloc[1] - rows['ZFWWeightAft'].iloc[0])) * (self.ZFW - rows['ZFWWeightAft'].iloc[0])\n",
    "\n",
    "        return float(ZFW_aft_limit)\n",
    "   \n",
    "\n",
    "    def define_INDEX_TOW_fwd(self, AC_type):\n",
    "        \"\"\"\n",
    "        Define the forward TOW index limit of the aircraft\n",
    "\n",
    "        Args:\n",
    "            AC_type (str): The aircraft type.\n",
    "        \"\"\"\n",
    "        #Reading the file and filtering the information needed\n",
    "        df = pd.read_csv(self.main_filename)\n",
    "        df = df[df['ACType'] == str(AC_type)][['TOWWeightFwd', 'TOWIndexFwd']].reset_index(drop=True)\n",
    "        df = df.dropna()\n",
    "        \n",
    "        #Finding the range of the TOW\n",
    "        pivot_index = df[df['TOWWeightFwd'] <= self.TOW].index[-1]\n",
    "\n",
    "        #If pivot index is the last index, the range is from the last index to 0\n",
    "        if pivot_index == df.index[-1]:\n",
    "            zero_row = pd.DataFrame([[0, 0]], columns=['TOWWeightFwd', 'TOWIndexFwd'])\n",
    "            pivot_row = df.iloc[[pivot_index]][['TOWWeightFwd', 'TOWIndexFwd']]\n",
    "            rows = pd.concat([pivot_row, zero_row], ignore_index=True)\n",
    "        #If pivot index is not the last index, the range is from the pivot index to the next index\n",
    "        else:\n",
    "            rows = df.iloc[[pivot_index, pivot_index + 1]][['TOWWeightFwd', 'TOWIndexFwd']]\n",
    "\n",
    "        #Calculating the TOW fwt index limit\n",
    "        TOW_fwt_limit = rows['TOWIndexFwd'].iloc[0] + ((rows['TOWIndexFwd'].iloc[1] - rows['TOWIndexFwd'].iloc[0]) / (rows['TOWWeightFwd'].iloc[1] - rows['TOWWeightFwd'].iloc[0])) * (self.TOW - rows['TOWWeightFwd'].iloc[0])\n",
    "\n",
    "        return float(TOW_fwt_limit)\n",
    "        \n",
    "        \n",
    "    def define_INDEX_TOW_aft(self, AC_type):\n",
    "        \"\"\"\n",
    "        Define the aft TOW index limit of the aircraft\n",
    "\n",
    "        Args:\n",
    "            AC_type (str): The aircraft type.\n",
    "        \"\"\"\n",
    "        #Reading the file and filtering the information needed\n",
    "        df = pd.read_csv(self.main_filename)\n",
    "        df = df[df['ACType'] == str(AC_type)][['TOWWeightAft', 'TOWIndexAft']].reset_index(drop=True)\n",
    "        df = df.dropna()\n",
    "\n",
    "        #Finding the range of the TOW\n",
    "        pivot_index = df[df['TOWWeightAft'] <= self.TOW].index[-1]\n",
    "\n",
    "        #If pivot index is the last index, the range is from the last index to 0\n",
    "        if pivot_index == df.index[-1]:\n",
    "            zero_row = pd.DataFrame([[0, 0]], columns=['TOWWeightAft', 'TOWIndexAft'])\n",
    "            pivot_row = df.iloc[[pivot_index]][['TOWWeightAft', 'TOWIndexAft']]\n",
    "            rows = pd.concat([pivot_row, zero_row], ignore_index=True)\n",
    "        #If pivot index is not the last index, the range is from the pivot index to the next index\n",
    "        else:\n",
    "            rows = df.iloc[[pivot_index, pivot_index + 1]][['TOWWeightAft', 'TOWIndexAft']]\n",
    "\n",
    "        #Calculating the TOW aft index limit\n",
    "        TOW_aft_limit = rows['TOWIndexAft'].iloc[0] + ((rows['TOWIndexAft'].iloc[1] - rows['TOWIndexAft'].iloc[0]) / (rows['TOWWeightAft'].iloc[1] - rows['TOWWeightAft'].iloc[0])) * (self.TOW - rows['TOWWeightAft'].iloc[0])\n",
    "\n",
    "        return float(TOW_aft_limit)\n",
    "\n",
    "\n",
    "    def define_INDEX_LW_fwd(self, AC_type):\n",
    "        \"\"\"\n",
    "        Define the forward LW index limit of the aircraft\n",
    "\n",
    "        Args:\n",
    "            AC_type (str): The aircraft type.\n",
    "        \"\"\"\n",
    "        #Reading the file and filtering the information needed\n",
    "        df = pd.read_csv(self.main_filename)\n",
    "        df = df[df['ACType'] == str(AC_type)].reset_index(drop=True)\n",
    "\n",
    "        #Finding the range of the LW\n",
    "        pivot_index = df[df['LWWeightFwd'] <= self.LW].index[-1]\n",
    "\n",
    "        #If pivot index is the last index, the range is from the last index to 0\n",
    "        if pivot_index == df.index[-1]:\n",
    "            missing_rows = df.iloc[pivot_index][['LWWeightFwd', 'LWIndexFwd']]\n",
    "            rows = pd.concat([rows, missing_rows], ignore_index=True)\n",
    "        #If pivot index is not the last index, the range is from the pivot index to the next index\n",
    "        else:\n",
    "            rows = df.iloc[[pivot_index, pivot_index + 1]][['LWWeightFwd', 'LWIndexFwd']]\n",
    "\n",
    "        #Calculating the LW fwt index limit\n",
    "        LW_fwt_limit = rows['LWIndexFwd'].iloc[0] + ((rows['LWIndexFwd'].iloc[1] - rows['LWIndexFwd'].iloc[0]) / (rows['LWWeightFwd'].iloc[1] - rows['LWWeightFwd'].iloc[0])) * (self.LW - rows['LWWeightFwd'].iloc[0])\n",
    "\n",
    "        return float(LW_fwt_limit)\n",
    "        \n",
    "\n",
    "    def define_INDEX_LW_aft(self, AC_type):\n",
    "        \"\"\"\n",
    "        Define the aft LW index limit of the aircraft\n",
    "\n",
    "        Args:\n",
    "            AC_type (str): The aircraft type.\n",
    "        \"\"\"\n",
    "        #Reading the file and filtering the information needed\n",
    "        df = pd.read_csv(self.main_filename)\n",
    "        df = df[df['ACType'] == str(AC_type)].reset_index(drop=True)\n",
    "\n",
    "        #Finding the range of the LW\n",
    "        pivot_index = df[df['LWWeightAft'] <= self.LW].index[-1]\n",
    "\n",
    "        #If pivot index is the last index, the range is from the last index to 0\n",
    "        if pivot_index == df.index[-1]:\n",
    "            missing_rows = df.iloc[pivot_index][['LWWeightAft', 'LWIndexAft']]\n",
    "            rows = pd.concat([rows, missing_rows], ignore_index=True)\n",
    "        #If pivot index is not the last index, the range is from the pivot index to the next index\n",
    "        else:\n",
    "            rows = df.iloc[[pivot_index, pivot_index + 1]][['LWWeightAft', 'LWIndexAft']]\n",
    "\n",
    "        #Calculating the LW aft index limit\n",
    "        LW_aft_limit = rows['LWIndexAft'].iloc[0] + ((rows['LWIndexAft'].iloc[1] - rows['LWIndexAft'].iloc[0]) / (rows['LWWeightAft'].iloc[1] - rows['LWWeightAft'].iloc[0])) * (self.LW - rows['LWWeightAft'].iloc[0])\n",
    "\n",
    "        return float(LW_aft_limit)\n",
    "\n",
    "        \n",
    "    def define_INDEX_LW(self, ZFW_index):\n",
    "        \"\"\"\n",
    "        Define the LW index of the aircraft\n",
    "\n",
    "        Args:\n",
    "            ZFW_index (float): The ZFW index of the aircraft.\n",
    "        \"\"\"\n",
    "        data = pd.read_csv(self.data_fuel_filename)\n",
    "        \n",
    "        data['corrected_weight'] = data['TakeOffFuel'] + self.ZFW\n",
    "        closest_corrected_weight =  (data['corrected_weight'] - self.LW).abs().idxmin()\n",
    "        closest_corrected_weight_row = data.loc[closest_corrected_weight]\n",
    "        LW_INDEX = closest_corrected_weight_row['FuelIndex'] +  ZFW_index\n",
    "\n",
    "        return LW_INDEX\n",
    "    \n",
    "\n",
    "    def define_axis_ZFW(self, AC_type):\n",
    "        \"\"\"\n",
    "        Define the ZFW axis of the aircraft for the graph\n",
    "\n",
    "        Args:\n",
    "            AC_type (str): The aircraft type.\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(self.main_filename)\n",
    "        df = df[df['ACType'] == str(AC_type)]\n",
    "\n",
    "        index_axis = [x for x in df['ZFWIndexFwd'].tolist() if not pd.isna(x)] + [x for x in df['ZFWIndexAft'].iloc[::-1].tolist() if not pd.isna(x)]\n",
    "        weight_axis = [x for x in df['ZFWWeightFwd'].tolist() if not pd.isna(x)] + [x for x in df['ZFWWeightAft'].iloc[::-1].tolist() if not pd.isna(x)]\n",
    "\n",
    "\n",
    "        return index_axis, weight_axis\n",
    "    \n",
    "\n",
    "    def define_axis_TOW(self, AC_type):\n",
    "        \"\"\"\n",
    "        Define the TOW axis of the aircraft for the graph\n",
    "\n",
    "        Args:\n",
    "            AC_type (str): The aircraft type.\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(self.main_filename)\n",
    "        df = df[df['ACType'] == str(AC_type)]\n",
    "\n",
    "        index_axis = [x for x in df['TOWIndexFwd'].tolist() if not pd.isna(x)] + [x for x in df['TOWIndexAft'].iloc[::-1].tolist() if not pd.isna(x)]\n",
    "        weight_axis = [x for x in df['TOWWeightFwd'].tolist() if not pd.isna(x)] + [x for x in df['TOWWeightAft'].iloc[::-1].tolist() if not pd.isna(x)]\n",
    "\n",
    "        return index_axis, weight_axis\n",
    "    \n",
    "\n",
    "    def define_axis_LW(self, AC_type):\n",
    "        \"\"\"\n",
    "        Define the LW axis of the aircraft for the graph\n",
    "\n",
    "        Args:\n",
    "            AC_type (str): The aircraft type.\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(self.main_filename)\n",
    "        df = df[df['ACType'] == str(AC_type)]\n",
    "\n",
    "        index_axis = [x for x in df['LWIndexFwd'].tolist() if not pd.isna(x)] + [x for x in df['LWIndexAft'].iloc[::-1].tolist() if not pd.isna(x)]\n",
    "        weight_axis = [x for x in df['LWWeightFwd'].tolist() if not pd.isna(x)] + [x for x in df['LWWeightAft'].iloc[::-1].tolist() if not pd.isna(x)]\n",
    "\n",
    "        return index_axis, weight_axis\n",
    "    \n",
    "    def define_PAX_allocation(self, pax_filename):\n",
    "        df = pd.read_csv(pax_filename)\n",
    "\n",
    "        self.pax_0A = df[df['CenterOfGravityCabin'] == 'CABIN0A']['PassengerCount'].iloc[0]\n",
    "        self.pax_0B = df[df['CenterOfGravityCabin'] == 'CABIN0B']['PassengerCount'].iloc[0]\n",
    "        self.pax_0C = df[df['CenterOfGravityCabin'] == 'CABIN0C']['PassengerCount'].iloc[0]\n",
    "        self.pax_0D = df[df['CenterOfGravityCabin'] == 'CABIN0D']['PassengerCount'].iloc[0]\n",
    "        self.pax_0E = df[df['CenterOfGravityCabin'] == 'CABIN0E']['PassengerCount'].iloc[0]\n",
    "        if 'CABIN0F' in df['CenterOfGravityCabin'].to_list() and 'CABIN0G' in df['CenterOfGravityCabin'].to_list():\n",
    "            self.pax_0F = df[df['CenterOfGravityCabin'] == 'CABIN0F']['PassengerCount'].iloc[0]\n",
    "            self.pax_0G = df[df['CenterOfGravityCabin'] == 'CABIN0G']['PassengerCount'].iloc[0]\n",
    "        else:\n",
    "            self.pax_0F = 0\n",
    "            self.pax_0G = 0\n",
    "            \n",
    "        self.total_PAX = self.pax_0A + self.pax_0B + self.pax_0C + self.pax_0D + self.pax_0E + self.pax_0F + self.pax_0G\n",
    "\n",
    "\n",
    "    def define_INDEX_PAX(self):\n",
    "        \"\"\"\n",
    "        Define the PAX index of the aicraft\n",
    "        \"\"\"\n",
    "        #Calculating the PAX index per compartment\n",
    "        index_0A = self.pax_0A * 84 * self.delta_index_pax_0A\n",
    "        index_0B = self.pax_0B * 84 * self.delta_index_pax_0B\n",
    "        index_0C = self.pax_0C * 84 * self.delta_index_pax_0C\n",
    "        index_0D = self.pax_0D * 84 * self.delta_index_pax_0D\n",
    "        index_0E = self.pax_0E * 84 * self.delta_index_pax_0E\n",
    "        index_0F = self.pax_0F * 84 * self.delta_index_pax_0F\n",
    "        index_0G = self.pax_0G * 84 * self.delta_index_pax_0G\n",
    "\n",
    "        #Calculating the total PAX index\n",
    "        index_PAX = index_0A + index_0B + index_0C + index_0D + index_0E + index_0F + index_0G\n",
    "\n",
    "        return float(index_PAX)\n",
    "    \n",
    "\n",
    "    def define_PAX_weight(self):\n",
    "        \"\"\"\n",
    "        Define the PAX weight of the aircraft\n",
    "        \"\"\"\n",
    "        #Calculating the PAX weight, IATA assumption of 84 kg per PAX\n",
    "        weight_pax = (self.pax_0A + self.pax_0B + self.pax_0C + self.pax_0D + self.pax_0E + self.pax_0F + self.pax_0G) * 84\n",
    "        return int(weight_pax)\n",
    "    \n",
    "    \n",
    "    def define_ff_increment_MAC_ZFW(self, MAC_ZFW):\n",
    "        \"\"\"\n",
    "        Define the fuel efficiency increment for the MAC ZFW\n",
    "\n",
    "        Args:\n",
    "            MAC_ZFW (float): The MAC ZFW of the aircraft.\n",
    "        \"\"\"\n",
    "        actual_increment = None \n",
    "        model_increment = None\n",
    "        \n",
    "        #Defining the fuel efficiency brackets for the different aircraft types\n",
    "        if str(self.aircraft_type) == '789':\n",
    "            fuel_efficiency_brackets = np.array([\n",
    "                (0, 1.9),\n",
    "                (16, 1.9),\n",
    "                (18, 1.7),\n",
    "                (20, 1.3),\n",
    "                (22, 1.1),\n",
    "                (24, 0.8),\n",
    "                (26, 0.5),\n",
    "                (28, 0.3),\n",
    "                (32, 0),\n",
    "                (34, -0.2),\n",
    "                (36, -0.3),\n",
    "                (40, -0.3),\n",
    "                (43, -0.3)\n",
    "            ])\n",
    "\n",
    "        elif str(self.aircraft_type) == '781':\n",
    "            fuel_efficiency_brackets = np.array([\n",
    "                (0, 2.2),\n",
    "                (16, 2.2),\n",
    "                (18, 2),\n",
    "                (20, 1.6),\n",
    "                (22, 1.3),\n",
    "                (24, 1),\n",
    "                (26, 0.6),\n",
    "                (28, 0.4),\n",
    "                (32, 0),\n",
    "                (34, -0.3),\n",
    "                (36, -0.4),\n",
    "                (40, -0.5),\n",
    "                (43, -0.5)\n",
    "            ])\n",
    "\n",
    "        elif str(self.aircraft_type) == '772':\n",
    "            fuel_efficiency_brackets = np.array([\n",
    "                (0, 1.3),\n",
    "                (16, 1.3),\n",
    "                (18, 1.3),\n",
    "                (20, 1.2),\n",
    "                (22, 0.9),\n",
    "                (24, 0.6),\n",
    "                (26, 0.4),\n",
    "                (28, 0.2),\n",
    "                (32, 0),\n",
    "                (34, -0.4),\n",
    "                (36, -0.5),\n",
    "                (40, -0.7),\n",
    "                (43, -0.7)\n",
    "            ])\n",
    "\n",
    "        elif str(self.aircraft_type) == '77W':\n",
    "            fuel_efficiency_brackets = np.array([\n",
    "                (0, 1.7), \n",
    "                (16, 1.7),\n",
    "                (18, 1.5),\n",
    "                (20, 1.2),\n",
    "                (22, 0.9),\n",
    "                (24, 0.6), \n",
    "                (26, 0.4),\n",
    "                (28, 0.2), \n",
    "                (32, 0),\n",
    "                (34, -0.4),\n",
    "                (36, -0.5),\n",
    "                (40, -0.6),\n",
    "                (43, -0.6)\n",
    "            ])\n",
    "\n",
    "\n",
    "        for i in range(len(fuel_efficiency_brackets) - 1):\n",
    "            if fuel_efficiency_brackets[i][0] <= MAC_ZFW <= fuel_efficiency_brackets[i + 1][0]:\n",
    "                x1, y1 = fuel_efficiency_brackets[i]\n",
    "                x2, y2 = fuel_efficiency_brackets[i + 1]\n",
    "                model_increment = y1 + (y2 - y1) * (MAC_ZFW - x1) / (x2 - x1)\n",
    "\n",
    "            if fuel_efficiency_brackets[i][0] <= self.actual_MAC_ZFW <= fuel_efficiency_brackets[i + 1][0]:\n",
    "                x1, y1 = fuel_efficiency_brackets[i]\n",
    "                x2, y2 = fuel_efficiency_brackets[i + 1]\n",
    "                actual_increment = y1 + (y2 - y1) * (self.actual_MAC_ZFW - x1) / (x2 - x1)\n",
    "\n",
    "        if actual_increment is not None and model_increment is not None:\n",
    "            fuel_saving = model_increment - actual_increment\n",
    "            return fuel_saving\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extreme_Points():\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def get_color_map(self, items):\n",
    "        \"\"\"\n",
    "        Generate a color map for items based on their prefix_serialnumber\n",
    "\n",
    "        Args:\n",
    "            items (list): List of items to generate a color map for.\n",
    "        \"\"\"\n",
    "        # Get unique prefixes_serialnumber\n",
    "        prefixes_serialnumber = sorted(\n",
    "            list(set([item.prefix_serialnumber for item in items]))\n",
    "        )\n",
    "        \n",
    "        # Generate a color map using a colormap from matplotlib\n",
    "        cmap = matplotlib.colormaps.get_cmap('tab20')\n",
    "        colors = np.linspace(0, 1, len(prefixes_serialnumber))\n",
    "        color_map = {prefix: cmap(color) for prefix, color in zip(prefixes_serialnumber, colors)}\n",
    "        \n",
    "        return color_map\n",
    "\n",
    "\n",
    "    def get_item_bounds(self, item, placed_items):\n",
    "        \"\"\"\n",
    "        Get the bounds of an item based on its position and orientation\n",
    "\n",
    "        Args:\n",
    "            item (Item): The item to get the bounds for.\n",
    "            placed_items (dict): Dictionary of placed items.\n",
    "        \"\"\"\n",
    "        x, y, z, length, width, height, weight, stack = placed_items[item]\n",
    "    \n",
    "        return {'x_min': x,'x_max': x + length,\n",
    "                'y_min': y,'y_max': y + width,\n",
    "                'z_min': z,'z_max': z + height\n",
    "                }\n",
    "    \n",
    "\n",
    "    def get_item_edges(self, item_bounds):\n",
    "        \"\"\"\n",
    "        Get the edges of an item based on its bounds\n",
    "\n",
    "        Args:\n",
    "            item_bounds (dict): Dictionary of item bounds.\n",
    "        \"\"\"\n",
    "        edges = {\n",
    "            'left': {(item_bounds['x_min'], y) for y in range(item_bounds['y_min'], item_bounds['y_max'] + 1)},\n",
    "            'right': {(item_bounds['x_max'], y) for y in range(item_bounds['y_min'], item_bounds['y_max'] + 1)},\n",
    "            'front': {(x, item_bounds['y_min']) for x in range(item_bounds['x_min'], item_bounds['x_max'] + 1)},\n",
    "            'back': {(x, item_bounds['y_max']) for x in range(item_bounds['x_min'], item_bounds['x_max'] + 1)},\n",
    "        }\n",
    "        return edges\n",
    "    \n",
    "\n",
    "    def get_base_corners(self, ep, orientation):\n",
    "        \"\"\"\n",
    "        Get the corners of the base of an item based on its extreme point and orientation\n",
    "\n",
    "        Args:\n",
    "            ep (tuple): The extreme point of the item.\n",
    "            orientation (tuple): The orientation of the item.\n",
    "        \"\"\"\n",
    "        length, width, height = orientation\n",
    "\n",
    "        corners = [\n",
    "            (ep[0], ep[1], ep[2]),\n",
    "            (ep[0] + length, ep[1], ep[2]),\n",
    "            (ep[0], ep[1] + width, ep[2]),\n",
    "            (ep[0] + length, ep[1] + width, ep[2]),\n",
    "        ]\n",
    "\n",
    "        return corners\n",
    "    \n",
    "\n",
    "    def get_starting_extreme_points(self, j):\n",
    "        \"\"\"\n",
    "        Get the starting extreme points for the ULD types\n",
    "\n",
    "        Args:\n",
    "            j (ULD): The ULD to get the starting extreme points for.\n",
    "        \"\"\"\n",
    "        if 'AKE' in j.serialnumber:\n",
    "            return [(j.a, 0, 0)]\n",
    "        else:\n",
    "            return [(0, 0, 0)]\n",
    "            \n",
    "\n",
    "    def update_extreme_points(self, extreme_points, ep, i, j):\n",
    "        \"\"\"\n",
    "        Update the extreme points based on the placed item\n",
    "\n",
    "        Args:\n",
    "            extreme_points (list): List of extreme points to update.\n",
    "            ep (tuple): The extreme point of the placed item.\n",
    "            i (Item): The placed item.\n",
    "        \"\"\"\n",
    "        # The farthest corner of the placed item\n",
    "        new_point = (ep[0] + i.length, ep[1] + i.width, ep[2] + i.height)\n",
    "\n",
    "        # Add the new extreme point if it's inside the container and not already present\n",
    "        if new_point not in extreme_points:\n",
    "            extreme_points.append(new_point)\n",
    "\n",
    "        # Additional potential extreme points generated by the placed item\n",
    "        potential_points = [\n",
    "            (ep[0] + i.length, ep[1], ep[2]),\n",
    "            (ep[0], ep[1] + i.width, ep[2]),\n",
    "            (ep[0], ep[1], ep[2] + i.height),\n",
    "            (ep[0] + i.length, ep[1] + i.width, ep[2]),\n",
    "            (ep[0] + i.length, ep[1], ep[2] + i.height),\n",
    "            (ep[0], ep[1] + i.width, ep[2] + i.height)\n",
    "        ]\n",
    "\n",
    "        # Add each potential extreme point if it's inside the bounds and not already present\n",
    "        for point in potential_points:\n",
    "            if point not in extreme_points:\n",
    "                extreme_points.append(point)\n",
    "\n",
    "        # Remove the extreme point where the item was placed, as it's no longer 'extreme'\n",
    "        if ep in extreme_points:\n",
    "            extreme_points.remove(ep)\n",
    "\n",
    "        return extreme_points\n",
    "\n",
    "\n",
    "    def get_orientations(self, item):\n",
    "        \"\"\"\n",
    "        Get the possible orientations of an item\n",
    "\n",
    "        Args:\n",
    "            item (Item): The item to get the orientations for.\n",
    "        \"\"\"\n",
    "        if item.rotate == 1:\n",
    "            dimensions = [\n",
    "                (item.length, item.width, item.height),\n",
    "                (item.length, item.height, item.width),\n",
    "                (item.width, item.length, item.height),\n",
    "                (item.width, item.height, item.length),\n",
    "                (item.height, item.length, item.width),\n",
    "                (item.height, item.width, item.length)\n",
    "\n",
    "            ]\n",
    "\n",
    "        else:\n",
    "            dimensions = [\n",
    "                (item.length, item.width, item.height),\n",
    "            ]\n",
    "        \n",
    "        return dimensions\n",
    "    \n",
    "\n",
    "    def check_collision(self, ep, length, width, height, placed_items, stack_item):\n",
    "        \"\"\"\n",
    "        Check for collisions between the placed item and other items\n",
    "\n",
    "        Args:\n",
    "            ep (tuple): The extreme point of the placed item.\n",
    "            length (float): The length of the placed item.\n",
    "            width (float): The width of the placed item.\n",
    "            height (float): The height of the placed item.\n",
    "            placed_items (dict): Dictionary of placed items.\n",
    "        \"\"\"\n",
    "        for other_item in placed_items:\n",
    "            x_other_item, y_other_item, z_other_item, length_other_item, width_other_item, height_other_item, weight_other_item, stack_other_item = placed_items[other_item]\n",
    "            if (ep[0] < x_other_item + length_other_item and ep[0] + length > x_other_item and\n",
    "                ep[1] < y_other_item + width_other_item and ep[1] + width > y_other_item and\n",
    "                ep[2] < z_other_item + height_other_item and ep[2] + height > z_other_item):\n",
    "                return True\n",
    "            \n",
    "            if stack_item == 1:\n",
    "                if (ep[2] + height > z_other_item):\n",
    "                    return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "\n",
    "    def is_point_supported(self, point, placed_items):\n",
    "        \"\"\"\n",
    "        Check if a point is supported by other items\n",
    "\n",
    "        Args:\n",
    "            point (tuple): The point to check for support.\n",
    "            placed_items (dict): Dictionary of placed items.\n",
    "        \"\"\"\n",
    "        x, y, z = point\n",
    "\n",
    "        for _, (item_x, item_y, item_z, length, width, height, weight, stack) in placed_items.items():\n",
    "            if (item_x <= x <= item_x + length) and (item_y <= y <= item_y + width) and z == item_z + height:\n",
    "                return True\n",
    "        return False\n",
    "        \n",
    "\n",
    "    def check_full_base_coverage(self, j, ep, orientation, placed_items):\n",
    "        \"\"\"\n",
    "        Check if the base of the placed item is fully supported\n",
    "\n",
    "        Args:\n",
    "            ep (tuple): The extreme point of the placed item.\n",
    "            orientation (tuple): The orientation of the placed item.\n",
    "            placed_items (dict): Dictionary of placed items.\n",
    "        \"\"\"\n",
    "        length, width, height = orientation\n",
    "        base_corners = self.get_base_corners(ep, orientation)\n",
    "\n",
    "        key_points = base_corners + [\n",
    "            (ep[0] + length / 2, ep[1] + width / 2, ep[2]),\n",
    "            (ep[0] + length / 2, ep[1], ep[2]),\n",
    "            (ep[0], ep[1] + width / 2, ep[2]),\n",
    "            (ep[0] + length, ep[1] + width / 2, ep[2]),\n",
    "            (ep[0] + length / 2, ep[1] + width, ep[2]),\n",
    "        ]\n",
    "\n",
    "        supported_points = 0\n",
    "\n",
    "        for point in key_points:\n",
    "            if self.is_point_supported(point, placed_items):\n",
    "                supported_points += 1\n",
    "      \n",
    "\n",
    "        return supported_points == len(key_points)\n",
    "\n",
    "\n",
    "    def is_supported_by_uld_side(self, ep, j):\n",
    "        \"\"\"\n",
    "        Check if the placed item is supported by the ULD side\n",
    "\n",
    "        Args:\n",
    "            ep (tuple): The extreme point of the placed item.\n",
    "            j (ULD): The ULD to check for support.\n",
    "        \"\"\"\n",
    "        x_support = (ep[0] == 0 or ep[0] == j.length)\n",
    "        y_support = (ep[1] == 0 or ep[1] == j.width)\n",
    "        \n",
    "        uld_support_count = int(x_support) + int(y_support) \n",
    "\n",
    "        return uld_support_count\n",
    "    \n",
    "\n",
    "    def is_side_contact(self, ep, orientation, placed_items):\n",
    "        \"\"\"\n",
    "        Check if the placed item has side contact with other items\n",
    "\n",
    "        Args:\n",
    "            ep (tuple): The extreme point of the placed item.\n",
    "            orientation (tuple): The orientation of the placed item.\n",
    "            placed_items (dict): Dictionary of placed items.\n",
    "        \"\"\"\n",
    "        contact_counts = {'left': 0, 'right': 0, 'front': 0, 'back': 0}\n",
    "\n",
    "        item_bounds = {\n",
    "            'x_min': ep[0], 'x_max': ep[0] + orientation[0],\n",
    "            'y_min': ep[1], 'y_max': ep[1] + orientation[1],\n",
    "            'z_min': ep[2], 'z_max': ep[2] + orientation[2],\n",
    "                    }\n",
    "\n",
    "        for other_item_serial, other_item_info in placed_items.items():\n",
    "            other_item_bounds = self.get_item_bounds(other_item_serial, placed_items)\n",
    "            \n",
    "            if (item_bounds['y_min'] < other_item_bounds['y_max'] and\n",
    "                item_bounds['y_max'] > other_item_bounds['y_min'] and\n",
    "                item_bounds['z_min'] < other_item_bounds['z_max'] and\n",
    "                item_bounds['z_max'] > other_item_bounds['z_min']):\n",
    "                if item_bounds['x_min'] == other_item_bounds['x_max']:\n",
    "                    contact_counts['left'] = 1\n",
    "                elif item_bounds['x_max'] == other_item_bounds['x_min']:\n",
    "                    contact_counts['right'] = 1\n",
    "\n",
    "            if (item_bounds['x_min'] < other_item_bounds['x_max'] and\n",
    "                item_bounds['x_max'] > other_item_bounds['x_min'] and\n",
    "                item_bounds['z_min'] < other_item_bounds['z_max'] and\n",
    "                item_bounds['z_max'] > other_item_bounds['z_min']):\n",
    "                if item_bounds['y_min'] == other_item_bounds['y_max']:\n",
    "                    contact_counts['front'] = 1\n",
    "                elif item_bounds['y_max'] == other_item_bounds['y_min']:\n",
    "                    contact_counts['back'] = 1\n",
    "\n",
    "        side_support_count = sum(contact_counts.values())\n",
    "\n",
    "        return side_support_count\n",
    "\n",
    "\n",
    "    def check_side_support(self, ep, orientation, placed_items, j):\n",
    "        \"\"\"\n",
    "        Check if the placed item is supported by the ULD side and has side contact with other items\n",
    "\n",
    "        Args:\n",
    "            ep (tuple): The extreme point of the placed item.\n",
    "            orientation (tuple): The orientation of the placed item.\n",
    "            placed_items (dict): Dictionary of placed items.\n",
    "            j (ULD): The ULD to check for support.\n",
    "        \"\"\"\n",
    "        side_support_count = 0\n",
    "\n",
    "        side_support = self.is_side_contact(ep, orientation, placed_items)\n",
    "        side_support_count += side_support\n",
    "\n",
    "        uld_support = self.is_supported_by_uld_side(ep, j)\n",
    "        side_support_count += uld_support\n",
    "                \n",
    "        return side_support_count\n",
    "    \n",
    "\n",
    "    def check_supported_by_cut(self, ep, orientation, j, placed_items):\n",
    "        \"\"\"\n",
    "        Check if the placed item is supported by the AKE ULD cut\n",
    "\n",
    "        Args:\n",
    "            ep (tuple): The extreme point of the placed item.\n",
    "            orientation (tuple): The orientation of the placed item.\n",
    "            j (ULD): The ULD to check for support.\n",
    "            placed_items (dict): Dictionary of placed items.\n",
    "        \"\"\"\n",
    "        if 'AKE' in j.serialnumber:\n",
    "            item_bounds = {\n",
    "                'x_min': ep[0], 'x_max': ep[0] + orientation[0],\n",
    "                'y_min': ep[1], 'y_max': ep[1] + orientation[1],\n",
    "                'z_min': ep[2], 'z_max': ep[2] + orientation[2],\n",
    "                    }\n",
    "\n",
    "\n",
    "            expected_z_on_cut = -j.cut_a * ep[0] + j.b\n",
    "\n",
    "\n",
    "            touches_cut = False\n",
    "            if (item_bounds['z_min'] == expected_z_on_cut):\n",
    "                touches_cut = True\n",
    "\n",
    "            lateral_support = False\n",
    "            for other_item_serial, other_item_info in placed_items.items():\n",
    "                other_item_bounds = self.get_item_bounds(other_item_serial, placed_items)\n",
    "\n",
    "                is_adjacent = (other_item_bounds['x_max'] == item_bounds['x_min'] or\n",
    "                            other_item_bounds['x_min'] == item_bounds['x_max'])\n",
    "\n",
    "                is_at_cut_height = (other_item_bounds['z_max'] >= expected_z_on_cut)\n",
    "\n",
    "                if is_adjacent and is_at_cut_height:\n",
    "                    lateral_support = True\n",
    "                    break\n",
    "\n",
    "            if touches_cut and lateral_support:\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "    \n",
    "\n",
    "    def is_fully_supported(self, ep, orientation, placed_items, j): \n",
    "        \"\"\"\n",
    "        Check if the placed item is fully supported, support count must be equal or greater than 3\n",
    "\n",
    "        Args:\n",
    "            ep (tuple): The extreme point of the placed item.\n",
    "            orientation (tuple): The orientation of the placed item.\n",
    "            placed_items (dict): Dictionary of placed items.\n",
    "            j (ULD): The ULD to check for support.\n",
    "        \"\"\"\n",
    "        support_count = 0\n",
    "        ground_supported = False\n",
    "        base_supported = False\n",
    "\n",
    "        if ep[2] == 0:\n",
    "            ground_support = 3\n",
    "            support_count += ground_support\n",
    "            ground_supported = True\n",
    "\n",
    "        if self.check_full_base_coverage(j, ep, orientation, placed_items):\n",
    "            base_support = 2\n",
    "            support_count += base_support\n",
    "            base_supported = True\n",
    "\n",
    "        if not ground_supported and not base_supported:\n",
    "            return False, support_count\n",
    "\n",
    "        if base_supported or ground_supported:\n",
    "            side_support = self.check_side_support(ep, orientation, placed_items, j)\n",
    "            support_count += side_support\n",
    "\n",
    "        if self.check_supported_by_cut(ep, orientation, j, placed_items):\n",
    "            cut_support = 3\n",
    "            support_count += cut_support\n",
    "\n",
    "        if support_count >= 3:\n",
    "            return True, support_count\n",
    "        \n",
    "        return False, support_count\n",
    "    \n",
    "\n",
    "    def calculate_cog_deviation(self, placed_items, j):\n",
    "        x_cog, y_cog = self.calculate_cog(placed_items)\n",
    "        center_x, center_y = j.length / 2, j.width / 2\n",
    "\n",
    "        cog_deviation = ((x_cog - center_x) ** 2 + (y_cog - center_y) ** 2) ** 0.5\n",
    "\n",
    "        return cog_deviation\n",
    "\n",
    "\n",
    "    def calculate_cog(self, placed_items):\n",
    "        total_weight = sum(item[6] for item in placed_items.values())\n",
    "        x_cog = sum((item[0] + item[3] / 2) * item[6] for item in placed_items.values()) / total_weight\n",
    "        y_cog = sum((item[1] + item[4] / 2) * item[6] for item in placed_items.values()) / total_weight\n",
    "\n",
    "        return x_cog, y_cog\n",
    "    \n",
    "\n",
    "    def calculate_cog_deviation(self, placed_items, j):\n",
    "        x_cog, y_cog = self.calculate_cog(placed_items)\n",
    "\n",
    "        cog_devaition = max(abs(x_cog - j.length / 2) - 0.2 * j.length, 0) +  max(abs(y_cog - j.width / 2) - 0.2 * j.width, 0)\n",
    "\n",
    "        return cog_devaition\n",
    "\n",
    "\n",
    "    def place_item(self, item, ep, placed_items, orientation, current_extreme_points):\n",
    "        \"\"\"\n",
    "        Place an item in the ULD\n",
    "\n",
    "        Args:\n",
    "            item (Item): The item to place.\n",
    "            ep (tuple): The extreme point to place the item at.\n",
    "            placed_items (dict): Dictionary of placed items.\n",
    "            orientation (tuple): The orientation of the item.\n",
    "            current_extreme_points (list): List of current extreme points.\n",
    "        \"\"\"\n",
    "        item.x, item.y, item.z = ep\n",
    "        item.length, item.width, item.height = orientation\n",
    "        placed_items[item.serialnumber] = [item.x, item.y, item.z, item.length, item.width, item.height, item.weight, item.stack] \n",
    "\n",
    "        removed_points = []\n",
    "        for point in current_extreme_points:\n",
    "            if (item.x <= point[0] <= item.x + item.length and\n",
    "                item.y <= point[1] <= item.y + item.width and\n",
    "                item.z <= point[2] <= item.z + item.height):\n",
    "                removed_points.append(point)\n",
    "\n",
    "        # Identify added points\n",
    "        added_points = [\n",
    "            (item.x + item.length, item.y, item.z),  \n",
    "            (item.x, item.y + item.width, item.z),  \n",
    "            (item.x, item.y, item.z + item.height),  \n",
    "            (item.x + item.length, item.y + item.width, item.z),  \n",
    "            (item.x + item.length, item.y, item.z + item.height),  \n",
    "            (item.x, item.y + item.width, item.z + item.height), \n",
    "            (item.x + item.length, item.y + item.width, item.z + item.height),  #\n",
    "        ]\n",
    "\n",
    "        added_points_by_item = [point for point in added_points if point not in current_extreme_points]\n",
    "\n",
    "        return placed_items, added_points_by_item, removed_points\n",
    "    \n",
    "\n",
    "    def calculate_residual_space(self, ep, placed_items, j):\n",
    "        \"\"\"\n",
    "        Calculate the residual space in the ULD\n",
    "\n",
    "        Args:\n",
    "            ep (tuple): The extreme point to calculate the residual space from.\n",
    "            placed_items (dict): Dictionary of placed items.\n",
    "            j (ULD): The ULD to calculate the residual space for.\n",
    "        \"\"\"\n",
    "        # Initialize residual space in all directions\n",
    "        rs_left = ep[0]\n",
    "        rs_right = j.length - ep[0]\n",
    "        rs_front = ep[1]\n",
    "        rs_back = j.width - ep[1]\n",
    "        rs_up = j.height - ep[2]\n",
    "\n",
    "        for _, (x, y, z, length, width, height, _, _) in placed_items.items():\n",
    "            # Check space to the left\n",
    "            if x + length <= ep[0]:\n",
    "                rs_left = min(rs_left, ep[0] - (x + length))\n",
    "            \n",
    "            # Check space to the right\n",
    "            if x >= ep[0]:\n",
    "                rs_right = min(rs_right, x - ep[0])\n",
    "\n",
    "            # Check space in front\n",
    "            if y + width <= ep[1]:\n",
    "                rs_front = min(rs_front, ep[1] - (y + width))\n",
    "\n",
    "            # Check space in back\n",
    "            if y >= ep[1]:\n",
    "                rs_back = min(rs_back, y - ep[1])\n",
    "\n",
    "            # Check space above\n",
    "            if z >= ep[2]:\n",
    "                rs_up = min(rs_up, z - ep[2])\n",
    "\n",
    "        # Ensure that residual space is not negative\n",
    "        rs_left = max(rs_left, 0)\n",
    "        rs_right = max(rs_right, 0)\n",
    "        rs_front = max(rs_front, 0)\n",
    "        rs_back = max(rs_back, 0)\n",
    "        rs_up = max(rs_up, 0)\n",
    "\n",
    "        return rs_left, rs_right, rs_front, rs_back, rs_up\n",
    "\n",
    "    \n",
    "    def does_item_fit_uld(self, ep, orientation, j):\n",
    "        \"\"\"\n",
    "        Check if the item fits in the ULD\n",
    "\n",
    "        Args:\n",
    "            ep (tuple): The extreme point to place the item at.\n",
    "            orientation (tuple): The orientation of the item.\n",
    "            j (ULD): The ULD to check if the item fits in.\n",
    "        \"\"\"\n",
    "        return (ep[0] + orientation[0] <= j.length and\n",
    "                ep[1] + orientation[1] <= j.width and\n",
    "                ep[2] + orientation[2] <= j.height)\n",
    "\n",
    "\n",
    "    def find_best_next_item_and_placement(self, items, j, placed_items, extreme_points):\n",
    "        \"\"\"\n",
    "        Find the best next item and placement for this item in the ULD based on merit\n",
    "\n",
    "        Args:\n",
    "            item (Item): The item to find the best placement for.\n",
    "            j (ULD): The ULD to find the best placement for the item in.\n",
    "            placed_items (dict): Dictionary of placed items.\n",
    "            extreme_points (list): List of extreme points.\n",
    "        \"\"\"\n",
    "        best_overall_merit = float('inf')\n",
    "        best_item_for_placement = None\n",
    "        best_placement_details = None\n",
    "\n",
    "        stackables = [i for i in items if i.stack == 0]\n",
    "        non_stackables = [i for i in items if i.stack == 1]\n",
    "\n",
    "\n",
    "        for prioritized_group in [stackables, non_stackables]:\n",
    "            for item in prioritized_group:\n",
    "                best_merit_for_item = float('inf')\n",
    "                best_ep_for_item = None\n",
    "                best_orientation_for_item = None\n",
    "                best_support_count_for_item = float('inf')\n",
    "                item_defer_reason = 'No feasible placement found'\n",
    "\n",
    "                ground_eps = [ep for ep in extreme_points if ep[2] == 0]\n",
    "                non_ground_eps = [ep for ep in extreme_points if ep[2] != 0]\n",
    "            \n",
    "                def try_place(eps):\n",
    "                    nonlocal best_merit_for_item, best_ep_for_item, best_orientation_for_item, best_support_count_for_item, item_defer_reason\n",
    "                    for ep in eps:\n",
    "                        orientations = self.get_orientations(item)\n",
    "                        for orientation in orientations:\n",
    "                            length, width, height = orientation\n",
    "\n",
    "                            if not self.does_item_fit_uld(ep, orientation, j):\n",
    "                                item_defer_reason = 'item does not fit in ULD'\n",
    "                                continue\n",
    "\n",
    "                            rs_left, rs_right, rs_front, rs_back, rs_up = self.calculate_residual_space(ep, placed_items, j)\n",
    "                            \n",
    "                            if self.check_collision(ep, length, width, height, placed_items, item.stack):\n",
    "                                item_defer_reason = 'item collides with other items'\n",
    "                                continue\n",
    "                            \n",
    "                            # cut_merit = compute_cut_merit(ep, j)\n",
    "                            merit = (max(rs_left - length, 0) + max(rs_right - length, 0) +\n",
    "                                        max(rs_front - width, 0) + max(rs_back - width, 0) +\n",
    "                                        max(rs_up - height, 0))\n",
    "                                \n",
    "                            stable, support_count = self.is_fully_supported(ep, orientation, placed_items, j)\n",
    "                            if not stable:\n",
    "                                item_defer_reason = 'item is not fully supported'\n",
    "                                continue\n",
    "\n",
    "                            if stable and (merit < best_merit_for_item or (merit == best_merit_for_item and support_count > best_support_count_for_item)):\n",
    "                                best_merit_for_item = merit\n",
    "                                best_ep_for_item = ep\n",
    "                                best_orientation_for_item = orientation\n",
    "                                best_support_count_for_item = support_count\n",
    "                                item_defer_reason = ''\n",
    "\n",
    "                try_place(ground_eps)\n",
    "\n",
    "                if best_merit_for_item == float('inf'):\n",
    "                    try_place(non_ground_eps)\n",
    "\n",
    "                \n",
    "                if best_merit_for_item < best_overall_merit:\n",
    "                    best_overall_merit = best_merit_for_item\n",
    "                    best_item_for_placement = item\n",
    "                    best_placement_details = (best_ep_for_item, best_orientation_for_item, best_merit_for_item, best_support_count_for_item)\n",
    "\n",
    "        return best_item_for_placement, best_placement_details, item_defer_reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plot():\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    def BPP(self, cargo, results_1D_BPP, placed_items, extreme_points, color_map, folder_path):\n",
    "        \"\"\" \n",
    "        Plot 3D BPP\n",
    "\n",
    "        Args:\n",
    "            cargo (Cargo): The cargo object.\n",
    "            results_1D_BPP (dict): Dictionary of 1D BPP results.\n",
    "            placed_items (dict): Dictionary of placed items.\n",
    "            extreme_points (dict): Dictionary of extreme points.\n",
    "            color_map (dict): Dictionary of colors for items.\n",
    "            folder_path (str): The folder path to save the plots to.\n",
    "        \"\"\"\n",
    "        for j, items in results_1D_BPP.items():\n",
    "            uld_serial = j.serialnumber\n",
    "            fig = plt.figure(figsize=(10, 10))\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            ax.set_title(f'{uld_serial}', fontsize=15)\n",
    "        \n",
    "            #Plane Plot\n",
    "            plane_coords = [(j.a, 0, 0), (0, 0, j.b), (0, j.width, j.b), (j.a, j.width, 0)]\n",
    "            plane = Poly3DCollection([plane_coords], alpha=0.3, edgecolor='black', facecolor='black')\n",
    "            ax.add_collection3d(plane)\n",
    "\n",
    "            #Items Plot\n",
    "            for serialnumber in placed_items[j].keys():\n",
    "                item_info = placed_items[j][serialnumber]\n",
    "                prefix_serialnumber = str(serialnumber).split('-')[0] if '-' in str(serialnumber) else str(serialnumber)\n",
    "                item_color = color_map[prefix_serialnumber]\n",
    "                x, y, z, length, width, height, weight, stack = item_info\n",
    "                ax.bar3d(x, y, z, length, width, height, color = item_color, alpha=0.3, edgecolor='black')\n",
    "                ax.text(x + length / 2, y + width / 2, z + height / 2, f\"{serialnumber}\", fontsize=11, ha='center', va='center')\n",
    "\n",
    "            #Extreme Points Plot\n",
    "            for ep in extreme_points[j]:\n",
    "                ax.scatter(ep[0], ep[1], ep[2], color='red')\n",
    "\n",
    "            #Legend\n",
    "            placed_count = {}\n",
    "            prefix_groups = cargo.get_prefix_groups()\n",
    "\n",
    "            for serialnumber in placed_items[j].keys():\n",
    "                prefix_serialnumber = str(serialnumber).split('-')[0]\n",
    "                placed_count[prefix_serialnumber] = placed_count.get(prefix_serialnumber, 0) + 1\n",
    "\n",
    "            legend_patches = []\n",
    "            for serialnumber in placed_items[j].keys():\n",
    "                prefix_serialnumber = str(serialnumber).split('-')[0] if '-' in str(serialnumber) else str(serialnumber)\n",
    "                item_color = color_map[prefix_serialnumber]\n",
    "                label = f'{prefix_serialnumber}: {placed_count[prefix_serialnumber]}/{len(prefix_groups[prefix_serialnumber])}'\n",
    "                if item_color not in [patch.get_facecolor() for patch in legend_patches]:\n",
    "                        legend_patches.append(Patch(color = item_color, label = label ))\n",
    "\n",
    "            #Special Handeling Patches \n",
    "            COL_items = [i.serialnumber for i in items if i.COL == 1]\n",
    "            CRT_items = [i.serialnumber for i in items if i.CRT == 1]\n",
    "            stack_items = [i.serialnumber for i in items if i.stack == 1]\n",
    "\n",
    "            # patch_size_length = 20 \n",
    "            # patch_size_width = 20  \n",
    "            # patch_height = 0\n",
    "\n",
    "            for serialnumber in COL_items:\n",
    "                if serialnumber in placed_items[j]:\n",
    "                    item_info = placed_items[j][serialnumber]\n",
    "                    x, y, z, length, width, height, weight, stack = item_info\n",
    "                    patch_size_length = length * 0.1\n",
    "                    patch_size_width = width * 0.1  \n",
    "                    patch_height = 0\n",
    "                    fontsize = 10 \n",
    "                    patch_x = x\n",
    "                    patch_y = y + width - patch_size_width\n",
    "                    patch_z = z + height\n",
    "                    ax.bar3d(patch_x, patch_y, patch_z, patch_size_length, patch_size_width, patch_height, color='aqua', alpha=0.4, edgecolor='white')\n",
    "                    ax.text(patch_x + patch_size_length / 2, patch_y + patch_size_width / 2, patch_z, \"COL\", color='black', ha='center', va='center', weight = 'bold', fontsize=fontsize, alpha = 1)\n",
    "\n",
    "            for serialnumber in CRT_items:\n",
    "                if serialnumber in placed_items[j]:\n",
    "                    item_info = placed_items[j][serialnumber]\n",
    "                    x, y, z, length, width, height, weight, stack = item_info\n",
    "                    patch_size_length = length * 0.1\n",
    "                    patch_size_width = width * 0.1  \n",
    "                    patch_height = 0\n",
    "                    fontsize = 10\n",
    "                    patch_x = x\n",
    "                    patch_y = y + width - patch_size_width\n",
    "                    patch_z = z + height\n",
    "                    ax.bar3d(patch_x, patch_y, patch_z, patch_size_length, patch_size_width, patch_height, color='lime', alpha=0.4, edgecolor='white')\n",
    "                    ax.text(patch_x + patch_size_length / 2, patch_y + patch_size_width / 2, patch_z, \"CRT\", color='black', ha='center', va='center', weight = 'bold', fontsize=fontsize, alpha = 1)\n",
    "\n",
    "\n",
    "            for serialnumber in stack_items:\n",
    "                if serialnumber in placed_items[j]:\n",
    "                    item_info = placed_items[j][serialnumber]\n",
    "                    x, y, z, length, width, height, weight, stack = item_info\n",
    "                    patch_size_length = length * 0.1\n",
    "                    patch_size_width = width * 0.1  \n",
    "                    patch_height = 0\n",
    "                    fontsize = 10\n",
    "                    patch_x = x\n",
    "                    patch_y = y + width - patch_size_width\n",
    "                    patch_z = z + height\n",
    "                    ax.bar3d(patch_x, patch_y, patch_z, patch_size_length, patch_size_width, patch_height, color='gold', alpha=0.4, edgecolor='white')\n",
    "                    ax.text(patch_x + patch_size_length / 2, patch_y + patch_size_width / 2, patch_z, \"STK\", color='black', ha='center', va='center', weight = 'bold', fontsize=fontsize, alpha = 1)\n",
    "\n",
    "            #Axis and Limit Plot\n",
    "            ax.set_xlabel('Length [cm]', fontsize=11)\n",
    "            ax.set_ylabel('Width [cm]', fontsize=11)\n",
    "            ax.set_zlabel('Height [cm]', fontsize=11)\n",
    "            ax.set_xlim(0, j.length)\n",
    "            ax.set_ylim(0, j.width)\n",
    "            ax.set_zlim(0, j.height)\n",
    "            ax.legend(handles=legend_patches, title=\"Serialnumbers\", bbox_to_anchor=(1.05, 1))\n",
    "            ax.set_box_aspect([1, 1, 1])\n",
    "\n",
    "            save_path = os.path.join(folder_path, f'{uld_serial}.png')\n",
    "            plt.savefig(save_path, bbox_inches='tight')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    def WB(self, aircraft, ZFW_index, TOW_index, folder_path):\n",
    "        \"\"\" \n",
    "        Plot CG Envelope\n",
    "\n",
    "        Args:\n",
    "            aircraft (Aircraft): The aircraft to plot the CG envelope for.\n",
    "            ZFW_index (float): The index for the Zero Fuel Weight.\n",
    "            TOW_index (float): The index for the Takeoff Weight.\n",
    "            folder_path (str): The folder path to save the plot.\n",
    "        \"\"\"\n",
    "\n",
    "        #Plotting the CG envelope for flight\n",
    "        index_axis_ZFW, weight_axis_ZFW = aircraft.define_axis_ZFW(aircraft.aircraft_type) \n",
    "        index_axis_TOW, weight_axis_TOW = aircraft.define_axis_TOW(aircraft.aircraft_type)\n",
    "        index_axis_LW, weight_axis_LW = aircraft.define_axis_LW(aircraft.aircraft_type) \n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 10)) \n",
    "\n",
    "        ax.plot(ZFW_index, aircraft.ZFW, marker='X', color='blue', label='ZFW')\n",
    "        ax.text(ZFW_index, aircraft.ZFW + 30, f'ZFW: {ZFW_index:.1f}', fontsize=8, ha = 'center', va='bottom', fontweight = 'bold')\n",
    "        ax.plot(aircraft.define_INDEX_ZFW_fwd(aircraft.aircraft_type), aircraft.ZFW, marker='_', color='blue', label='ZFW fwd')\n",
    "        ax.text(aircraft.define_INDEX_ZFW_fwd(aircraft.aircraft_type) - 10, aircraft.ZFW, f'ZFW fwd: {aircraft.define_INDEX_ZFW_fwd(aircraft.aircraft_type):.1f}', fontsize=8, ha='right', fontstyle = 'italic')\n",
    "        ax.plot(aircraft.define_INDEX_ZFW_aft(aircraft.aircraft_type), aircraft.ZFW, marker='_', color='blue', label='ZFW aft')\n",
    "        ax.text(aircraft.define_INDEX_ZFW_aft(aircraft.aircraft_type) + 10, aircraft.ZFW, f'ZFW aft: {aircraft.define_INDEX_ZFW_aft(aircraft.aircraft_type):.1f}', fontsize=8, ha='left', fontstyle = 'italic')\n",
    "\n",
    "        ax.plot(TOW_index, aircraft.TOW, marker='D', color='red', label='TOW')\n",
    "        ax.text(TOW_index, aircraft.TOW + 30, f'TOW: {TOW_index:.1f}', fontsize=8, ha = 'center', va='bottom', fontweight = 'bold')\n",
    "        ax.plot(aircraft.define_INDEX_TOW_fwd(aircraft.aircraft_type), aircraft.TOW, marker='_', color='red', label='TOW fwd')\n",
    "        ax.text(aircraft.define_INDEX_TOW_fwd(aircraft.aircraft_type) - 5, aircraft.TOW, f'TOW fwd: {aircraft.define_INDEX_TOW_fwd(aircraft.aircraft_type):.1f}', fontsize=8, ha='right', fontstyle = 'italic')\n",
    "        ax.plot(aircraft.define_INDEX_TOW_aft(aircraft.aircraft_type), aircraft.TOW, marker='_', color='red', label='TOW aft')\n",
    "        ax.text(aircraft.define_INDEX_TOW_aft(aircraft.aircraft_type) + 5, aircraft.TOW, f'TOW aft: {aircraft.define_INDEX_TOW_aft(aircraft.aircraft_type):.1f}', fontsize=8, ha='left', fontstyle = 'italic')\n",
    "\n",
    "        ax.plot(aircraft.define_INDEX_LW(ZFW_index), aircraft.LW, marker='s', color='green', label='LW')\n",
    "        ax.text(aircraft.define_INDEX_LW(ZFW_index), aircraft.LW + 30, f'LW: {aircraft.define_INDEX_LW(ZFW_index):.1f}', fontsize=8, ha = 'center', va='bottom', fontweight = 'bold')\n",
    "        ax.plot(aircraft.define_INDEX_LW_fwd(aircraft.aircraft_type), aircraft.LW, marker='_', color='green', label='LW fwd')\n",
    "        ax.text(aircraft.define_INDEX_LW_fwd(aircraft.aircraft_type) - 10, aircraft.LW, f'LW fwd: {aircraft.define_INDEX_LW_fwd(aircraft.aircraft_type):.1f}', fontsize=8, ha='right', fontstyle = 'italic')\n",
    "        ax.plot(aircraft.define_INDEX_LW_aft(aircraft.aircraft_type), aircraft.LW, marker='_', color='green', label='LW aft')\n",
    "        ax.text(aircraft.define_INDEX_LW_aft(aircraft.aircraft_type) + 10, aircraft.LW, f'LW aft: {aircraft.define_INDEX_LW_aft(aircraft.aircraft_type):.1f}', fontsize=8, ha='left', fontstyle = 'italic')\n",
    "\n",
    "        ax.plot(index_axis_ZFW, weight_axis_ZFW, linestyle='-', color='blue', label='ZFW')\n",
    "        ax.plot(index_axis_TOW, weight_axis_TOW, linestyle='-', color='red', label='TOW')\n",
    "        ax.plot(index_axis_LW, weight_axis_LW, linestyle='-', color='green', label='LW')\n",
    "\n",
    "        ax.set_xlim(0, 200)\n",
    "        if aircraft.aircraft_type == '789' and aircraft.aircraft_type == '781':\n",
    "            ax.set_ylim(100000, 300000)\n",
    "\n",
    "        elif aircraft.aircraft_type == '77W':\n",
    "            ax.set_ylim(100000, 400000)\n",
    "\n",
    "        elif aircraft.aircraft_type == '772':\n",
    "            ax.set_y_lim(100000, 350000)\n",
    "\n",
    "        ax.set_xlabel('Index', fontsize=11)\n",
    "        ax.set_ylabel('Weight [kg]', fontsize=11)\n",
    "        ax.set_title('CG Envelope', fontsize=15)\n",
    "\n",
    "        ax.grid(axis='y', linestyle='--', color='gray', alpha=0.7)\n",
    "\n",
    "        save_path = os.path.join(folder_path, f'CG_envelope.png')\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectSetup:\n",
    "    def __init__(self) -> None:\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def setup_logger(self, directory_path, log_filename='General_Information.txt'):\n",
    "        \"\"\"\n",
    "        Setup the logger\n",
    "\n",
    "        Args:\n",
    "            directory_path (str): The directory path to save the log file.\n",
    "            log_filename (str): The name of the log file.\n",
    "        \"\"\"\n",
    "        log_file_path = os.path.join(directory_path, log_filename)\n",
    "        \n",
    "        # Clear any existing handlers\n",
    "        self.logger.handlers = []\n",
    "        \n",
    "        # Create a file handler for writing to file\n",
    "        file_handler = logging.FileHandler(log_file_path, 'w')\n",
    "        file_formatter = logging.Formatter('%(message)s')\n",
    "        file_handler.setFormatter(file_formatter)\n",
    "        self.logger.addHandler(file_handler)\n",
    "        \n",
    "        # Create a stream handler for printing to console\n",
    "        stream_handler = logging.StreamHandler(sys.stdout)\n",
    "        stream_formatter = logging.Formatter('%(message)s')\n",
    "        stream_handler.setFormatter(stream_formatter)\n",
    "        self.logger.addHandler(stream_handler)\n",
    "        \n",
    "        self.logger.setLevel(logging.INFO)\n",
    "\n",
    "    def setup_project_directory(self, flight_number, date, departure, arrival, baseline, optimized_actual, BAX_fixed=False):\n",
    "        \"\"\" \n",
    "        Setup the project directory\n",
    "\n",
    "        Args:\n",
    "            flight_number (str): The flight number.\n",
    "            date (str): The date of the flight.\n",
    "            departure (str): The departure airport.\n",
    "            arrival (str): The arrival airport.\n",
    "        \"\"\"\n",
    "        ## esto antes estaba con los paths de windows, los tuve que cambiar para que funcione en mac, asi como estos son 26 paths mas\n",
    "        if baseline:\n",
    "            base_path = 'Results_Baseline'  # Changed from Windows path\n",
    "        if optimized_actual:\n",
    "            base_path = 'Results_Optimized_Actual'  # Changed from Windows path\n",
    "        if BAX_fixed:\n",
    "            base_path = 'Results_BAX_Fixed'  # Changed from Windows path\n",
    "        if not baseline and not optimized_actual and not BAX_fixed:\n",
    "            base_path = 'Results'  # Changed from Windows path\n",
    "\n",
    "        date_split = date.split(' ')\n",
    "        folder_name = f'Results {departure}{arrival} {date_split[1]} 20{date_split[2]}'\n",
    "\n",
    "        base_path = os.path.join(base_path, folder_name)\n",
    "        directory_name = f\"Flight {flight_number} {departure}{arrival} {date}\"\n",
    "        full_path = os.path.join(base_path, directory_name)\n",
    "\n",
    "        if not os.path.exists(full_path):\n",
    "            os.makedirs(full_path)\n",
    "        return full_path\n",
    "    \n",
    "    def setup_project(self, piece_information_csv, flight_information_csv, load_locations_csv, pax_information_csv, buildup_information_csv, arrival_airport, restricted_locations, baseline = False, optimized_actual = False, BAX_fixed = False):\n",
    "        \"\"\"\n",
    "        Setup the project\n",
    "\n",
    "        Args:\n",
    "            piece_information_csv (str): The path to the piece information csv file.\n",
    "            flight_information_csv (str): The path to the flight information xlsx file.\n",
    "            load_locations_csv (str): The path to the load locations xlsx file.\n",
    "            pax_information_csv (str): The path to the pax information csv file.\n",
    "        \"\"\"\n",
    "        data_analysis = Data_Analysis()\n",
    "        if optimized_actual:\n",
    "            cargo = CargoActual()\n",
    "        if not optimized_actual:\n",
    "            cargo = Cargo() # ver la diff \n",
    "        aircraft = Aircraft()\n",
    "        EP = Extreme_Points()\n",
    "        plot = Plot()\n",
    "        \n",
    "        cargo.read_cargo_pieces(piece_information_csv, buildup_information_csv, arrival_airport)\n",
    "        aircraft.define_flight_information(flight_information_csv)\n",
    "        \n",
    "        #tambien cambie esto para q los paths sean relativos:\n",
    "        aircraft.define_aircraft('Inputfiles/LoadLocations.csv', aircraft.aircraft_type, restricted_locations)  # Changed from Windows path\n",
    "        aircraft.define_fuel_index('Inputfiles/Fuel_Index.csv', aircraft.aircraft_type)  # Changed from Windows path\n",
    "        aircraft.define_max_weight_information('Inputfiles/Main.csv', aircraft.aircraft_type)  # Changed from Windows path\n",
    "        aircraft.define_DOI('Inputfiles/Dry_Operating_Index.csv', aircraft.aircraft_type)  # Changed from Windows path\n",
    "        aircraft.define_envelope_information(aircraft.aircraft_type)\n",
    "        aircraft.define_PAX_allocation(pax_information_csv)\n",
    "\n",
    "        cargo.define_ulds_used_flight(load_locations_csv, buildup_information_csv)\n",
    "        cargo.define_parameters_ULD()\n",
    "        cargo.define_uld_cut_sets()\n",
    "        cargo.total_number_of_build_ULDs = len([j for j in cargo.uld if j.isNeitherBAXnorBUPnorT])\n",
    "\n",
    "        items_not_fit = [item for item in cargo.items if not any(item.length <= j.length and item.width <= j.width and item.height <= j.height for j in cargo.uld)]\n",
    "        total_items = len(cargo.items)\n",
    "        \n",
    "        aircraft.ZFW = aircraft.OEW + sum([i.weight for i in cargo.items]) + sum([j.weight for j in cargo.uld if j.isBAXorBUPorT]) + aircraft.define_PAX_weight() - sum([i.weight for i in items_not_fit])\n",
    "        aircraft.TOW = aircraft.ZFW + aircraft.TOF\n",
    "        aircraft.LW = aircraft.TOW - aircraft.TripF\n",
    "\n",
    "        number_of_BAX_ULDs = len([j for j in cargo.uld if j.isBAX])\n",
    "        number_of_BUP_ULDs = len([j for j in cargo.uld if 'BUP' in j.serialnumber])\n",
    "        number_of_T_ULDs = len([j for j in cargo.uld if 'T' in j.serialnumber])\n",
    "        number_of_cargo_ULDs = len([j for j in cargo.uld if j.isNeitherBAXnorBUPnorT])\n",
    "\n",
    "        directory_path = self.setup_project_directory(aircraft.flight_number, aircraft.date, aircraft.departure_airport, aircraft.arrival_airport, baseline, optimized_actual, BAX_fixed)\n",
    "        self.setup_logger(directory_path)\n",
    "\n",
    "        '''Print Statements'''\n",
    "        self.logger.info('The model will run the following flight:')\n",
    "        self.logger.info('--------------------------------------------------------------------------------------------------------')\n",
    "        self.logger.info(f'Flight Number: {aircraft.flight_number} {aircraft.aircraft_registration} - Aircraft Type: {aircraft.aircraft_type} - Departure: {aircraft.departure_airport} - Arrival: {aircraft.arrival_airport} - Date: {aircraft.date}')\n",
    "        self.logger.info('')\n",
    "        self.logger.info(f'ZFW: {aircraft.ZFW:.1f} kg - TOW: {aircraft.TOW:.1f} kg - LW: {aircraft.LW:.1f} kg - OEW: {aircraft.OEW:.1f} kg')\n",
    "        self.logger.info('')\n",
    "        self.logger.info(f'Fuel: {aircraft.TOF} kg - Trip Fuel: {aircraft.TripF} kg')\n",
    "        self.logger.info('')\n",
    "        self.logger.info(f'Number of Cargo ULDs used: {number_of_cargo_ULDs}')\n",
    "        self.logger.info('')\n",
    "        self.logger.info(f'Number of BAX ULDs: {number_of_BAX_ULDs} - Number of BUP ULDs: {number_of_BUP_ULDs} - Number of T ULDs: {number_of_T_ULDs}')\n",
    "        self.logger.info('--------------------------------------------------------------------------------------------------------')\n",
    "        self.logger.info('ULD set available for loading:')\n",
    "        for j in cargo.uld:\n",
    "            if j.isNeitherBAXnorBUPnorT:\n",
    "                self.logger.info(f'{j.serialnumber}, {j.type}')\n",
    "\n",
    "        self.logger.info('--------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "        self.logger.info('BAX and BUP set for loading:')\n",
    "        for j in cargo.uld:   \n",
    "            if j.isBAXorBUPorT:\n",
    "                self.logger.info(f'{j.serialnumber}, {j.type}')\n",
    "        self.logger.info('--------------------------------------------------------------------------------------------------------')\n",
    "        self.logger.info('PAX allocation:')\n",
    "        self.logger.info(f'PAX-A: {aircraft.pax_0A}')\n",
    "        self.logger.info(f'PAX-B: {aircraft.pax_0B}')\n",
    "        self.logger.info(f'PAX-C: {aircraft.pax_0C}')\n",
    "        self.logger.info(f'PAX-D: {aircraft.pax_0D}')\n",
    "        self.logger.info(f'PAX-E: {aircraft.pax_0E}')\n",
    "        self.logger.info(f'PAX-F: {aircraft.pax_0F}')\n",
    "        self.logger.info(f'PAX-G: {aircraft.pax_0G}')\n",
    "        self.logger.info(f'Total PAX: {aircraft.total_PAX}')\n",
    "        self.logger.info('--------------------------------------------------------------------------------------------------------')\n",
    "        self.logger.info('Check if all items fit the ULDs dimensions:')\n",
    "        if items_not_fit:\n",
    "            self.logger.info('--------------------------------------------------------------------------------------------------------')\n",
    "            self.logger.info('The following items do not fit the dimensions of the ULDs:')\n",
    "            for item in items_not_fit:\n",
    "                self.logger.info(f'Serialnumber: {item.serialnumber}')\n",
    "                self.logger.info(f'Dimensions: {item.length, item.width, item.height}')\n",
    "                cargo.items.remove(item)\n",
    "            self.logger.info('--------------------------------------------------------------------------------------------------------')\n",
    "        self.logger.info('')\n",
    "        self.logger.info(f'{len(cargo.items)} / {total_items} items fit the dimensions of the ULDs')\n",
    "        self.logger.info('--------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "        return cargo, aircraft, EP, plot, data_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataExtraction():\n",
    "    def __init__(self):\n",
    "        self.df_flight_details = 'Inputfiles/FlightDetailsSpotfire.csv'  # Changed from Windows path\n",
    "        self.df_load_locations = 'Inputfiles/LoadLocationsSpotfire.csv'  # Changed from Windows path\n",
    "        self.df_piece_information = 'Inputfiles/PieceInformationSpotfire.csv'  # Changed from Windows path\n",
    "        self.df_pax_information = 'Inputfiles/PaxInformationSpotfire.csv'  # Changed from Windows path\n",
    "        self.df_buildup_information = 'Inputfiles/BuildUpInformationSpotfire.csv'  # Changed from Windows path\n",
    "    def custom_date_parser(self, date_string):\n",
    "        \"\"\"\n",
    "        Parses date strings that are in either 'd/m/YYYY' or 'd-m-YYYY' format.\n",
    "\n",
    "        Args:\n",
    "            date_string (str): The date string to parse.\n",
    "\n",
    "        Returns:\n",
    "            datetime: The parsed date as a datetime object.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return datetime.strptime(date_string, '%d/%m/%Y')\n",
    "        except ValueError:\n",
    "            return datetime.strptime(date_string, '%d-%m-%Y')\n",
    "        \n",
    "        \n",
    "    def standardize_decimal(self, value):\n",
    "        if isinstance(value, str):\n",
    "            cleaned_value = value.replace(',', '.')\n",
    "            try:\n",
    "                return float(cleaned_value)\n",
    "            except ValueError:\n",
    "                pass \n",
    "        return value\n",
    "    \n",
    "        \n",
    "    def setup_project_directory(self, flight_number, date, departure, arrival):\n",
    "        \"\"\" \n",
    "        Setup the project directory\n",
    "\n",
    "        Args:\n",
    "            flight_number (str): The flight number.\n",
    "            date (str): The date of the flight.\n",
    "            departure (str): The departure airport.\n",
    "            arrival (str): The arrival airport.\n",
    "        \"\"\"\n",
    "\n",
    "        base_path = 'Data_Common_102' ## lo cambie yo\n",
    "        date_split = date.split(' ')\n",
    "        folder_name = f'Flights {departure}{arrival} {date_split[1]} {date_split[2]}'\n",
    "\n",
    "        base_path = os.path.join(base_path, folder_name)\n",
    "        directory_name = f\"Flight {flight_number} {departure}{arrival} {date}\"\n",
    "        full_path = os.path.join(base_path, directory_name)\n",
    "        if not os.path.exists(full_path):\n",
    "            os.makedirs(full_path)\n",
    "        return full_path\n",
    "    \n",
    "\n",
    "    def extract_individual_flight_details(self):\n",
    "        \"\"\" \n",
    "        Extract the flight details data from spotfire csv file\n",
    "        \"\"\"\n",
    "        flight_details_data = pd.read_csv(self.df_flight_details, parse_dates=['LegDepartureDateUtc'], date_parser = self.custom_date_parser)\n",
    "        flight_details_data['MacZFW'] = flight_details_data['MacZFW'].apply(lambda x: round(float(str(x).replace(',', '')) / 10**7, 1))\n",
    "        unique_flights = flight_details_data.drop_duplicates(subset=['FlightNumber', 'LegDepartureDateUtc', 'DepartureAirport', 'ArrivalAirport'])\n",
    "\n",
    "        for index, flight in unique_flights.iterrows():\n",
    "            flight_number = flight['FlightNumber']\n",
    "            flight_number_folder = f'KL0{flight_number}'\n",
    "            date = flight['LegDepartureDateUtc']\n",
    "            date_folder = date.strftime('%d %b %Y').upper()\n",
    "            departure = flight['DepartureAirport']\n",
    "            arrival = flight['ArrivalAirport']    \n",
    "\n",
    "            directory = self.setup_project_directory(flight_number_folder, date_folder, departure, arrival)\n",
    "            \n",
    "            flight_details = flight_details_data[(flight_details_data['FlightNumber'] == flight_number) & \n",
    "                                                 (flight_details_data['LegDepartureDateUtc'] == date) &\n",
    "                                                 (flight_details_data['DepartureAirport'] == departure) & \n",
    "                                                 (flight_details_data['ArrivalAirport'] == arrival)]\n",
    "            \n",
    "            flight_details.to_csv(os.path.join(directory, 'FlightInformation.csv'), index=False)\n",
    "\n",
    "\n",
    "    def extract_individual_load_locations(self):\n",
    "        \"\"\" \n",
    "        Extract the load locations data from spotfire csv file\n",
    "        \"\"\"\n",
    "        load_locations_data = pd.read_csv(self.df_load_locations)\n",
    "        unique_flights = load_locations_data.drop_duplicates(subset=['FlightLegDepartureKey'])\n",
    "\n",
    "        for index, flight in unique_flights.iterrows():\n",
    "            parts = flight['FlightLegDepartureKey'].split('|')\n",
    "            flight_number = parts[2]\n",
    "            flight_number_folder = f'KL{flight_number}'\n",
    "            date = pd.to_datetime(parts[0])\n",
    "            date_folder = date.strftime('%d %b %Y').upper()\n",
    "            departure = flight['DeadloadOrigin']\n",
    "            arrival = flight['DeadloadDestination']\n",
    "\n",
    "            load_locations = load_locations_data[load_locations_data['FlightLegDepartureKey'] == flight['FlightLegDepartureKey']]\n",
    "\n",
    "            directory = self.setup_project_directory(flight_number_folder, date_folder, departure, arrival)            \n",
    "            load_locations.to_csv(os.path.join(directory, 'LoadLocations.csv'), index=False)\n",
    "\n",
    "    def extract_individual_piece_information(self):\n",
    "        \"\"\" \n",
    "        Extract the piece information data from spotfire csv file\n",
    "        \"\"\"\n",
    "        converters = {'BookingTotalVolume': self.standardize_decimal,\n",
    "                'BookingTotalWeight': self.standardize_decimal,\n",
    "                'BookingSegmentVolume': self.standardize_decimal,\n",
    "                'BookingSegmentWeight': self.standardize_decimal,\n",
    "                'BookingSegmentPiecesVolume': self.standardize_decimal,\n",
    "                'BookingSegmentPiecesWeight': self.standardize_decimal,\n",
    "                'BookingLinePieceVolume': self.standardize_decimal,\n",
    "                'BookingLinePieceWeight': self.standardize_decimal,\n",
    "                'BookingLinePieceHeight': self.standardize_decimal,\n",
    "                'BookingLinePieceWidth': self.standardize_decimal,\n",
    "                'BookingLinePieceLength': self.standardize_decimal\n",
    "                }\n",
    "        piece_information_data = pd.read_csv(self.df_piece_information, parse_dates = ['BookingSegmentFlightDateLT'], date_parser = self.custom_date_parser, converters=converters)\n",
    "        unique_flights = piece_information_data.drop_duplicates(subset=['BookingSegmentFlightNumber', 'BookingSegmentFlightDateLT',\n",
    "                                                                        'BookingSegmentBoardPointStationCode', 'BookingSegmentOffPointStationCode'])\n",
    "\n",
    "        for index, flight in unique_flights.iterrows():\n",
    "            flight_number = flight['BookingSegmentFlightNumber']\n",
    "            flight_number_folder = f'KL0{flight_number}'\n",
    "            date = pd.to_datetime(flight['BookingSegmentFlightDateLT'])\n",
    "            date_folder = date.strftime('%d %b %Y').upper()\n",
    "            departure = flight['BookingSegmentBoardPointStationCode']\n",
    "            arrival = flight['BookingSegmentOffPointStationCode']\n",
    "\n",
    "            piece_information = piece_information_data[(piece_information_data['BookingSegmentFlightNumber'] == flight_number) &\n",
    "                                                       (piece_information_data['BookingSegmentFlightDateLT'] == flight['BookingSegmentFlightDateLT']) &\n",
    "                                                       (piece_information_data['BookingSegmentBoardPointStationCode'] == departure) &\n",
    "                                                       (piece_information_data['BookingSegmentOffPointStationCode'] == arrival)]\n",
    "\n",
    "\n",
    "            directory = self.setup_project_directory(flight_number_folder, date_folder, departure, arrival)            \n",
    "            piece_information.to_csv(os.path.join(directory, 'PieceInformation.csv'), index=False)\n",
    "\n",
    "    def extract_individual_pax_information(self):\n",
    "        \"\"\" \n",
    "        Extract the pax information data from spotfire csv file\n",
    "        \"\"\"\n",
    "        pax_information_data = pd.read_csv(self.df_pax_information, parse_dates=['LocalDepartureDate'], date_parser = self.custom_date_parser)\n",
    "        unique_flights = pax_information_data.drop_duplicates(subset=['FlightNumber', 'LocalDepartureDate', 'DepartureAirport', 'SegmentArrivalAirport'])\n",
    "\n",
    "        for index, flight in unique_flights.iterrows():\n",
    "            flight_number = flight['FlightNumber']\n",
    "            flight_number_folder = f'KL0{flight_number}'\n",
    "            date = pd.to_datetime(flight['LocalDepartureDate'])\n",
    "            date_folder = date.strftime('%d %b %Y').upper()\n",
    "            departure = flight['DepartureAirport']\n",
    "            arrival = flight['SegmentArrivalAirport']\n",
    "\n",
    "            pax_information = pax_information_data[(pax_information_data['FlightNumber'] == flight_number) &\n",
    "                                                   (pax_information_data['LocalDepartureDate'] == flight['LocalDepartureDate']) &\n",
    "                                                   (pax_information_data['DepartureAirport'] == departure) &\n",
    "                                                   (pax_information_data['SegmentArrivalAirport'] == arrival)]\n",
    "\n",
    "            directory = self.setup_project_directory(flight_number_folder, date_folder, departure, arrival)            \n",
    "            pax_information.to_csv(os.path.join(directory, 'PaxInformation.csv'), index=False)\n",
    "\n",
    "    def extract_individual_buildup_information(self):\n",
    "        \"\"\"  \n",
    "        Extract the buildup information data from spotfire csv file\n",
    "        \"\"\"\n",
    "        converters = {'TotalWeightOnAWB': self.standardize_decimal}\n",
    "\n",
    "        buildup_information_data = pd.read_csv(self.df_buildup_information, parse_dates=['DepartureFlightDate'], date_parser = self.custom_date_parser, converters=converters)\n",
    "        unique_flights = buildup_information_data.drop_duplicates(subset=['DepartureFlightNumber', 'DepartureFlightDate'])\n",
    "\n",
    "        for index, flight in unique_flights.iterrows():\n",
    "            flight_number = flight['DepartureFlightNumber']\n",
    "            flight_number_folder = f'KL0{flight_number}'\n",
    "            date = pd.to_datetime(flight['DepartureFlightDate'])\n",
    "            date_folder = date.strftime('%d %b %Y').upper()\n",
    "            arrival_airport = flight['DestinationStationCode']\n",
    "\n",
    "            buildup_information = buildup_information_data[(buildup_information_data['DepartureFlightNumber'] == flight_number) &\n",
    "                                                           (buildup_information_data['DepartureFlightDate'] == flight['DepartureFlightDate'])]\n",
    "\n",
    "            directory = self.setup_project_directory(flight_number_folder, date_folder, 'AMS', arrival_airport)            \n",
    "            buildup_information.to_csv(os.path.join(directory, 'BuildUpInformation.csv'), index=False)\n",
    "\n",
    "    def delete_incorrect_folders(self):\n",
    "        \"\"\" \n",
    "        Delete the incorrect folders that do not contain the 3 files\n",
    "        \"\"\"\n",
    "        base_path = 'Data_Common_102'\n",
    "        required_files = ['FlightInformation.csv', 'LoadLocations.csv', 'PieceInformation.csv', 'PaxInformation.csv', 'BuildUpInformation.csv']\n",
    "\n",
    "        for months_folder in os.listdir(base_path):\n",
    "            months_folder_path = os.path.join(base_path, months_folder)\n",
    "            if not os.path.isdir(months_folder_path):\n",
    "                continue\n",
    "            for flight_folder in os.listdir(months_folder_path):\n",
    "                folder_path = os.path.join(months_folder_path, flight_folder)\n",
    "                if not os.path.isdir(folder_path):\n",
    "                    continue\n",
    "                if not all(os.path.exists(os.path.join(folder_path, file_name)) for file_name in required_files):\n",
    "                    shutil.rmtree(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilterData():\n",
    "    def __init__(self):\n",
    "        self.base_dir = 'Data_Common_102'  # Using relative path\n",
    "\n",
    "    def per_month(self, departure_airport, arrival_airport, month, year):\n",
    "        \"\"\"\n",
    "        Run the model for a specific month\n",
    "\n",
    "        Args:\n",
    "            departure_airport (str): The departure airport.\n",
    "            arrival_airport (str): The arrival airport.\n",
    "            month (str): The month to run the model for.\n",
    "            year (str): The year to run the model for.\n",
    "        \"\"\"\n",
    "        month = month.capitalize()\n",
    "        year = str(year)\n",
    "        month_folder_name = f'Flights {departure_airport}{arrival_airport} {month} {year}'\n",
    "\n",
    "        month_folder = os.path.join(self.base_dir, month_folder_name)\n",
    "        pattern = os.path.join(month_folder, 'Flight *')\n",
    "\n",
    "        flights = glob.glob(pattern)\n",
    "\n",
    "        print(f'{len(flights)} flights found for {departure_airport} to {arrival_airport} in {month} {year}')\n",
    "        print('========================================================================================================')\n",
    "\n",
    "        return flights\n",
    "    \n",
    "    def per_flight(self, flight_number, departure_airport, arrival_airport, day, month, year):\n",
    "        \"\"\"   \n",
    "        Run the model for a specific flight\n",
    "\n",
    "        Args:\n",
    "            flight_number (str): The flight number.\n",
    "            departure_airport (str): The departure airport.\n",
    "            arrival_airport (str): The arrival airport.\n",
    "            day (str): The day of the flight.\n",
    "            month (str): The month of the flight.\n",
    "            year (str): The year of the flight.\n",
    "        \"\"\"\n",
    "\n",
    "        month = month.upper()\n",
    "        year = str(year)\n",
    "        flight_number = str(flight_number)\n",
    "        day = str(day)\n",
    "        month_folder_name = f'Flights {departure_airport}{arrival_airport} {month} {year}'\n",
    "        flight_folder_name = f'Flight {flight_number} {departure_airport}{arrival_airport} {day} {month} {year}'\n",
    "\n",
    "        flight_folder = os.path.join(self.base_dir, month_folder_name, flight_folder_name)\n",
    "        print(f'Running the model for Flight {flight_number} {departure_airport}{arrival_airport} {day} {month} {year}')\n",
    "        print('========================================================================================================')\n",
    "\n",
    "        return flight_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultsReader():\n",
    "    def __init__(self, departure_airport = None, arrival_airport = None, month = None, year = None):\n",
    "        self.departure_airport = departure_airport\n",
    "        self.arrival_airport = arrival_airport\n",
    "        self.month = month\n",
    "        self.year = year\n",
    "        self.aircraft_type = None\n",
    "        self.aircraft_registration = None\n",
    "        self.fuel_reduction_percentage = 0\n",
    "        self.fuel_reduction_kg = 0\n",
    "        self.uld_built_by_model = 0\n",
    "        self.uld_actually_used = 0\n",
    "        self.total_run_time = 0\n",
    "        self.total_1D_BPP_WB_time = 0\n",
    "        self.total_3D_BPP_time = 0\n",
    "        self.MAC = 0\n",
    "        self.MAC_actual = 0\n",
    "        self.TOW = 0\n",
    "\n",
    "    def read_all_results(self):\n",
    "        \"\"\"\n",
    "        Read all the results from the results folder\n",
    "        \"\"\"\n",
    "        results = []\n",
    "\n",
    "        base_dir = 'Results'\n",
    "\n",
    "        for root, dirs, files in os.walk(base_dir):\n",
    "            for dir_name in dirs:\n",
    "                if dir_name.startswith('Results '):  # Check if directory name starts with 'Results'\n",
    "                    full_path = os.path.join(root, dir_name)\n",
    "                    pattern = os.path.join(full_path, 'Flight *')\n",
    "                    flights = glob.glob(pattern)\n",
    "\n",
    "                    for flight in flights:\n",
    "                        result = self.read_individual_flight_results(flight)\n",
    "                        if result:\n",
    "                            results.append(result)\n",
    "        \n",
    "        df = pd.DataFrame(results)\n",
    "\n",
    "        sum_data = {\n",
    "            'Flight Number': 'Total',\n",
    "            'Flight Date': '-',\n",
    "            'Fuel Deviation Percentage': '-',\n",
    "            'Fuel Deviation': df['Fuel Deviation'].sum(),\n",
    "            'TOW': df['TOW'].sum(),\n",
    "            'ULDs Built by Model': df['ULDs Built by Model'].sum(),\n",
    "            'ULDs Actually Used': df['ULDs Actually Used'].sum(),\n",
    "            '%MAC ZFW': '-',\n",
    "            'Actual %MAC ZFW': '-',\n",
    "            'Total Run Time': df['Total Run Time'].sum(),\n",
    "            'Total 1D BPP WB Time': df['Total 1D BPP WB Time'].sum(),\n",
    "            'Total 3D BPP Time': df['Total 3D BPP Time'].sum(),\n",
    "            'Number of BAX ULDs': df['Number of BAX ULDs'].sum(),\n",
    "            'Number of BUP ULDs': df['Number of BUP ULDs'].sum(),\n",
    "            'Number of T ULDs': df['Number of T ULDs'].sum(),\n",
    "            'Number of PAX A': '-',\n",
    "            'Number of PAX B': '-',\n",
    "            'Number of PAX C': '-',\n",
    "            'Number of PAX D': '-',\n",
    "            'Number of PAX E': '-',\n",
    "            'Number of PAX F': '-',\n",
    "            'Number of PAX G': '-',\n",
    "            'Total PAX': '-',\n",
    "            'Number of items': df['Number of items'].sum(),\n",
    "            'Weight in Comp 1': df['Weight in Comp 1'].sum(),\n",
    "            'Weight in Comp 2': df['Weight in Comp 2'].sum(),\n",
    "            'Weight in Comp 3': df['Weight in Comp 3'].sum(),\n",
    "            'Weight in Comp 4': df['Weight in Comp 4'].sum(),\n",
    "            'Number of ULDs in Comp 1': df['Number of ULDs in Comp 1'].sum(),\n",
    "            'Number of BAX ULDs in Comp 1': df['Number of BAX ULDs in Comp 1'].sum(),\n",
    "            'Weight ULDs in Comp 1': df['Weight ULDs in Comp 1'].sum(),\n",
    "            'Weight BAX ULDs in Comp 1': df['Weight BAX ULDs in Comp 1'].sum(),\n",
    "            'Number of ULDs in Comp 2': df['Number of ULDs in Comp 2'].sum(),\n",
    "            'Number of BAX ULDs in Comp 2': df['Number of BAX ULDs in Comp 2'].sum(),\n",
    "            'Weight ULDs in Comp 2': df['Weight ULDs in Comp 2'].sum(),\n",
    "            'Weight BAX ULDs in Comp 2': df['Weight BAX ULDs in Comp 2'].sum(),\n",
    "            'Number of ULDs in Comp 3': df['Number of ULDs in Comp 3'].sum(),\n",
    "            'Number of BAX ULDs in Comp 3': df['Number of BAX ULDs in Comp 3'].sum(),\n",
    "            'Weight ULDs in Comp 3': df['Weight ULDs in Comp 3'].sum(),\n",
    "            'Weight BAX ULDs in Comp 3': df['Weight BAX ULDs in Comp 3'].sum(),\n",
    "            'Number of ULDs in Comp 4': df['Number of ULDs in Comp 4'].sum(),\n",
    "            'Number of BAX ULDs in Comp 4': df['Number of BAX ULDs in Comp 4'].sum(),\n",
    "            'Weight ULDs in Comp 4': df['Weight ULDs in Comp 4'].sum(),\n",
    "            'Weight BAX ULDs in Comp 4': df['Weight BAX ULDs in Comp 4'].sum(),\n",
    "        }\n",
    "\n",
    "        average_data = {\n",
    "            'Flight Number': 'Average',\n",
    "            'Flight Date': '-',\n",
    "            'Fuel Deviation Percentage': df['Fuel Deviation Percentage'].mean(),\n",
    "            'Fuel Deviation': df['Fuel Deviation'].mean(),\n",
    "            'TOW': df['TOW'].mean(),\n",
    "            'ULDs Built by Model': df['ULDs Built by Model'].mean(),\n",
    "            'ULDs Actually Used': df['ULDs Actually Used'].mean(),\n",
    "            '%MAC ZFW': df['%MAC ZFW'].mean(),\n",
    "            'Actual %MAC ZFW': df['Actual %MAC ZFW'].mean(),\n",
    "            'Total Run Time': df['Total Run Time'].mean(),\n",
    "            'Total 1D BPP WB Time': df['Total 1D BPP WB Time'].mean(),\n",
    "            'Total 3D BPP Time': df['Total 3D BPP Time'].mean(),\n",
    "            'Number of BAX ULDs': df['Number of BAX ULDs'].mean(),\n",
    "            'Number of BUP ULDs': df['Number of BUP ULDs'].mean(),\n",
    "            'Number of T ULDs': df['Number of T ULDs'].mean(),\n",
    "            'Number of PAX A': df['Number of PAX A'].mean(),\n",
    "            'Number of PAX B': df['Number of PAX B'].mean(),\n",
    "            'Number of PAX C': df['Number of PAX C'].mean(),\n",
    "            'Number of PAX D': df['Number of PAX D'].mean(),\n",
    "            'Number of PAX E': df['Number of PAX E'].mean(),\n",
    "            'Number of PAX F': df['Number of PAX F'].mean(),\n",
    "            'Number of PAX G': df['Number of PAX G'].mean(),\n",
    "            'Total PAX': df['Total PAX'].mean(),\n",
    "            'Number of items': df['Number of items'].mean(),\n",
    "            'Weight in Comp 1': df['Weight in Comp 1'].mean(),\n",
    "            'Weight in Comp 2': df['Weight in Comp 2'].mean(),\n",
    "            'Weight in Comp 3': df['Weight in Comp 3'].mean(),\n",
    "            'Weight in Comp 4': df['Weight in Comp 4'].mean(),\n",
    "            'Number of ULDs in Comp 1': df['Number of ULDs in Comp 1'].mean(),\n",
    "            'Number of BAX ULDs in Comp 1': df['Number of BAX ULDs in Comp 1'].mean(),\n",
    "            'Weight ULDs in Comp 1': df['Weight ULDs in Comp 1'].mean(),\n",
    "            'Weight BAX ULDs in Comp 1': df['Weight BAX ULDs in Comp 1'].mean(),\n",
    "            'Number of ULDs in Comp 2': df['Number of ULDs in Comp 2'].mean(),\n",
    "            'Number of BAX ULDs in Comp 2': df['Number of BAX ULDs in Comp 2'].mean(),\n",
    "            'Weight ULDs in Comp 2': df['Weight ULDs in Comp 2'].mean(),\n",
    "            'Weight BAX ULDs in Comp 2': df['Weight BAX ULDs in Comp 2'].mean(),\n",
    "            'Number of ULDs in Comp 3': df['Number of ULDs in Comp 3'].mean(),\n",
    "            'Number of BAX ULDs in Comp 3': df['Number of BAX ULDs in Comp 3'].mean(),\n",
    "            'Weight ULDs in Comp 3': df['Weight ULDs in Comp 3'].mean(),\n",
    "            'Weight BAX ULDs in Comp 3': df['Weight BAX ULDs in Comp 3'].mean(),\n",
    "            'Number of ULDs in Comp 4': df['Number of ULDs in Comp 4'].mean(),\n",
    "            'Number of BAX ULDs in Comp 4': df['Number of BAX ULDs in Comp 4'].mean(),\n",
    "            'Weight ULDs in Comp 4': df['Weight ULDs in Comp 4'].mean(),\n",
    "            'Weight BAX ULDs in Comp 4': df['Weight BAX ULDs in Comp 4'].mean()\n",
    "        }\n",
    "\n",
    "        sum_df = pd.DataFrame([sum_data])\n",
    "        average_df = pd.DataFrame([average_data])\n",
    "\n",
    "        df = pd.concat([df, sum_df, average_df], ignore_index=True)\n",
    "\n",
    "        col_order = ['Flight Number', 'Flight Date', 'Aircraft Type', 'Aircraft Registration', '%MAC ZFW', 'Actual %MAC ZFW', 'Fuel Deviation Percentage',\n",
    "        'Fuel Deviation', 'TOW', 'ULDs Built by Model', 'ULDs Actually Used', 'Total Run Time', 'Total 1D BPP WB Time', 'Total 3D BPP Time',\n",
    "        'Number of BAX ULDs', 'Number of BUP ULDs','Number of T ULDs', 'Number of PAX A', 'Number of PAX B', 'Number of PAX C',\n",
    "        'Number of PAX D', 'Number of PAX E', 'Number of PAX F', 'Number of PAX G', 'Total PAX', 'Number of items',\n",
    "        'Weight in Comp 1', 'Weight in Comp 2', 'Weight in Comp 3', 'Weight in Comp 4', 'Number of ULDs in Comp 1',\n",
    "        'Number of BAX ULDs in Comp 1',\t'Weight ULDs in Comp 1', 'Weight BAX ULDs in Comp 1', 'Number of ULDs in Comp 2',\n",
    "        'Number of BAX ULDs in Comp 2',\t'Weight ULDs in Comp 2', 'Weight BAX ULDs in Comp 2', 'Number of ULDs in Comp 3',\n",
    "        'Number of BAX ULDs in Comp 3', 'Weight ULDs in Comp 3', 'Weight BAX ULDs in Comp 3', 'Number of ULDs in Comp 4',\t\n",
    "        'Number of BAX ULDs in Comp 4', 'Weight ULDs in Comp 4', 'Weight BAX ULDs in Comp 4'\n",
    "        ]\n",
    "\n",
    "        df = df[col_order]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def read_results(self):\n",
    "        \"\"\"\n",
    "        Read the results from the results folder and display them in a DataFrame\n",
    "        \"\"\"\n",
    "\n",
    "        base_dir = 'Results'\n",
    "        month_folder_name = f'Results {self.departure_airport}{self.arrival_airport} {self.month} {self.year}'\n",
    "        month_folder = os.path.join(base_dir, month_folder_name)\n",
    "        pattern = os.path.join(month_folder, 'Flight *')\n",
    "\n",
    "        flights = glob.glob(pattern)\n",
    "        results = []\n",
    "\n",
    "\n",
    "        for flight in flights:\n",
    "            result = self.read_individual_flight_results(flight)\n",
    "            if result is not None:\n",
    "                results.append(result)\n",
    "\n",
    "        df = pd.DataFrame(results)\n",
    "\n",
    "    \n",
    "        sum_data = {\n",
    "            'Flight Number': 'Total',\n",
    "            'Flight Date': '-',\n",
    "            'Fuel Deviation Percentage': '-',\n",
    "            'Fuel Deviation': df['Fuel Deviation'].sum(),\n",
    "            'TOW': df['TOW'].sum(),\n",
    "            'ULDs Built by Model': df['ULDs Built by Model'].sum(),\n",
    "            'ULDs Actually Used': df['ULDs Actually Used'].sum(),\n",
    "            '%MAC ZFW': '-',\n",
    "            'Actual %MAC ZFW': '-',\n",
    "            'Total Run Time': df['Total Run Time'].sum(),\n",
    "            'Total 1D BPP WB Time': df['Total 1D BPP WB Time'].sum(),\n",
    "            'Total 3D BPP Time': df['Total 3D BPP Time'].sum(),\n",
    "            'Number of BAX ULDs': df['Number of BAX ULDs'].sum(),\n",
    "            'Number of BUP ULDs': df['Number of BUP ULDs'].sum(),\n",
    "            'Number of T ULDs': df['Number of T ULDs'].sum(),\n",
    "            'Number of PAX A': '-',\n",
    "            'Number of PAX B': '-',\n",
    "            'Number of PAX C': '-',\n",
    "            'Number of PAX D': '-',\n",
    "            'Number of PAX E': '-',\n",
    "            'Number of PAX F': '-',\n",
    "            'Number of PAX G': '-',\n",
    "            'Total PAX': '-',\n",
    "            'Number of items': df['Number of items'].sum(),\n",
    "            'Weight in Comp 1': df['Weight in Comp 1'].sum(),\n",
    "            'Weight in Comp 2': df['Weight in Comp 2'].sum(),\n",
    "            'Weight in Comp 3': df['Weight in Comp 3'].sum(),\n",
    "            'Weight in Comp 4': df['Weight in Comp 4'].sum(),\n",
    "            'Number of ULDs in Comp 1': df['Number of ULDs in Comp 1'].sum(),\n",
    "            'Number of BAX ULDs in Comp 1': df['Number of BAX ULDs in Comp 1'].sum(),\n",
    "            'Weight ULDs in Comp 1': df['Weight ULDs in Comp 1'].sum(),\n",
    "            'Weight BAX ULDs in Comp 1': df['Weight BAX ULDs in Comp 1'].sum(),\n",
    "            'Number of ULDs in Comp 2': df['Number of ULDs in Comp 2'].sum(),\n",
    "            'Number of BAX ULDs in Comp 2': df['Number of BAX ULDs in Comp 2'].sum(),\n",
    "            'Weight ULDs in Comp 2': df['Weight ULDs in Comp 2'].sum(),\n",
    "            'Weight BAX ULDs in Comp 2': df['Weight BAX ULDs in Comp 2'].sum(),\n",
    "            'Number of ULDs in Comp 3': df['Number of ULDs in Comp 3'].sum(),\n",
    "            'Number of BAX ULDs in Comp 3': df['Number of BAX ULDs in Comp 3'].sum(),\n",
    "            'Weight ULDs in Comp 3': df['Weight ULDs in Comp 3'].sum(),\n",
    "            'Weight BAX ULDs in Comp 3': df['Weight BAX ULDs in Comp 3'].sum(),\n",
    "            'Number of ULDs in Comp 4': df['Number of ULDs in Comp 4'].sum(),\n",
    "            'Number of BAX ULDs in Comp 4': df['Number of BAX ULDs in Comp 4'].sum(),\n",
    "            'Weight ULDs in Comp 4': df['Weight ULDs in Comp 4'].sum(),\n",
    "            'Weight BAX ULDs in Comp 4': df['Weight BAX ULDs in Comp 4'].sum()\n",
    "        }\n",
    "\n",
    "        average_data = {\n",
    "            'Flight Number': 'Average',\n",
    "            'Flight Date': '-',\n",
    "            'Fuel Deviation Percentage': df['Fuel Deviation Percentage'].mean(),\n",
    "            'Fuel Deviation': df['Fuel Deviation'].mean(),\n",
    "            'TOW': df['TOW'].mean(),\n",
    "            'ULDs Built by Model': df['ULDs Built by Model'].mean(),\n",
    "            'ULDs Actually Used': df['ULDs Actually Used'].mean(),\n",
    "            '%MAC ZFW': df['%MAC ZFW'].mean(),\n",
    "            'Actual %MAC ZFW': df['Actual %MAC ZFW'].mean(),\n",
    "            'Total Run Time': df['Total Run Time'].mean(),\n",
    "            'Total 1D BPP WB Time': df['Total 1D BPP WB Time'].mean(),\n",
    "            'Total 3D BPP Time': df['Total 3D BPP Time'].mean(),\n",
    "            'Number of BAX ULDs': df['Number of BAX ULDs'].mean(),\n",
    "            'Number of BUP ULDs': df['Number of BUP ULDs'].mean(),\n",
    "            'Number of T ULDs': df['Number of T ULDs'].mean(),\n",
    "            'Number of PAX A': df['Number of PAX A'].mean(),\n",
    "            'Number of PAX B': df['Number of PAX B'].mean(),\n",
    "            'Number of PAX C': df['Number of PAX C'].mean(),\n",
    "            'Number of PAX D': df['Number of PAX D'].mean(),\n",
    "            'Number of PAX E': df['Number of PAX E'].mean(),\n",
    "            'Number of PAX F': df['Number of PAX F'].mean(),\n",
    "            'Number of PAX G': df['Number of PAX G'].mean(),\n",
    "            'Total PAX': df['Total PAX'].mean(),\n",
    "            'Number of items': df['Number of items'].mean(),\n",
    "            'Weight in Comp 1': df['Weight in Comp 1'].mean(),\n",
    "            'Weight in Comp 2': df['Weight in Comp 2'].mean(),\n",
    "            'Weight in Comp 3': df['Weight in Comp 3'].mean(),\n",
    "            'Weight in Comp 4': df['Weight in Comp 4'].mean(),\n",
    "            'Number of ULDs in Comp 1': df['Number of ULDs in Comp 1'].mean(),\n",
    "            'Number of BAX ULDs in Comp 1': df['Number of BAX ULDs in Comp 1'].mean(),\n",
    "            'Weight ULDs in Comp 1': df['Weight ULDs in Comp 1'].mean(),\n",
    "            'Weight BAX ULDs in Comp 1': df['Weight BAX ULDs in Comp 1'].mean(),\n",
    "            'Number of ULDs in Comp 2': df['Number of ULDs in Comp 2'].mean(),\n",
    "            'Number of BAX ULDs in Comp 2': df['Number of BAX ULDs in Comp 2'].mean(),\n",
    "            'Weight ULDs in Comp 2': df['Weight ULDs in Comp 2'].mean(),\n",
    "            'Weight BAX ULDs in Comp 2': df['Weight BAX ULDs in Comp 2'].mean(),\n",
    "            'Number of ULDs in Comp 3': df['Number of ULDs in Comp 3'].mean(),\n",
    "            'Number of BAX ULDs in Comp 3': df['Number of BAX ULDs in Comp 3'].mean(),\n",
    "            'Weight ULDs in Comp 3': df['Weight ULDs in Comp 3'].mean(),\n",
    "            'Weight BAX ULDs in Comp 3': df['Weight BAX ULDs in Comp 3'].mean(),\n",
    "            'Number of ULDs in Comp 4': df['Number of ULDs in Comp 4'].mean(),\n",
    "            'Number of BAX ULDs in Comp 4': df['Number of BAX ULDs in Comp 4'].mean(),\n",
    "            'Weight ULDs in Comp 4': df['Weight ULDs in Comp 4'].mean(),\n",
    "            'Weight BAX ULDs in Comp 4': df['Weight BAX ULDs in Comp 4'].mean()\n",
    "        }\n",
    "\n",
    "        sum_df = pd.DataFrame([sum_data])\n",
    "        average_df = pd.DataFrame([average_data])\n",
    "\n",
    "        df = pd.concat([df, sum_df, average_df], ignore_index=True)\n",
    "\n",
    "        col_order = ['Flight Number', 'Flight Date', 'Aircraft Type', 'Aircraft Registration', '%MAC ZFW', 'Actual %MAC ZFW', 'Fuel Deviation Percentage',\n",
    "        'Fuel Deviation', 'TOW', 'ULDs Built by Model', 'ULDs Actually Used', 'Total Run Time', 'Total 1D BPP WB Time', 'Total 3D BPP Time',\n",
    "        'Number of BAX ULDs', 'Number of BUP ULDs','Number of T ULDs', 'Number of PAX A', 'Number of PAX B', 'Number of PAX C',\n",
    "        'Number of PAX D', 'Number of PAX E', 'Number of PAX F', 'Number of PAX G', 'Total PAX', 'Number of items',\n",
    "        'Weight in Comp 1', 'Weight in Comp 2', 'Weight in Comp 3', 'Weight in Comp 4', 'Number of ULDs in Comp 1',\n",
    "        'Number of BAX ULDs in Comp 1',\t'Weight ULDs in Comp 1', 'Weight BAX ULDs in Comp 1', 'Number of ULDs in Comp 2',\n",
    "        'Number of BAX ULDs in Comp 2',\t'Weight ULDs in Comp 2', 'Weight BAX ULDs in Comp 2', 'Number of ULDs in Comp 3',\n",
    "        'Number of BAX ULDs in Comp 3', 'Weight ULDs in Comp 3', 'Weight BAX ULDs in Comp 3', 'Number of ULDs in Comp 4',\t\n",
    "        'Number of BAX ULDs in Comp 4', 'Weight ULDs in Comp 4', 'Weight BAX ULDs in Comp 4'\n",
    "        ]\n",
    "\n",
    "        df = df[col_order]\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def style_results(self, df):\n",
    "        \"\"\"\n",
    "        Style the results DataFrame\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to style.\n",
    "        \"\"\"\n",
    "        \n",
    "        last_two_indices = df.tail(2).index\n",
    "\n",
    "        df.replace('-', np.nan, inplace=True)\n",
    "\n",
    "        styled_df = (df.style\n",
    "                    .apply(lambda x: ['font-weight: bold;' if x.name in last_two_indices else '' for _ in x], axis=1)\n",
    "                    .format({\n",
    "                        'Fuel Deviation Percentage': '{:.3%}',\n",
    "                        'Fuel Deviation': '{:,.3f} kg',\n",
    "                        'TOW': '{:,.1f} kg',\n",
    "                        'Total Run Time': '{:.2f} s',\n",
    "                        'Total 1D BPP WB Time': '{:.2f} s',\n",
    "                        'Total 3D BPP Time': '{:.2f} s',\n",
    "                        '%MAC ZFW': '{:.4f}',\n",
    "                        'Actual %MAC ZFW': '{:.4f}',\n",
    "                        'ULDs Built by Model': '{:,.0f}',\n",
    "                        'ULDs Actually Used': '{:,.0f}',\n",
    "                        'Number of BAX ULDs': '{:,.0f}',\n",
    "                        'Number of BUP ULDs': '{:,.0f}',\n",
    "                        'Number of T ULDs': '{:,.0f}',\n",
    "                        'Number of PAX A': '{:,.0f}',\n",
    "                        'Number of PAX B': '{:,.0f}',\n",
    "                        'Number of PAX C': '{:,.0f}',\n",
    "                        'Number of PAX D': '{:,.0f}',\n",
    "                        'Number of PAX E': '{:,.0f}',\n",
    "                        'Number of PAX F': '{:,.0f}',\n",
    "                        'Number of PAX G': '{:,.0f}',\n",
    "                        'Total PAX': '{:,.0f}',\n",
    "                        'Number of items': '{:,.0f}',\n",
    "                        'Weight in Comp 1': '{:,.1f} kg',\n",
    "                        'Weight in Comp 2': '{:,.1f} kg',\n",
    "                        'Weight in Comp 3': '{:,.1f} kg',\n",
    "                        'Weight in Comp 4': '{:,.1f} kg',\n",
    "                        'Number of ULDs in Comp 1': '{:,.0f}',\n",
    "                        'Number of BAX ULDs in Comp 1': '{:,.0f}',\n",
    "                        'Weight ULDs in Comp 1': '{:,.1f} kg',\n",
    "                        'Weight BAX ULDs in Comp 1': '{:,.1f} kg',\n",
    "                        'Number of ULDs in Comp 2': '{:,.0f}',\n",
    "                        'Number of BAX ULDs in Comp 2': '{:,.0f}',\n",
    "                        'Weight ULDs in Comp 2': '{:,.1f} kg',\n",
    "                        'Weight BAX ULDs in Comp 2': '{:,.1f} kg',\n",
    "                        'Number of ULDs in Comp 3': '{:,.0f}',\n",
    "                        'Number of BAX ULDs in Comp 3': '{:,.0f}',\n",
    "                        'Weight ULDs in Comp 3': '{:,.1f} kg',\n",
    "                        'Weight BAX ULDs in Comp 3': '{:,.1f} kg',\n",
    "                        'Number of ULDs in Comp 4': '{:,.0f}',\n",
    "                        'Number of BAX ULDs in Comp 4': '{:,.0f}',\n",
    "                        'Weight ULDs in Comp 4': '{:,.1f} kg',\n",
    "                        'Weight BAX ULDs in Comp 4': '{:,.1f} kg'\n",
    "                    }, na_rep='')\n",
    "                    .hide(axis='index')\n",
    "                    # Apply bar only to numeric columns that do not have 'Total' or 'Average' in the index\n",
    "                    .set_table_styles({\n",
    "                        'A': [{'selector': 'th', 'props': [('text-align', 'left')]}],\n",
    "                        'B': [{'selector': 'td', 'props': [('text-align', 'center')]}]\n",
    "                    }, overwrite=False)\n",
    "                    .set_properties(subset=['Flight Number'], **{'text-align': 'left'})\n",
    "                    .set_table_attributes('style=\"font-size: 13px; border: 1px solid black;\"')\n",
    "                    .set_caption(f\"Results\"))\n",
    "        \n",
    "            \n",
    "        return styled_df\n",
    "    \n",
    "\n",
    "    def read_individual_flight_results(self, flight_folder):\n",
    "        \"\"\"\n",
    "        Read the results for an individual flight\n",
    "\n",
    "        Args:\n",
    "            flight_folder (str): The folder path to the flight results.\n",
    "        \"\"\"\n",
    "\n",
    "        model_info_file = os.path.join(flight_folder, 'Model_Information.txt')\n",
    "        if not os.path.exists(model_info_file):\n",
    "            return None\n",
    "\n",
    "        flight_number = os.path.basename(flight_folder).split(' ')[1]\n",
    "        flight_date = os.path.basename(flight_folder).split(' ')[3:6]\n",
    "        flight_date = ' '.join(flight_date)\n",
    "\n",
    "\n",
    "        results = {\n",
    "            'Flight Number': flight_number,\n",
    "            'Flight Date': flight_date,\n",
    "        }\n",
    "\n",
    "        results_file = os.path.join(flight_folder, 'Results.txt')\n",
    "        model_info_file = os.path.join(flight_folder, 'Model_Information.txt')\n",
    "        general_info_file = os.path.join(flight_folder, 'General_Information.txt')\n",
    "        CG_info_file = os.path.join(flight_folder, 'CG_envelope.png')\n",
    "\n",
    "        with open(general_info_file, 'r') as file:\n",
    "            content = file.read()\n",
    "            aircraft_type_match = re.search(r'Aircraft Type: ([\\d\\w]+) ', content)\n",
    "            if aircraft_type_match:\n",
    "                self.aircraft_type = aircraft_type_match.group(1)\n",
    "\n",
    "            aircraft_registration_match = re.search(r'Flight Number: ([\\w\\d]+) ([\\w\\d]+)', content)\n",
    "            if aircraft_registration_match:\n",
    "                self.aircraft_registration = aircraft_registration_match.group(2)\n",
    "\n",
    "            TOW_match = re.search(r'TOW: ([\\d.]+) kg', content)\n",
    "            if TOW_match:\n",
    "                self.TOW = float(TOW_match.group(1))\n",
    "\n",
    "            results['Number of BAX ULDs'] = int(re.search(r'Number of BAX ULDs: (\\d+)', content).group(1))\n",
    "            results['Number of BUP ULDs'] = int(re.search(r'Number of BUP ULDs: (\\d+)', content).group(1))\n",
    "            results['Number of T ULDs'] = int(re.search(r'Number of T ULDs: (\\d+)', content).group(1))\n",
    "            \n",
    "            results['Number of PAX A'] = int(re.search(r'PAX-A: (\\d+)', content).group(1))\n",
    "            results['Number of PAX B'] = int(re.search(r'PAX-B: (\\d+)', content).group(1))\n",
    "            results['Number of PAX C'] = int(re.search(r'PAX-C: (\\d+)', content).group(1))\n",
    "            results['Number of PAX D'] = int(re.search(r'PAX-D: (\\d+)', content).group(1))\n",
    "            results['Number of PAX E'] = int(re.search(r'PAX-E: (\\d+)', content).group(1))\n",
    "            results['Number of PAX F'] = int(re.search(r'PAX-F: (\\d+)', content).group(1))\n",
    "            results['Number of PAX G'] = int(re.search(r'PAX-G: (\\d+)', content).group(1))\n",
    "            total_pax = int(re.search(r'Total PAX: (\\d+)', content).group(1))\n",
    "            results['Total PAX'] = total_pax\n",
    "\n",
    "            items_fit = int(re.search(r'(\\d+) / \\d+ items fit the dimensions of the ULDs', content).group(1))\n",
    "            results['Number of items'] = items_fit\n",
    "\n",
    "        # Read and process the Results.txt file\n",
    "        with open(results_file, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "            fuel_data = re.search(r\"Resulting in a fuel deviation of ([\\-\\d.]+)% or ([\\-\\d.]+) kg\", content)\n",
    "            if fuel_data:\n",
    "                fuel_percentage = float(fuel_data.group(1)) / 100\n",
    "                fuel_kg = float(fuel_data.group(2))\n",
    "\n",
    "                self.fuel_reduction_percentage = fuel_percentage\n",
    "                self.fuel_reduction_kg = fuel_kg\n",
    "\n",
    "            uld_data = re.search(r\"(\\d+) ULDs are built by the model\\n(\\d+) ULDs were actually built\", content)\n",
    "            if uld_data:\n",
    "                self.uld_built_by_model = int(uld_data.group(1))\n",
    "                self.uld_actually_used = int(uld_data.group(2))\n",
    "\n",
    "            mac_data = re.search(r\"%MAC ZFW is ([\\d.]+)\", content)\n",
    "            if mac_data:\n",
    "                self.MAC = float(mac_data.group(1))\n",
    "\n",
    "            mac_actual = re.search(r'The actual %MAC ZFW for this flight was ([\\d.]+)', content)\n",
    "            if mac_actual:\n",
    "                self.MAC_actual = float(mac_actual.group(1))\n",
    "\n",
    "            weight_uld_comp_1 = 0\n",
    "            weight_uld_comp_2 = 0\n",
    "            weight_uld_comp_3 = 0\n",
    "            weight_uld_comp_4 = 0\n",
    "            count_uld_comp_1 = 0\n",
    "            count_uld_comp_2 = 0\n",
    "            count_uld_comp_3 = 0\n",
    "            count_uld_comp_4 = 0\n",
    "\n",
    "            weight_bax_comp_1 = 0\n",
    "            weight_bax_comp_2 = 0\n",
    "            weight_bax_comp_3 = 0\n",
    "            weight_bax_comp_4 = 0\n",
    "            count_bax_comp_1 = 0\n",
    "            count_bax_comp_2 = 0\n",
    "            count_bax_comp_3 = 0\n",
    "            count_bax_comp_4 = 0\n",
    "\n",
    "            pattern = r'ULD (\\w+-?\\d*) with weight ([\\d.]+) kg.*position (\\d+)'\n",
    "\n",
    "            for match in re.finditer(pattern, content):\n",
    "                uld_type = match.group(1)\n",
    "                weight = float(match.group(2))\n",
    "                compartment = int(match.group(3)[0])\n",
    "\n",
    "                if 'BAX' not in str(uld_type):\n",
    "                    if compartment == 1:\n",
    "                        count_uld_comp_1 += 1\n",
    "                        weight_uld_comp_1 += weight\n",
    "                    elif compartment == 2:\n",
    "                        count_uld_comp_2 += 1\n",
    "                        weight_uld_comp_2 += weight\n",
    "                    elif compartment == 3:\n",
    "                        count_uld_comp_3 += 1\n",
    "                        weight_uld_comp_3 += weight\n",
    "                    elif compartment == 4:\n",
    "                        count_uld_comp_4 += 1\n",
    "                        weight_uld_comp_4 += weight\n",
    "\n",
    "                if 'BAX' in str(uld_type):\n",
    "                    if compartment == 1:\n",
    "                        count_bax_comp_1 += 1\n",
    "                        weight_bax_comp_1 += weight\n",
    "                    elif compartment == 2:\n",
    "                        count_bax_comp_2 += 1\n",
    "                        weight_bax_comp_2 += weight\n",
    "                    elif compartment == 3:\n",
    "                        count_bax_comp_3 += 1\n",
    "                        weight_bax_comp_3 += weight\n",
    "                    elif compartment == 4:\n",
    "                        count_bax_comp_4 += 1\n",
    "                        weight_bax_comp_4 += weight\n",
    "\n",
    "            results['Aircraft Type'] = self.aircraft_type\n",
    "            results['Aircraft Registration'] = self.aircraft_registration\n",
    "            results['%MAC ZFW'] = self.MAC\n",
    "            results['Actual %MAC ZFW'] = self.MAC_actual\n",
    "            results['Fuel Deviation Percentage'] = self.fuel_reduction_percentage\n",
    "            results['Fuel Deviation'] = self.fuel_reduction_kg\n",
    "            results['TOW'] = self.TOW\n",
    "            results['ULDs Built by Model'] = self.uld_built_by_model\n",
    "            results['ULDs Actually Used'] = self.uld_actually_used\n",
    "            results['Weight in Comp 1'] = float(re.search(r'Weight in Compartment 1: ([\\d.]+)', content).group(1))\n",
    "            results['Weight in Comp 2'] = float(re.search(r'Weight in Compartment 2: ([\\d.]+)', content).group(1))\n",
    "            results['Weight in Comp 3'] = float(re.search(r'Weight in Compartment 3: ([\\d.]+)', content).group(1))\n",
    "            results['Weight in Comp 4'] = float(re.search(r'Weight in Compartment 4: ([\\d.]+)', content).group(1))\n",
    "            results['Number of ULDs in Comp 1'] = count_uld_comp_1\n",
    "            results['Number of BAX ULDs in Comp 1'] = count_bax_comp_1\n",
    "            results['Weight ULDs in Comp 1'] = weight_uld_comp_1\n",
    "            results['Weight BAX ULDs in Comp 1'] = weight_bax_comp_1\n",
    "            results['Number of ULDs in Comp 2'] = count_uld_comp_2\n",
    "            results['Number of BAX ULDs in Comp 2'] = count_bax_comp_2\n",
    "            results['Weight ULDs in Comp 2'] = weight_uld_comp_2\n",
    "            results['Weight BAX ULDs in Comp 2'] = weight_bax_comp_2\n",
    "            results['Number of ULDs in Comp 3'] = count_uld_comp_3\n",
    "            results['Number of BAX ULDs in Comp 3'] = count_bax_comp_3\n",
    "            results['Weight ULDs in Comp 3'] = weight_uld_comp_3\n",
    "            results['Weight BAX ULDs in Comp 3'] = weight_bax_comp_3\n",
    "            results['Number of ULDs in Comp 4'] = count_uld_comp_4\n",
    "            results['Number of BAX ULDs in Comp 4'] = count_bax_comp_4\n",
    "            results['Weight ULDs in Comp 4'] = weight_uld_comp_4\n",
    "            results['Weight BAX ULDs in Comp 4'] = weight_bax_comp_4\n",
    "        \n",
    "\n",
    "\n",
    "        with open(model_info_file, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "            total_time_data = re.search(r\"Total time: ([\\d.]+) seconds\", content)\n",
    "            if total_time_data:\n",
    "                self.total_run_time = float(total_time_data.group(1))\n",
    "\n",
    "            total_1D_BPP_WB_data = re.search(r\"Total time 1D BPP WB: ([\\d.]+) seconds\", content)\n",
    "            if total_1D_BPP_WB_data:\n",
    "                self.total_1D_BPP_WB_time = float(total_1D_BPP_WB_data.group(1))\n",
    "\n",
    "            total_3D_BPP_data = re.search(r\"Total time 3D BPP: ([\\d.]+) seconds\", content)\n",
    "            if total_3D_BPP_data:\n",
    "                self.total_3D_BPP_time = float(total_3D_BPP_data.group(1))\n",
    "\n",
    "        results['Total Run Time'] = self.total_run_time\n",
    "        results['Total 1D BPP WB Time'] = self.total_1D_BPP_WB_time\n",
    "        results['Total 3D BPP Time'] = self.total_3D_BPP_time\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultsReaderBaseline():\n",
    "    def __init__(self, departure_airport = None, arrival_airport = None, month = None, year = None):\n",
    "        self.departure_airport = departure_airport\n",
    "        self.arrival_airport = arrival_airport\n",
    "        self.month = month\n",
    "        self.year = year\n",
    "        self.aircraft_type = None\n",
    "        self.aircraft_registration = None\n",
    "        self.fuel_reduction_percentage = 0\n",
    "        self.fuel_reduction_kg = 0\n",
    "        self.uld_built_by_model = 0\n",
    "        self.uld_actually_used = 0\n",
    "        self.total_run_time = 0\n",
    "        self.total_1D_BPP_time = 0\n",
    "        self.total_3D_BPP_time = 0\n",
    "        self.total_WB_time = 0\n",
    "        self.MAC = 0\n",
    "        self.MAC_actual = 0\n",
    "        self.TOW = 0\n",
    "\n",
    "    def read_all_results(self):\n",
    "        \"\"\"\n",
    "        Read all the results from the results folder\n",
    "        \"\"\"\n",
    "        results = []\n",
    "\n",
    "        base_dir = 'Results_Baseline'\n",
    "\n",
    "        for root, dirs, files in os.walk(base_dir):\n",
    "            for dir_name in dirs:\n",
    "                if dir_name.startswith('Results '):  # Check if directory name starts with 'Results'\n",
    "                    full_path = os.path.join(root, dir_name)\n",
    "                    pattern = os.path.join(full_path, 'Flight *')\n",
    "                    flights = glob.glob(pattern)\n",
    "\n",
    "                    for flight in flights:\n",
    "                        result = self.read_individual_flight_results(flight)\n",
    "                        if result:\n",
    "                            results.append(result)\n",
    "        \n",
    "        df = pd.DataFrame(results)\n",
    "\n",
    "        sum_data = {\n",
    "            'Flight Number': 'Total',\n",
    "            'Flight Date': '-',\n",
    "            'Fuel Deviation Percentage': '-',\n",
    "            'Fuel Deviation': df['Fuel Deviation'].sum(),\n",
    "            'TOW': df['TOW'].sum(),\n",
    "            'ULDs Built by Model': df['ULDs Built by Model'].sum(),\n",
    "            'ULDs Actually Used': df['ULDs Actually Used'].sum(),\n",
    "            '%MAC ZFW': '-',\n",
    "            'Actual %MAC ZFW': '-',\n",
    "            'Total Run Time': df['Total Run Time'].sum(),\n",
    "            'Total 1D BPP Time': df['Total 1D BPP Time'].sum(),\n",
    "            'Total 3D BPP Time': df['Total 3D BPP Time'].sum(),\n",
    "            'Total WB Time': df['Total WB Time'].sum(),\n",
    "            'Number of BAX ULDs': df['Number of BAX ULDs'].sum(),\n",
    "            'Number of BUP ULDs': df['Number of BUP ULDs'].sum(),\n",
    "            'Number of T ULDs': df['Number of T ULDs'].sum(),\n",
    "            'Number of PAX A': '-',\n",
    "            'Number of PAX B': '-',\n",
    "            'Number of PAX C': '-',\n",
    "            'Number of PAX D': '-',\n",
    "            'Number of PAX E': '-',\n",
    "            'Number of PAX F': '-',\n",
    "            'Number of PAX G': '-',\n",
    "            'Total PAX': '-',\n",
    "            'Number of items': df['Number of items'].sum(),\n",
    "            'Weight in Comp 1': df['Weight in Comp 1'].sum(),\n",
    "            'Weight in Comp 2': df['Weight in Comp 2'].sum(),\n",
    "            'Weight in Comp 3': df['Weight in Comp 3'].sum(),\n",
    "            'Weight in Comp 4': df['Weight in Comp 4'].sum(),\n",
    "            'Number of ULDs in Comp 1': df['Number of ULDs in Comp 1'].sum(),\n",
    "            'Number of BAX ULDs in Comp 1': df['Number of BAX ULDs in Comp 1'].sum(),\n",
    "            'Weight ULDs in Comp 1': df['Weight ULDs in Comp 1'].sum(),\n",
    "            'Weight BAX ULDs in Comp 1': df['Weight BAX ULDs in Comp 1'].sum(),\n",
    "            'Number of ULDs in Comp 2': df['Number of ULDs in Comp 2'].sum(),\n",
    "            'Number of BAX ULDs in Comp 2': df['Number of BAX ULDs in Comp 2'].sum(),\n",
    "            'Weight ULDs in Comp 2': df['Weight ULDs in Comp 2'].sum(),\n",
    "            'Weight BAX ULDs in Comp 2': df['Weight BAX ULDs in Comp 2'].sum(),\n",
    "            'Number of ULDs in Comp 3': df['Number of ULDs in Comp 3'].sum(),\n",
    "            'Number of BAX ULDs in Comp 3': df['Number of BAX ULDs in Comp 3'].sum(),\n",
    "            'Weight ULDs in Comp 3': df['Weight ULDs in Comp 3'].sum(),\n",
    "            'Weight BAX ULDs in Comp 3': df['Weight BAX ULDs in Comp 3'].sum(),\n",
    "            'Number of ULDs in Comp 4': df['Number of ULDs in Comp 4'].sum(),\n",
    "            'Number of BAX ULDs in Comp 4': df['Number of BAX ULDs in Comp 4'].sum(),\n",
    "            'Weight ULDs in Comp 4': df['Weight ULDs in Comp 4'].sum(),\n",
    "            'Weight BAX ULDs in Comp 4': df['Weight BAX ULDs in Comp 4'].sum()\n",
    "        }\n",
    "\n",
    "        average_data = {\n",
    "            'Flight Number': 'Average',\n",
    "            'Flight Date': '-',\n",
    "            'Fuel Deviation Percentage': df['Fuel Deviation Percentage'].mean(),\n",
    "            'Fuel Deviation': df['Fuel Deviation'].mean(),\n",
    "            'TOW': df['TOW'].mean(),\n",
    "            'ULDs Built by Model': df['ULDs Built by Model'].mean(),\n",
    "            'ULDs Actually Used': df['ULDs Actually Used'].mean(),\n",
    "            '%MAC ZFW': df['%MAC ZFW'].mean(),\n",
    "            'Actual %MAC ZFW': df['Actual %MAC ZFW'].mean(),\n",
    "            'Total Run Time': df['Total Run Time'].mean(),\n",
    "            'Total 1D BPP Time': df['Total 1D BPP Time'].mean(),\n",
    "            'Total 3D BPP Time': df['Total 3D BPP Time'].mean(),\n",
    "            'Total WB Time': df['Total WB Time'].mean(),\n",
    "            'Number of BAX ULDs': df['Number of BAX ULDs'].mean(),\n",
    "            'Number of BUP ULDs': df['Number of BUP ULDs'].mean(),\n",
    "            'Number of T ULDs': df['Number of T ULDs'].mean(),\n",
    "            'Number of PAX A': df['Number of PAX A'].mean(),\n",
    "            'Number of PAX B': df['Number of PAX B'].mean(),\n",
    "            'Number of PAX C': df['Number of PAX C'].mean(),\n",
    "            'Number of PAX D': df['Number of PAX D'].mean(),\n",
    "            'Number of PAX E': df['Number of PAX E'].mean(),\n",
    "            'Number of PAX F': df['Number of PAX F'].mean(),\n",
    "            'Number of PAX G': df['Number of PAX G'].mean(),\n",
    "            'Total PAX': df['Total PAX'].mean(),\n",
    "            'Number of items': df['Number of items'].mean(),\n",
    "            'Weight in Comp 1': df['Weight in Comp 1'].mean(),\n",
    "            'Weight in Comp 2': df['Weight in Comp 2'].mean(),\n",
    "            'Weight in Comp 3': df['Weight in Comp 3'].mean(),\n",
    "            'Weight in Comp 4': df['Weight in Comp 4'].mean(),\n",
    "            'Number of ULDs in Comp 1': df['Number of ULDs in Comp 1'].mean(),\n",
    "            'Number of BAX ULDs in Comp 1': df['Number of BAX ULDs in Comp 1'].mean(),\n",
    "            'Weight ULDs in Comp 1': df['Weight ULDs in Comp 1'].mean(),\n",
    "            'Weight BAX ULDs in Comp 1': df['Weight BAX ULDs in Comp 1'].mean(),\n",
    "            'Number of ULDs in Comp 2': df['Number of ULDs in Comp 2'].mean(),\n",
    "            'Number of BAX ULDs in Comp 2': df['Number of BAX ULDs in Comp 2'].mean(),\n",
    "            'Weight ULDs in Comp 2': df['Weight ULDs in Comp 2'].mean(),\n",
    "            'Weight BAX ULDs in Comp 2': df['Weight BAX ULDs in Comp 2'].mean(),\n",
    "            'Number of ULDs in Comp 3': df['Number of ULDs in Comp 3'].mean(),\n",
    "            'Number of BAX ULDs in Comp 3': df['Number of BAX ULDs in Comp 3'].mean(),\n",
    "            'Weight ULDs in Comp 3': df['Weight ULDs in Comp 3'].mean(),\n",
    "            'Weight BAX ULDs in Comp 3': df['Weight BAX ULDs in Comp 3'].mean(),\n",
    "            'Number of ULDs in Comp 4': df['Number of ULDs in Comp 4'].mean(),\n",
    "            'Number of BAX ULDs in Comp 4': df['Number of BAX ULDs in Comp 4'].mean(),\n",
    "            'Weight ULDs in Comp 4': df['Weight ULDs in Comp 4'].mean(),\n",
    "            'Weight BAX ULDs in Comp 4': df['Weight BAX ULDs in Comp 4'].mean()\n",
    "        }\n",
    "\n",
    "        sum_df = pd.DataFrame([sum_data])\n",
    "        average_df = pd.DataFrame([average_data])\n",
    "\n",
    "        df = pd.concat([df, sum_df, average_df], ignore_index=True)\n",
    "\n",
    "        col_order = ['Flight Number', 'Flight Date', 'Aircraft Type', 'Aircraft Registration', '%MAC ZFW', 'Actual %MAC ZFW', 'Fuel Deviation Percentage',\n",
    "        'Fuel Deviation', 'TOW', 'ULDs Built by Model', 'ULDs Actually Used', 'Total Run Time', 'Total 1D BPP Time', 'Total 3D BPP Time', 'Total WB Time',\n",
    "        'Number of BAX ULDs', 'Number of BUP ULDs','Number of T ULDs', 'Number of PAX A', 'Number of PAX B', 'Number of PAX C',\n",
    "        'Number of PAX D', 'Number of PAX E', 'Number of PAX F', 'Number of PAX G', 'Total PAX', 'Number of items',\n",
    "        'Weight in Comp 1', 'Weight in Comp 2', 'Weight in Comp 3', 'Weight in Comp 4', 'Number of ULDs in Comp 1',\n",
    "        'Number of BAX ULDs in Comp 1',\t'Weight ULDs in Comp 1', 'Weight BAX ULDs in Comp 1', 'Number of ULDs in Comp 2',\n",
    "        'Number of BAX ULDs in Comp 2',\t'Weight ULDs in Comp 2', 'Weight BAX ULDs in Comp 2', 'Number of ULDs in Comp 3',\n",
    "        'Number of BAX ULDs in Comp 3', 'Weight ULDs in Comp 3', 'Weight BAX ULDs in Comp 3', 'Number of ULDs in Comp 4',\t\n",
    "        'Number of BAX ULDs in Comp 4', 'Weight ULDs in Comp 4', 'Weight BAX ULDs in Comp 4'\n",
    "        ]\n",
    "\n",
    "        df = df[col_order]\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    def read_results(self):\n",
    "        \"\"\"\n",
    "        Read the results from the results folder and display them in a DataFrame\n",
    "        \"\"\"\n",
    "\n",
    "        base_dir = 'Results_Baseline'\n",
    "        month_folder_name = f'Results {self.departure_airport}{self.arrival_airport} {self.month} {self.year}'\n",
    "        month_folder = os.path.join(base_dir, month_folder_name)\n",
    "        pattern = os.path.join(month_folder, 'Flight *')\n",
    "\n",
    "        flights = glob.glob(pattern)\n",
    "        results = []\n",
    "\n",
    "\n",
    "        for flight in flights:\n",
    "            result = self.read_individual_flight_results(flight)\n",
    "            if result is not None:\n",
    "                results.append(result)\n",
    "\n",
    "\n",
    "        df = pd.DataFrame(results)\n",
    "\n",
    "    \n",
    "        sum_data = {\n",
    "            'Flight Number': 'Total',\n",
    "            'Flight Date': '-',\n",
    "            'Fuel Deviation Percentage': '-',\n",
    "            'Fuel Deviation': df['Fuel Deviation'].sum(),\n",
    "            'TOW': df['TOW'].sum(),\n",
    "            'ULDs Built by Model': df['ULDs Built by Model'].sum(),\n",
    "            'ULDs Actually Used': df['ULDs Actually Used'].sum(),\n",
    "            '%MAC ZFW': '-',\n",
    "            'Actual %MAC ZFW': '-',\n",
    "            'Total Run Time': df['Total Run Time'].sum(),\n",
    "            'Total 1D BPP Time': df['Total 1D BPP Time'].sum(),\n",
    "            'Total 3D BPP Time': df['Total 3D BPP Time'].sum(),\n",
    "            'Total WB Time': df['Total WB Time'].sum(),\n",
    "            'Number of BAX ULDs': df['Number of BAX ULDs'].sum(),\n",
    "            'Number of BUP ULDs': df['Number of BUP ULDs'].sum(),\n",
    "            'Number of T ULDs': df['Number of T ULDs'].sum(),\n",
    "            'Number of PAX A': '-',\n",
    "            'Number of PAX B': '-',\n",
    "            'Number of PAX C': '-',\n",
    "            'Number of PAX D': '-',\n",
    "            'Number of PAX E': '-',\n",
    "            'Number of PAX F': '-',\n",
    "            'Number of PAX G': '-',\n",
    "            'Total PAX': '-',\n",
    "            'Number of items': df['Number of items'].sum(),\n",
    "            'Weight in Comp 1': df['Weight in Comp 1'].sum(),\n",
    "            'Weight in Comp 2': df['Weight in Comp 2'].sum(),\n",
    "            'Weight in Comp 3': df['Weight in Comp 3'].sum(),\n",
    "            'Weight in Comp 4': df['Weight in Comp 4'].sum(),\n",
    "            'Number of ULDs in Comp 1': df['Number of ULDs in Comp 1'].sum(),\n",
    "            'Number of BAX ULDs in Comp 1': df['Number of BAX ULDs in Comp 1'].sum(),\n",
    "            'Weight ULDs in Comp 1': df['Weight ULDs in Comp 1'].sum(),\n",
    "            'Weight BAX ULDs in Comp 1': df['Weight BAX ULDs in Comp 1'].sum(),\n",
    "            'Number of ULDs in Comp 2': df['Number of ULDs in Comp 2'].sum(),\n",
    "            'Number of BAX ULDs in Comp 2': df['Number of BAX ULDs in Comp 2'].sum(),\n",
    "            'Weight ULDs in Comp 2': df['Weight ULDs in Comp 2'].sum(),\n",
    "            'Weight BAX ULDs in Comp 2': df['Weight BAX ULDs in Comp 2'].sum(),\n",
    "            'Number of ULDs in Comp 3': df['Number of ULDs in Comp 3'].sum(),\n",
    "            'Number of BAX ULDs in Comp 3': df['Number of BAX ULDs in Comp 3'].sum(),\n",
    "            'Weight ULDs in Comp 3': df['Weight ULDs in Comp 3'].sum(),\n",
    "            'Weight BAX ULDs in Comp 3': df['Weight BAX ULDs in Comp 3'].sum(),\n",
    "            'Number of ULDs in Comp 4': df['Number of ULDs in Comp 4'].sum(),\n",
    "            'Number of BAX ULDs in Comp 4': df['Number of BAX ULDs in Comp 4'].sum(),\n",
    "            'Weight ULDs in Comp 4': df['Weight ULDs in Comp 4'].sum(),\n",
    "            'Weight BAX ULDs in Comp 4': df['Weight BAX ULDs in Comp 4'].sum()\n",
    "        }\n",
    "\n",
    "        average_data = {\n",
    "            'Flight Number': 'Average',\n",
    "            'Flight Date': '-',\n",
    "            'Fuel Deviation Percentage': df['Fuel Deviation Percentage'].mean(),\n",
    "            'Fuel Deviation': df['Fuel Deviation'].mean(),\n",
    "            'TOW': df['TOW'].mean(),\n",
    "            'ULDs Built by Model': df['ULDs Built by Model'].mean(),\n",
    "            'ULDs Actually Used': df['ULDs Actually Used'].mean(),\n",
    "            '%MAC ZFW': df['%MAC ZFW'].mean(),\n",
    "            'Actual %MAC ZFW': df['Actual %MAC ZFW'].mean(),\n",
    "            'Total Run Time': df['Total Run Time'].mean(),\n",
    "            'Total 1D BPP Time': df['Total 1D BPP Time'].mean(),\n",
    "            'Total 3D BPP Time': df['Total 3D BPP Time'].mean(),\n",
    "            'Total WB Time': df['Total WB Time'].mean(),\n",
    "            'Number of BAX ULDs': df['Number of BAX ULDs'].mean(),\n",
    "            'Number of BUP ULDs': df['Number of BUP ULDs'].mean(),\n",
    "            'Number of T ULDs': df['Number of T ULDs'].mean(),\n",
    "            'Number of PAX A': df['Number of PAX A'].mean(),\n",
    "            'Number of PAX B': df['Number of PAX B'].mean(),\n",
    "            'Number of PAX C': df['Number of PAX C'].mean(),\n",
    "            'Number of PAX D': df['Number of PAX D'].mean(),\n",
    "            'Number of PAX E': df['Number of PAX E'].mean(),\n",
    "            'Number of PAX F': df['Number of PAX F'].mean(),\n",
    "            'Number of PAX G': df['Number of PAX G'].mean(),\n",
    "            'Total PAX': df['Total PAX'].mean(),\n",
    "            'Number of items': df['Number of items'].mean(),\n",
    "            'Weight in Comp 1': df['Weight in Comp 1'].mean(),\n",
    "            'Weight in Comp 2': df['Weight in Comp 2'].mean(),\n",
    "            'Weight in Comp 3': df['Weight in Comp 3'].mean(),\n",
    "            'Weight in Comp 4': df['Weight in Comp 4'].mean(),\n",
    "            'Number of ULDs in Comp 1': df['Number of ULDs in Comp 1'].mean(),\n",
    "            'Number of BAX ULDs in Comp 1': df['Number of BAX ULDs in Comp 1'].mean(),\n",
    "            'Weight ULDs in Comp 1': df['Weight ULDs in Comp 1'].mean(),\n",
    "            'Weight BAX ULDs in Comp 1': df['Weight BAX ULDs in Comp 1'].mean(),\n",
    "            'Number of ULDs in Comp 2': df['Number of ULDs in Comp 2'].mean(),\n",
    "            'Number of BAX ULDs in Comp 2': df['Number of BAX ULDs in Comp 2'].mean(),\n",
    "            'Weight ULDs in Comp 2': df['Weight ULDs in Comp 2'].mean(),\n",
    "            'Weight BAX ULDs in Comp 2': df['Weight BAX ULDs in Comp 2'].mean(),\n",
    "            'Number of ULDs in Comp 3': df['Number of ULDs in Comp 3'].mean(),\n",
    "            'Number of BAX ULDs in Comp 3': df['Number of BAX ULDs in Comp 3'].mean(),\n",
    "            'Weight ULDs in Comp 3': df['Weight ULDs in Comp 3'].mean(),\n",
    "            'Weight BAX ULDs in Comp 3': df['Weight BAX ULDs in Comp 3'].mean(),\n",
    "            'Number of ULDs in Comp 4': df['Number of ULDs in Comp 4'].mean(),\n",
    "            'Number of BAX ULDs in Comp 4': df['Number of BAX ULDs in Comp 4'].mean(),\n",
    "            'Weight ULDs in Comp 4': df['Weight ULDs in Comp 4'].mean(),\n",
    "            'Weight BAX ULDs in Comp 4': df['Weight BAX ULDs in Comp 4'].mean()\n",
    "        }\n",
    "\n",
    "        sum_df = pd.DataFrame([sum_data])\n",
    "        average_df = pd.DataFrame([average_data])\n",
    "\n",
    "        df = pd.concat([df, sum_df, average_df], ignore_index=True)\n",
    "\n",
    "        col_order = ['Flight Number', 'Flight Date', 'Aircraft Type', 'Aircraft Registration', '%MAC ZFW', 'Actual %MAC ZFW', 'Fuel Deviation Percentage',\n",
    "        'Fuel Deviation', 'TOW', 'ULDs Built by Model', 'ULDs Actually Used', 'Total Run Time', 'Total 1D BPP Time', 'Total 3D BPP Time', 'Total WB Time',\n",
    "        'Number of BAX ULDs', 'Number of BUP ULDs','Number of T ULDs', 'Number of PAX A', 'Number of PAX B', 'Number of PAX C',\n",
    "        'Number of PAX D', 'Number of PAX E', 'Number of PAX F', 'Number of PAX G', 'Total PAX', 'Number of items',\n",
    "        'Weight in Comp 1', 'Weight in Comp 2', 'Weight in Comp 3', 'Weight in Comp 4', 'Number of ULDs in Comp 1',\n",
    "        'Number of BAX ULDs in Comp 1',\t'Weight ULDs in Comp 1', 'Weight BAX ULDs in Comp 1', 'Number of ULDs in Comp 2',\n",
    "        'Number of BAX ULDs in Comp 2',\t'Weight ULDs in Comp 2', 'Weight BAX ULDs in Comp 2', 'Number of ULDs in Comp 3',\n",
    "        'Number of BAX ULDs in Comp 3', 'Weight ULDs in Comp 3', 'Weight BAX ULDs in Comp 3', 'Number of ULDs in Comp 4',\t\n",
    "        'Number of BAX ULDs in Comp 4', 'Weight ULDs in Comp 4', 'Weight BAX ULDs in Comp 4'\n",
    "        ]\n",
    "\n",
    "        df = df[col_order]\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def style_baseline_results(self, df):\n",
    "        \"\"\"  \n",
    "        Style the results DataFrame\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to style.\n",
    "        \"\"\"\n",
    "        \n",
    "        last_two_indices = df.tail(2).index\n",
    "\n",
    "        df.replace('-', np.nan, inplace=True)\n",
    "\n",
    "        styled_df = (df.style\n",
    "                    .apply(lambda x: ['font-weight: bold;' if x.name in last_two_indices else '' for _ in x], axis=1)\n",
    "                    .format({\n",
    "                        'Fuel Deviation Percentage': '{:.3%}',\n",
    "                        'Fuel Deviation': '{:,.3f} kg',\n",
    "                        'TOW': '{:,.1f} kg',\n",
    "                        'Total Run Time': '{:.2f} s',\n",
    "                        'Total 1D BPP Time': '{:.2f} s',\n",
    "                        'Total 3D BPP Time': '{:.2f} s',\n",
    "                        'Total WB Time': '{:.2f} s',\n",
    "                        '%MAC ZFW': '{:.4f}',\n",
    "                        'Actual %MAC ZFW': '{:.4f}',\n",
    "                        'ULDs Built by Model': '{:,.0f}',\n",
    "                        'ULDs Actually Used': '{:,.0f}',\n",
    "                        'Number of BAX ULDs': '{:,.0f}',\n",
    "                        'Number of BUP ULDs': '{:,.0f}',\n",
    "                        'Number of T ULDs': '{:,.0f}',\n",
    "                        'Number of PAX A': '{:,.0f}',\n",
    "                        'Number of PAX B': '{:,.0f}',\n",
    "                        'Number of PAX C': '{:,.0f}',\n",
    "                        'Number of PAX D': '{:,.0f}',\n",
    "                        'Number of PAX E': '{:,.0f}',\n",
    "                        'Number of PAX F': '{:,.0f}',\n",
    "                        'Number of PAX G': '{:,.0f}',\n",
    "                        'Total PAX': '{:,.0f}',\n",
    "                        'Number of items': '{:,.0f}',\n",
    "                        'Weight in Comp 1': '{:,.1f} kg',\n",
    "                        'Weight in Comp 2': '{:,.1f} kg',\n",
    "                        'Weight in Comp 3': '{:,.1f} kg',\n",
    "                        'Weight in Comp 4': '{:,.1f} kg',\n",
    "                        'Number of ULDs in Comp 1': '{:,.0f}',\n",
    "                        'Number of BAX ULDs in Comp 1': '{:,.0f}',\n",
    "                        'Weight ULDs in Comp 1': '{:,.1f} kg',\n",
    "                        'Weight BAX ULDs in Comp 1': '{:,.1f} kg',\n",
    "                        'Number of ULDs in Comp 2': '{:,.0f}',\n",
    "                        'Number of BAX ULDs in Comp 2': '{:,.0f}',\n",
    "                        'Weight ULDs in Comp 2': '{:,.1f} kg',\n",
    "                        'Weight BAX ULDs in Comp 2': '{:,.1f} kg',\n",
    "                        'Number of ULDs in Comp 3': '{:,.0f}',\n",
    "                        'Number of BAX ULDs in Comp 3': '{:,.0f}',\n",
    "                        'Weight ULDs in Comp 3': '{:,.1f} kg',\n",
    "                        'Weight BAX ULDs in Comp 3': '{:,.1f} kg',\n",
    "                        'Number of ULDs in Comp 4': '{:,.0f}',\n",
    "                        'Number of BAX ULDs in Comp 4': '{:,.0f}',\n",
    "                        'Weight ULDs in Comp 4': '{:,.1f} kg',\n",
    "                        'Weight BAX ULDs in Comp 4': '{:,.1f} kg'\n",
    "                    }, na_rep='')\n",
    "                    .hide(axis='index')\n",
    "                    # Apply bar only to numeric columns that do not have 'Total' or 'Average' in the index\n",
    "                    .set_table_styles({\n",
    "                        'A': [{'selector': 'th', 'props': [('text-align', 'left')]}],\n",
    "                        'B': [{'selector': 'td', 'props': [('text-align', 'center')]}]\n",
    "                    }, overwrite=False)\n",
    "                    .set_properties(subset=['Flight Number'], **{'text-align': 'left'})\n",
    "                    .set_table_attributes('style=\"font-size: 13px; border: 1px solid black;\"')\n",
    "                    .set_caption(f\"Results for {self.departure_airport} to {self.arrival_airport} in {self.month} {self.year}\"))\n",
    "        \n",
    "            \n",
    "        return styled_df\n",
    "    \n",
    "\n",
    "    def read_individual_flight_results(self, flight_folder):\n",
    "        \"\"\"\n",
    "        Read the results for an individual flight\n",
    "\n",
    "        Args:\n",
    "            flight_folder (str): The folder path to the flight results.\n",
    "        \"\"\"\n",
    "        model_info_file = os.path.join(flight_folder, 'Model_Information.txt')\n",
    "        if not os.path.exists(model_info_file):\n",
    "            return None\n",
    "        \n",
    "        flight_number = os.path.basename(flight_folder).split(' ')[1]\n",
    "        flight_date = os.path.basename(flight_folder).split(' ')[3:6]\n",
    "        flight_date = ' '.join(flight_date)\n",
    "\n",
    "\n",
    "        results = {\n",
    "            'Flight Number': flight_number,\n",
    "            'Flight Date': flight_date,\n",
    "        }\n",
    "\n",
    "        results_file = os.path.join(flight_folder, 'Results.txt')\n",
    "        model_info_file = os.path.join(flight_folder, 'Model_Information.txt')\n",
    "        general_info_file = os.path.join(flight_folder, 'General_Information.txt')\n",
    "        CG_info_file = os.path.join(flight_folder, 'CG_info.png')\n",
    "\n",
    "        with open(general_info_file, 'r') as file:\n",
    "            content = file.read()\n",
    "            aircraft_type_match = re.search(r'Aircraft Type: ([\\d\\w]+) ', content)\n",
    "            if aircraft_type_match:\n",
    "                self.aircraft_type = aircraft_type_match.group(1) \n",
    "\n",
    "            aircraft_registration_match = re.search(r'Flight Number: ([\\w\\d]+) ([\\w\\d]+)', content)\n",
    "            if aircraft_registration_match:\n",
    "                self.aircraft_registration = aircraft_registration_match.group(2)\n",
    "\n",
    "            TOW_match = re.search(r'TOW: ([\\d.]+) kg', content)\n",
    "            if TOW_match:\n",
    "                self.TOW = float(TOW_match.group(1))\n",
    "\n",
    "            results['Number of BAX ULDs'] = int(re.search(r'Number of BAX ULDs: (\\d+)', content).group(1))\n",
    "            results['Number of BUP ULDs'] = int(re.search(r'Number of BUP ULDs: (\\d+)', content).group(1))\n",
    "            results['Number of T ULDs'] = int(re.search(r'Number of T ULDs: (\\d+)', content).group(1))\n",
    "            \n",
    "            results['Number of PAX A'] = int(re.search(r'PAX-A: (\\d+)', content).group(1))\n",
    "            results['Number of PAX B'] = int(re.search(r'PAX-B: (\\d+)', content).group(1))\n",
    "            results['Number of PAX C'] = int(re.search(r'PAX-C: (\\d+)', content).group(1))\n",
    "            results['Number of PAX D'] = int(re.search(r'PAX-D: (\\d+)', content).group(1))\n",
    "            results['Number of PAX E'] = int(re.search(r'PAX-E: (\\d+)', content).group(1))\n",
    "            results['Number of PAX F'] = int(re.search(r'PAX-F: (\\d+)', content).group(1))\n",
    "            results['Number of PAX G'] = int(re.search(r'PAX-G: (\\d+)', content).group(1))\n",
    "            total_pax = int(re.search(r'Total PAX: (\\d+)', content).group(1))\n",
    "            results['Total PAX'] = total_pax\n",
    "\n",
    "            items_fit = int(re.search(r'(\\d+) / \\d+ items fit the dimensions of the ULDs', content).group(1))\n",
    "            results['Number of items'] = items_fit\n",
    "\n",
    "        # Read and process the Results.txt file\n",
    "        with open(results_file, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "            fuel_data = re.search(r\"Resulting in a fuel deviation of ([\\-\\d.]+)% or ([\\-\\d.]+) kg\", content)\n",
    "            if fuel_data:\n",
    "                fuel_percentage = float(fuel_data.group(1)) / 100\n",
    "                fuel_kg = float(fuel_data.group(2))\n",
    "\n",
    "                self.fuel_reduction_percentage = fuel_percentage\n",
    "                self.fuel_reduction_kg = fuel_kg\n",
    "\n",
    "            uld_data = re.search(r\"(\\d+) ULDs are built by the model\\n(\\d+) ULDs were actually built\", content)\n",
    "            if uld_data:\n",
    "                self.uld_built_by_model = int(uld_data.group(1))\n",
    "                self.uld_actually_used = int(uld_data.group(2))\n",
    "\n",
    "            mac_data = re.search(r\"%MAC ZFW is ([\\d.]+)\", content)\n",
    "            if mac_data:\n",
    "                self.MAC = float(mac_data.group(1))\n",
    "\n",
    "            mac_actual = re.search(r'The actual %MAC ZFW for this flight was ([\\d.]+)', content)\n",
    "            if mac_actual:\n",
    "                self.MAC_actual = float(mac_actual.group(1))\n",
    "\n",
    "            weight_uld_comp_1 = 0\n",
    "            weight_uld_comp_2 = 0\n",
    "            weight_uld_comp_3 = 0\n",
    "            weight_uld_comp_4 = 0\n",
    "            count_uld_comp_1 = 0\n",
    "            count_uld_comp_2 = 0\n",
    "            count_uld_comp_3 = 0\n",
    "            count_uld_comp_4 = 0\n",
    "\n",
    "            weight_bax_comp_1 = 0\n",
    "            weight_bax_comp_2 = 0\n",
    "            weight_bax_comp_3 = 0\n",
    "            weight_bax_comp_4 = 0\n",
    "            count_bax_comp_1 = 0\n",
    "            count_bax_comp_2 = 0\n",
    "            count_bax_comp_3 = 0\n",
    "            count_bax_comp_4 = 0\n",
    "\n",
    "            pattern = r'ULD (\\w+-?\\d*) with weight ([\\d.]+) kg.*position (\\d+)'\n",
    "\n",
    "            for match in re.finditer(pattern, content):\n",
    "                uld_type = match.group(1)\n",
    "                weight = float(match.group(2))\n",
    "                compartment = int(match.group(3)[0])\n",
    "\n",
    "                if 'BAX' not in str(uld_type):\n",
    "                    if compartment == 1:\n",
    "                        count_uld_comp_1 += 1\n",
    "                        weight_uld_comp_1 += weight\n",
    "                    elif compartment == 2:\n",
    "                        count_uld_comp_2 += 1\n",
    "                        weight_uld_comp_2 += weight\n",
    "                    elif compartment == 3:\n",
    "                        count_uld_comp_3 += 1\n",
    "                        weight_uld_comp_3 += weight\n",
    "                    elif compartment == 4:\n",
    "                        count_uld_comp_4 += 1\n",
    "                        weight_uld_comp_4 += weight\n",
    "\n",
    "                if 'BAX' in str(uld_type):\n",
    "                    if compartment == 1:\n",
    "                        count_bax_comp_1 += 1\n",
    "                        weight_bax_comp_1 += weight\n",
    "                    elif compartment == 2:\n",
    "                        count_bax_comp_2 += 1\n",
    "                        weight_bax_comp_2 += weight\n",
    "                    elif compartment == 3:\n",
    "                        count_bax_comp_3 += 1\n",
    "                        weight_bax_comp_3 += weight\n",
    "                    elif compartment == 4:\n",
    "                        count_bax_comp_4 += 1\n",
    "                        weight_bax_comp_4 += weight\n",
    "\n",
    "        results['Aircraft Type'] = self.aircraft_type\n",
    "        results['Aircraft Registration'] = self.aircraft_registration\n",
    "        results['%MAC ZFW'] = self.MAC\n",
    "        results['Actual %MAC ZFW'] = self.MAC_actual\n",
    "        results['Fuel Deviation Percentage'] = self.fuel_reduction_percentage\n",
    "        results['Fuel Deviation'] = self.fuel_reduction_kg\n",
    "        results['TOW'] = self.TOW\n",
    "        results['ULDs Built by Model'] = self.uld_built_by_model\n",
    "        results['ULDs Actually Used'] = self.uld_actually_used\n",
    "        results['Weight in Comp 1'] = float(re.search(r'Weight in Compartment 1: ([\\d.]+)', content).group(1))\n",
    "        results['Weight in Comp 2'] = float(re.search(r'Weight in Compartment 2: ([\\d.]+)', content).group(1))\n",
    "        results['Weight in Comp 3'] = float(re.search(r'Weight in Compartment 3: ([\\d.]+)', content).group(1))\n",
    "        results['Weight in Comp 4'] = float(re.search(r'Weight in Compartment 4: ([\\d.]+)', content).group(1))\n",
    "        results['Number of ULDs in Comp 1'] = count_uld_comp_1\n",
    "        results['Number of BAX ULDs in Comp 1'] = count_bax_comp_1\n",
    "        results['Weight ULDs in Comp 1'] = weight_uld_comp_1\n",
    "        results['Weight BAX ULDs in Comp 1'] = weight_bax_comp_1\n",
    "        results['Number of ULDs in Comp 2'] = count_uld_comp_2\n",
    "        results['Number of BAX ULDs in Comp 2'] = count_bax_comp_2\n",
    "        results['Weight ULDs in Comp 2'] = weight_uld_comp_2\n",
    "        results['Weight BAX ULDs in Comp 2'] = weight_bax_comp_2\n",
    "        results['Number of ULDs in Comp 3'] = count_uld_comp_3\n",
    "        results['Number of BAX ULDs in Comp 3'] = count_bax_comp_3\n",
    "        results['Weight ULDs in Comp 3'] = weight_uld_comp_3\n",
    "        results['Weight BAX ULDs in Comp 3'] = weight_bax_comp_3\n",
    "        results['Number of ULDs in Comp 4'] = count_uld_comp_4\n",
    "        results['Number of BAX ULDs in Comp 4'] = count_bax_comp_4\n",
    "        results['Weight ULDs in Comp 4'] = weight_uld_comp_4\n",
    "        results['Weight BAX ULDs in Comp 4'] = weight_bax_comp_4\n",
    "\n",
    "        with open(model_info_file, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "            total_time_data = re.search(r\"Total time: ([\\d.]+) seconds\", content)\n",
    "            if total_time_data:\n",
    "                self.total_run_time = float(total_time_data.group(1))\n",
    "\n",
    "            total_1D_BPP_data = re.search(r\"Total time 1D BPP: ([\\d.]+) seconds\", content)\n",
    "            if total_1D_BPP_data:\n",
    "                self.total_1D_BPP_time = float(total_1D_BPP_data.group(1))\n",
    "\n",
    "            total_3D_BPP_data = re.search(r\"Total time 3D BPP: ([\\d.]+) seconds\", content)\n",
    "            if total_3D_BPP_data:\n",
    "                self.total_3D_BPP_time = float(total_3D_BPP_data.group(1))\n",
    "\n",
    "            total_WB_data = re.search(r\"Total time WB: ([\\d.]+) seconds\", content)\n",
    "            if total_WB_data:\n",
    "                self.total_WB_time = float(total_WB_data.group(1))\n",
    "\n",
    "        results['Total Run Time'] = self.total_run_time\n",
    "        results['Total 1D BPP Time'] = self.total_1D_BPP_time\n",
    "        results['Total 3D BPP Time'] = self.total_3D_BPP_time\n",
    "        results['Total WB Time'] = self.total_WB_time\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultsReaderOptimizedActual():\n",
    "    def __init__(self, departure_airport = None, arrival_airport = None, month = None, year = None):\n",
    "        self.departure_airport = departure_airport\n",
    "        self.arrival_airport = arrival_airport\n",
    "        self.month = month\n",
    "        self.year = year\n",
    "        self.aircraft_type = None\n",
    "        self.aircraft_registration = None\n",
    "        self.fuel_reduction_percentage = 0\n",
    "        self.fuel_reduction_kg = 0\n",
    "        self.uld_built_by_model = 0\n",
    "        self.uld_actually_used = 0\n",
    "        self.total_run_time = 0\n",
    "        self.total_1D_BPP_time = 0\n",
    "        self.total_3D_BPP_time = 0\n",
    "        self.total_WB_time = 0\n",
    "        self.MAC = 0\n",
    "        self.MAC_actual = 0\n",
    "        self.TOW = 0\n",
    "\n",
    "\n",
    "    def read_all_results(self):\n",
    "        \"\"\"\n",
    "        Read all the results from the results folder\n",
    "        \"\"\"\n",
    "        results = []\n",
    "\n",
    "        base_dir = 'Results_Optimized_Actual'\n",
    "\n",
    "        for root, dirs, files in os.walk(base_dir):\n",
    "            for dir_name in dirs:\n",
    "                if dir_name.startswith('Results '):  # Check if directory name starts with 'Results'\n",
    "                    full_path = os.path.join(root, dir_name)\n",
    "                    pattern = os.path.join(full_path, 'Flight *')\n",
    "                    flights = glob.glob(pattern)\n",
    "\n",
    "                    for flight in flights:\n",
    "                        result = self.read_individual_flight_results(flight)\n",
    "                        if result:\n",
    "                            results.append(result)\n",
    "        \n",
    "        df = pd.DataFrame(results)\n",
    "\n",
    "        sum_data = {\n",
    "            'Flight Number': 'Total',\n",
    "            'Flight Date': '-',\n",
    "            'Fuel Deviation Percentage': '-',\n",
    "            'Fuel Deviation': df['Fuel Deviation'].sum(),\n",
    "            'TOW': df['TOW'].sum(),\n",
    "            'ULDs Built by Model': df['ULDs Built by Model'].sum(),\n",
    "            'ULDs Actually Used': df['ULDs Actually Used'].sum(),\n",
    "            '%MAC ZFW': '-',\n",
    "            'Actual %MAC ZFW': '-',\n",
    "            'Total Run Time': df['Total Run Time'].sum(),\n",
    "            'Number of BAX ULDs': df['Number of BAX ULDs'].sum(),\n",
    "            'Number of BUP ULDs': df['Number of BUP ULDs'].sum(),\n",
    "            'Number of T ULDs': df['Number of T ULDs'].sum(),\n",
    "            'Number of PAX A': '-',\n",
    "            'Number of PAX B': '-',\n",
    "            'Number of PAX C': '-',\n",
    "            'Number of PAX D': '-',\n",
    "            'Number of PAX E': '-',\n",
    "            'Number of PAX F': '-',\n",
    "            'Number of PAX G': '-',\n",
    "            'Total PAX': '-',\n",
    "            'Number of items': df['Number of items'].sum(),\n",
    "            'Weight in Comp 1': df['Weight in Comp 1'].sum(),\n",
    "            'Weight in Comp 2': df['Weight in Comp 2'].sum(),\n",
    "            'Weight in Comp 3': df['Weight in Comp 3'].sum(),\n",
    "            'Weight in Comp 4': df['Weight in Comp 4'].sum(),\n",
    "            'Number of ULDs in Comp 1': df['Number of ULDs in Comp 1'].sum(),\n",
    "            'Number of BAX ULDs in Comp 1': df['Number of BAX ULDs in Comp 1'].sum(),\n",
    "            'Weight ULDs in Comp 1': df['Weight ULDs in Comp 1'].sum(),\n",
    "            'Weight BAX ULDs in Comp 1': df['Weight BAX ULDs in Comp 1'].sum(),\n",
    "            'Number of ULDs in Comp 2': df['Number of ULDs in Comp 2'].sum(),\n",
    "            'Number of BAX ULDs in Comp 2': df['Number of BAX ULDs in Comp 2'].sum(),\n",
    "            'Weight ULDs in Comp 2': df['Weight ULDs in Comp 2'].sum(),\n",
    "            'Weight BAX ULDs in Comp 2': df['Weight BAX ULDs in Comp 2'].sum(),\n",
    "            'Number of ULDs in Comp 3': df['Number of ULDs in Comp 3'].sum(),\n",
    "            'Number of BAX ULDs in Comp 3': df['Number of BAX ULDs in Comp 3'].sum(),\n",
    "            'Weight ULDs in Comp 3': df['Weight ULDs in Comp 3'].sum(),\n",
    "            'Weight BAX ULDs in Comp 3': df['Weight BAX ULDs in Comp 3'].sum(),\n",
    "            'Number of ULDs in Comp 4': df['Number of ULDs in Comp 4'].sum(),\n",
    "            'Number of BAX ULDs in Comp 4': df['Number of BAX ULDs in Comp 4'].sum(),\n",
    "            'Weight ULDs in Comp 4': df['Weight ULDs in Comp 4'].sum(),\n",
    "            'Weight BAX ULDs in Comp 4': df['Weight BAX ULDs in Comp 4'].sum()\n",
    "        }\n",
    "\n",
    "        average_data = {\n",
    "            'Flight Number': 'Average',\n",
    "            'Flight Date': '-',\n",
    "            'Fuel Deviation Percentage': df['Fuel Deviation Percentage'].mean(),\n",
    "            'Fuel Deviation': df['Fuel Deviation'].mean(),\n",
    "            'TOW': df['TOW'].mean(),\n",
    "            'ULDs Built by Model': df['ULDs Built by Model'].mean(),\n",
    "            'ULDs Actually Used': df['ULDs Actually Used'].mean(),\n",
    "            '%MAC ZFW': df['%MAC ZFW'].mean(),\n",
    "            'Actual %MAC ZFW': df['Actual %MAC ZFW'].mean(),\n",
    "            'Total Run Time': df['Total Run Time'].mean(),\n",
    "            'Number of BAX ULDs': df['Number of BAX ULDs'].mean(),\n",
    "            'Number of BUP ULDs': df['Number of BUP ULDs'].mean(),\n",
    "            'Number of T ULDs': df['Number of T ULDs'].mean(),\n",
    "            'Number of PAX A': df['Number of PAX A'].mean(),\n",
    "            'Number of PAX B': df['Number of PAX B'].mean(),\n",
    "            'Number of PAX C': df['Number of PAX C'].mean(),\n",
    "            'Number of PAX D': df['Number of PAX D'].mean(),\n",
    "            'Number of PAX E': df['Number of PAX E'].mean(),\n",
    "            'Number of PAX F': df['Number of PAX F'].mean(),\n",
    "            'Number of PAX G': df['Number of PAX G'].mean(),\n",
    "            'Total PAX': df['Total PAX'].mean(),\n",
    "            'Number of items': df['Number of items'].mean(),\n",
    "            'Weight in Comp 1': df['Weight in Comp 1'].mean(),\n",
    "            'Weight in Comp 2': df['Weight in Comp 2'].mean(),\n",
    "            'Weight in Comp 3': df['Weight in Comp 3'].mean(),\n",
    "            'Weight in Comp 4': df['Weight in Comp 4'].mean(),\n",
    "            'Number of ULDs in Comp 1': df['Number of ULDs in Comp 1'].mean(),\n",
    "            'Number of BAX ULDs in Comp 1': df['Number of BAX ULDs in Comp 1'].mean(),\n",
    "            'Weight ULDs in Comp 1': df['Weight ULDs in Comp 1'].mean(),\n",
    "            'Weight BAX ULDs in Comp 1': df['Weight BAX ULDs in Comp 1'].mean(),\n",
    "            'Number of ULDs in Comp 2': df['Number of ULDs in Comp 2'].mean(),\n",
    "            'Number of BAX ULDs in Comp 2': df['Number of BAX ULDs in Comp 2'].mean(),\n",
    "            'Weight ULDs in Comp 2': df['Weight ULDs in Comp 2'].mean(),\n",
    "            'Weight BAX ULDs in Comp 2': df['Weight BAX ULDs in Comp 2'].mean(),\n",
    "            'Number of ULDs in Comp 3': df['Number of ULDs in Comp 3'].mean(),\n",
    "            'Number of BAX ULDs in Comp 3': df['Number of BAX ULDs in Comp 3'].mean(),\n",
    "            'Weight ULDs in Comp 3': df['Weight ULDs in Comp 3'].mean(),\n",
    "            'Weight BAX ULDs in Comp 3': df['Weight BAX ULDs in Comp 3'].mean(),\n",
    "            'Number of ULDs in Comp 4': df['Number of ULDs in Comp 4'].mean(),\n",
    "            'Number of BAX ULDs in Comp 4': df['Number of BAX ULDs in Comp 4'].mean(),\n",
    "            'Weight ULDs in Comp 4': df['Weight ULDs in Comp 4'].mean(),\n",
    "            'Weight BAX ULDs in Comp 4': df['Weight BAX ULDs in Comp 4'].mean()\n",
    "        }\n",
    "\n",
    "        sum_df = pd.DataFrame([sum_data])\n",
    "        average_df = pd.DataFrame([average_data])\n",
    "\n",
    "        df = pd.concat([df, sum_df, average_df], ignore_index=True)\n",
    "\n",
    "        col_order = ['Flight Number', 'Flight Date', 'Aircraft Type', 'Aircraft Registration', '%MAC ZFW', 'Actual %MAC ZFW', 'Fuel Deviation Percentage',\n",
    "        'Fuel Deviation', 'TOW', 'ULDs Built by Model', 'ULDs Actually Used', 'Total Run Time',\n",
    "        'Number of BAX ULDs', 'Number of BUP ULDs','Number of T ULDs', 'Number of PAX A', 'Number of PAX B', 'Number of PAX C',\n",
    "        'Number of PAX D', 'Number of PAX E', 'Number of PAX F', 'Number of PAX G', 'Total PAX', 'Number of items',\n",
    "        'Weight in Comp 1', 'Weight in Comp 2', 'Weight in Comp 3', 'Weight in Comp 4', 'Number of ULDs in Comp 1',\n",
    "        'Number of BAX ULDs in Comp 1',\t'Weight ULDs in Comp 1', 'Weight BAX ULDs in Comp 1', 'Number of ULDs in Comp 2',\n",
    "        'Number of BAX ULDs in Comp 2',\t'Weight ULDs in Comp 2', 'Weight BAX ULDs in Comp 2', 'Number of ULDs in Comp 3',\n",
    "        'Number of BAX ULDs in Comp 3', 'Weight ULDs in Comp 3', 'Weight BAX ULDs in Comp 3', 'Number of ULDs in Comp 4',\t\n",
    "        'Number of BAX ULDs in Comp 4', 'Weight ULDs in Comp 4', 'Weight BAX ULDs in Comp 4'\n",
    "        ]\n",
    "\n",
    "        df = df[col_order]\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    def read_results(self):\n",
    "        \"\"\"\n",
    "        Read the results from the results folder and display them in a DataFrame\n",
    "        \"\"\"\n",
    "\n",
    "        base_dir = 'Results_Optimized_Actual'\n",
    "        month_folder_name = f'Results {self.departure_airport}{self.arrival_airport} {self.month} {self.year}'\n",
    "        month_folder = os.path.join(base_dir, month_folder_name)\n",
    "        pattern = os.path.join(month_folder, 'Flight *')\n",
    "\n",
    "        flights = glob.glob(pattern)\n",
    "        results = []\n",
    "\n",
    "\n",
    "        for flight in flights:\n",
    "            result = self.read_individual_flight_results(flight)\n",
    "            if result is not None:\n",
    "                results.append(result)\n",
    "\n",
    "\n",
    "        df = pd.DataFrame(results)\n",
    "\n",
    "    \n",
    "        sum_data = {\n",
    "            'Flight Number': 'Total',\n",
    "            'Flight Date': '-',\n",
    "            'Fuel Deviation Percentage': '-',\n",
    "            'Fuel Deviation': df['Fuel Deviation'].sum(),\n",
    "            'TOW': df['TOW'].sum(),\n",
    "            'ULDs Built by Model': df['ULDs Built by Model'].sum(),\n",
    "            'ULDs Actually Used': df['ULDs Actually Used'].sum(),\n",
    "            '%MAC ZFW': '-',\n",
    "            'Actual %MAC ZFW': '-',\n",
    "            'Total Run Time': df['Total Run Time'].sum(),\n",
    "            'Number of BAX ULDs': df['Number of BAX ULDs'].sum(),\n",
    "            'Number of BUP ULDs': df['Number of BUP ULDs'].sum(),\n",
    "            'Number of T ULDs': df['Number of T ULDs'].sum(),\n",
    "            'Number of PAX A': '-',\n",
    "            'Number of PAX B': '-',\n",
    "            'Number of PAX C': '-',\n",
    "            'Number of PAX D': '-',\n",
    "            'Number of PAX E': '-',\n",
    "            'Number of PAX F': '-',\n",
    "            'Number of PAX G': '-',\n",
    "            'Total PAX': '-',\n",
    "            'Number of items': df['Number of items'].sum(),\n",
    "            'Weight in Comp 1': df['Weight in Comp 1'].sum(),\n",
    "            'Weight in Comp 2': df['Weight in Comp 2'].sum(),\n",
    "            'Weight in Comp 3': df['Weight in Comp 3'].sum(),\n",
    "            'Weight in Comp 4': df['Weight in Comp 4'].sum(),\n",
    "            'Number of ULDs in Comp 1': df['Number of ULDs in Comp 1'].sum(),\n",
    "            'Number of BAX ULDs in Comp 1': df['Number of BAX ULDs in Comp 1'].sum(),\n",
    "            'Weight ULDs in Comp 1': df['Weight ULDs in Comp 1'].sum(),\n",
    "            'Weight BAX ULDs in Comp 1': df['Weight BAX ULDs in Comp 1'].sum(),\n",
    "            'Number of ULDs in Comp 2': df['Number of ULDs in Comp 2'].sum(),\n",
    "            'Number of BAX ULDs in Comp 2': df['Number of BAX ULDs in Comp 2'].sum(),\n",
    "            'Weight ULDs in Comp 2': df['Weight ULDs in Comp 2'].sum(),\n",
    "            'Weight BAX ULDs in Comp 2': df['Weight BAX ULDs in Comp 2'].sum(),\n",
    "            'Number of ULDs in Comp 3': df['Number of ULDs in Comp 3'].sum(),\n",
    "            'Number of BAX ULDs in Comp 3': df['Number of BAX ULDs in Comp 3'].sum(),\n",
    "            'Weight ULDs in Comp 3': df['Weight ULDs in Comp 3'].sum(),\n",
    "            'Weight BAX ULDs in Comp 3': df['Weight BAX ULDs in Comp 3'].sum(),\n",
    "            'Number of ULDs in Comp 4': df['Number of ULDs in Comp 4'].sum(),\n",
    "            'Number of BAX ULDs in Comp 4': df['Number of BAX ULDs in Comp 4'].sum(),\n",
    "            'Weight ULDs in Comp 4': df['Weight ULDs in Comp 4'].sum(),\n",
    "            'Weight BAX ULDs in Comp 4': df['Weight BAX ULDs in Comp 4'].sum()\n",
    "        }\n",
    "\n",
    "        average_data = {\n",
    "            'Flight Number': 'Average',\n",
    "            'Flight Date': '-',\n",
    "            'Fuel Deviation Percentage': df['Fuel Deviation Percentage'].mean(),\n",
    "            'Fuel Deviation': df['Fuel Deviation'].mean(),\n",
    "            'TOW': df['TOW'].mean(),\n",
    "            'ULDs Built by Model': df['ULDs Built by Model'].mean(),\n",
    "            'ULDs Actually Used': df['ULDs Actually Used'].mean(),\n",
    "            '%MAC ZFW': df['%MAC ZFW'].mean(),\n",
    "            'Actual %MAC ZFW': df['Actual %MAC ZFW'].mean(),\n",
    "            'Total Run Time': df['Total Run Time'].mean(),\n",
    "            'Number of BAX ULDs': df['Number of BAX ULDs'].mean(),\n",
    "            'Number of BUP ULDs': df['Number of BUP ULDs'].mean(),\n",
    "            'Number of T ULDs': df['Number of T ULDs'].mean(),\n",
    "            'Number of PAX A': df['Number of PAX A'].mean(),\n",
    "            'Number of PAX B': df['Number of PAX B'].mean(),\n",
    "            'Number of PAX C': df['Number of PAX C'].mean(),\n",
    "            'Number of PAX D': df['Number of PAX D'].mean(),\n",
    "            'Number of PAX E': df['Number of PAX E'].mean(),\n",
    "            'Number of PAX F': df['Number of PAX F'].mean(),\n",
    "            'Number of PAX G': df['Number of PAX G'].mean(),\n",
    "            'Total PAX': df['Total PAX'].mean(),\n",
    "            'Number of items': df['Number of items'].mean(),\n",
    "            'Weight in Comp 1': df['Weight in Comp 1'].mean(),\n",
    "            'Weight in Comp 2': df['Weight in Comp 2'].mean(),\n",
    "            'Weight in Comp 3': df['Weight in Comp 3'].mean(),\n",
    "            'Weight in Comp 4': df['Weight in Comp 4'].mean(),\n",
    "            'Number of ULDs in Comp 1': df['Number of ULDs in Comp 1'].mean(),\n",
    "            'Number of BAX ULDs in Comp 1': df['Number of BAX ULDs in Comp 1'].mean(),\n",
    "            'Weight ULDs in Comp 1': df['Weight ULDs in Comp 1'].mean(),\n",
    "            'Weight BAX ULDs in Comp 1': df['Weight BAX ULDs in Comp 1'].mean(),\n",
    "            'Number of ULDs in Comp 2': df['Number of ULDs in Comp 2'].mean(),\n",
    "            'Number of BAX ULDs in Comp 2': df['Number of BAX ULDs in Comp 2'].mean(),\n",
    "            'Weight ULDs in Comp 2': df['Weight ULDs in Comp 2'].mean(),\n",
    "            'Weight BAX ULDs in Comp 2': df['Weight BAX ULDs in Comp 2'].mean(),\n",
    "            'Number of ULDs in Comp 3': df['Number of ULDs in Comp 3'].mean(),\n",
    "            'Number of BAX ULDs in Comp 3': df['Number of BAX ULDs in Comp 3'].mean(),\n",
    "            'Weight ULDs in Comp 3': df['Weight ULDs in Comp 3'].mean(),\n",
    "            'Weight BAX ULDs in Comp 3': df['Weight BAX ULDs in Comp 3'].mean(),\n",
    "            'Number of ULDs in Comp 4': df['Number of ULDs in Comp 4'].mean(),\n",
    "            'Number of BAX ULDs in Comp 4': df['Number of BAX ULDs in Comp 4'].mean(),\n",
    "            'Weight ULDs in Comp 4': df['Weight ULDs in Comp 4'].mean(),\n",
    "            'Weight BAX ULDs in Comp 4': df['Weight BAX ULDs in Comp 4'].mean()\n",
    "            \n",
    "        }\n",
    "\n",
    "        sum_df = pd.DataFrame([sum_data])\n",
    "        average_df = pd.DataFrame([average_data])\n",
    "\n",
    "        df = pd.concat([df, sum_df, average_df], ignore_index=True)\n",
    "\n",
    "        col_order = ['Flight Number', 'Flight Date', 'Aircraft Type', 'Aircraft Registration', '%MAC ZFW', 'Actual %MAC ZFW', 'Fuel Deviation Percentage',\n",
    "        'Fuel Deviation', 'TOW', 'ULDs Built by Model', 'ULDs Actually Used', 'Total Run Time',\n",
    "        'Number of BAX ULDs', 'Number of BUP ULDs','Number of T ULDs', 'Number of PAX A', 'Number of PAX B', 'Number of PAX C',\n",
    "        'Number of PAX D', 'Number of PAX E', 'Number of PAX F', 'Number of PAX G', 'Total PAX', 'Number of items',\n",
    "        'Weight in Comp 1', 'Weight in Comp 2', 'Weight in Comp 3', 'Weight in Comp 4', 'Number of ULDs in Comp 1',\n",
    "        'Number of BAX ULDs in Comp 1',\t'Weight ULDs in Comp 1', 'Weight BAX ULDs in Comp 1', 'Number of ULDs in Comp 2',\n",
    "        'Number of BAX ULDs in Comp 2',\t'Weight ULDs in Comp 2', 'Weight BAX ULDs in Comp 2', 'Number of ULDs in Comp 3',\n",
    "        'Number of BAX ULDs in Comp 3', 'Weight ULDs in Comp 3', 'Weight BAX ULDs in Comp 3', 'Number of ULDs in Comp 4',\t\n",
    "        'Number of BAX ULDs in Comp 4', 'Weight ULDs in Comp 4', 'Weight BAX ULDs in Comp 4'\n",
    "        ]\n",
    "\n",
    "        df = df[col_order]\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def style_baseline_results(self, df):\n",
    "        \"\"\"  \n",
    "        Style the results DataFrame\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to style.\n",
    "        \"\"\"\n",
    "        \n",
    "        last_two_indices = df.tail(2).index\n",
    "\n",
    "        df.replace('-', np.nan, inplace=True)\n",
    "\n",
    "        styled_df = (df.style\n",
    "                    .apply(lambda x: ['font-weight: bold;' if x.name in last_two_indices else '' for _ in x], axis=1)\n",
    "                    .format({\n",
    "                        'Fuel Deviation Percentage': '{:.3%}',\n",
    "                        'Fuel Deviation': '{:,.3f} kg',\n",
    "                        'TOW': '{:,.1f} kg',\n",
    "                        'Total Run Time': '{:.2f} s',\n",
    "                        '%MAC ZFW': '{:.4f}',\n",
    "                        'Actual %MAC ZFW': '{:.4f}',\n",
    "                        'ULDs Built by Model': '{:,.0f}',\n",
    "                        'ULDs Actually Used': '{:,.0f}',\n",
    "                        'Number of BAX ULDs': '{:,.0f}',\n",
    "                        'Number of BUP ULDs': '{:,.0f}',\n",
    "                        'Number of T ULDs': '{:,.0f}',\n",
    "                        'Number of PAX A': '{:,.0f}',\n",
    "                        'Number of PAX B': '{:,.0f}',\n",
    "                        'Number of PAX C': '{:,.0f}',\n",
    "                        'Number of PAX D': '{:,.0f}',\n",
    "                        'Number of PAX E': '{:,.0f}',\n",
    "                        'Number of PAX F': '{:,.0f}',\n",
    "                        'Number of PAX G': '{:,.0f}',\n",
    "                        'Total PAX': '{:,.0f}',\n",
    "                        'Number of items': '{:,.0f}',\n",
    "                        'Weight in Comp 1': '{:,.1f} kg',\n",
    "                        'Weight in Comp 2': '{:,.1f} kg',\n",
    "                        'Weight in Comp 3': '{:,.1f} kg',\n",
    "                        'Weight in Comp 4': '{:,.1f} kg',\n",
    "                        'Number of ULDs in Comp 1': '{:,.0f}',\n",
    "                        'Number of BAX ULDs in Comp 1': '{:,.0f}',\n",
    "                        'Weight ULDs in Comp 1': '{:,.1f} kg',\n",
    "                        'Weight BAX ULDs in Comp 1': '{:,.1f} kg',\n",
    "                        'Number of ULDs in Comp 2': '{:,.0f}',\n",
    "                        'Number of BAX ULDs in Comp 2': '{:,.0f}',\n",
    "                        'Weight ULDs in Comp 2': '{:,.1f} kg',\n",
    "                        'Weight BAX ULDs in Comp 2': '{:,.1f} kg',\n",
    "                        'Number of ULDs in Comp 3': '{:,.0f}',\n",
    "                        'Number of BAX ULDs in Comp 3': '{:,.0f}',\n",
    "                        'Weight ULDs in Comp 3': '{:,.1f} kg',\n",
    "                        'Weight BAX ULDs in Comp 3': '{:,.1f} kg',\n",
    "                        'Number of ULDs in Comp 4': '{:,.0f}',\n",
    "                        'Number of BAX ULDs in Comp 4': '{:,.0f}',\n",
    "                        'Weight ULDs in Comp 4': '{:,.1f} kg',\n",
    "                        'Weight BAX ULDs in Comp 4': '{:,.1f} kg',\n",
    "                    }, na_rep='')\n",
    "                    .hide(axis='index')\n",
    "                    # Apply bar only to numeric columns that do not have 'Total' or 'Average' in the index\n",
    "                    .set_table_styles({\n",
    "                        'A': [{'selector': 'th', 'props': [('text-align', 'left')]}],\n",
    "                        'B': [{'selector': 'td', 'props': [('text-align', 'center')]}]\n",
    "                    }, overwrite=False)\n",
    "                    .set_properties(subset=['Flight Number'], **{'text-align': 'left'})\n",
    "                    .set_table_attributes('style=\"font-size: 13px; border: 1px solid black;\"')\n",
    "                    .set_caption(f\"Results for {self.departure_airport} to {self.arrival_airport} in {self.month} {self.year}\"))\n",
    "        \n",
    "            \n",
    "        return styled_df\n",
    "    \n",
    "\n",
    "    def read_individual_flight_results(self, flight_folder):\n",
    "        \"\"\"\n",
    "        Read the results for an individual flight\n",
    "\n",
    "        Args:\n",
    "            flight_folder (str): The folder path to the flight results.\n",
    "        \"\"\"\n",
    "        model_info_file = os.path.join(flight_folder, 'Model_Information.txt')\n",
    "        if not os.path.exists(model_info_file):\n",
    "            return None\n",
    "        \n",
    "        flight_number = os.path.basename(flight_folder).split(' ')[1]\n",
    "        flight_date = os.path.basename(flight_folder).split(' ')[3:6]\n",
    "        flight_date = ' '.join(flight_date)\n",
    "\n",
    "\n",
    "        results = {\n",
    "            'Flight Number': flight_number,\n",
    "            'Flight Date': flight_date,\n",
    "        }\n",
    "\n",
    "        results_file = os.path.join(flight_folder, 'Results.txt')\n",
    "        model_info_file = os.path.join(flight_folder, 'Model_Information.txt')\n",
    "        general_info_file = os.path.join(flight_folder, 'General_Information.txt')\n",
    "        CG_info_file = os.path.join(flight_folder, 'CG_envelope.png')\n",
    "\n",
    "        with open(general_info_file, 'r') as file:\n",
    "            content = file.read()\n",
    "            aircraft_type_match = re.search(r'Aircraft Type: ([\\d\\w]+) ', content)\n",
    "            if aircraft_type_match:\n",
    "                self.aircraft_type = aircraft_type_match.group(1)\n",
    "\n",
    "            aircraft_registration_match = re.search(r'Flight Number: ([\\w\\d]+) ([\\w\\d]+)', content)\n",
    "            if aircraft_registration_match:\n",
    "                self.aircraft_registration = aircraft_registration_match.group(2)\n",
    "\n",
    "            TOW_match = re.search(r'TOW: ([\\d.]+) kg', content)\n",
    "            if TOW_match:\n",
    "                self.TOW = float(TOW_match.group(1))\n",
    "            \n",
    "            results['Number of BAX ULDs'] = int(re.search(r'Number of BAX ULDs: (\\d+)', content).group(1))\n",
    "            results['Number of BUP ULDs'] = int(re.search(r'Number of BUP ULDs: (\\d+)', content).group(1))\n",
    "            results['Number of T ULDs'] = int(re.search(r'Number of T ULDs: (\\d+)', content).group(1))\n",
    "            \n",
    "            results['Number of PAX A'] = int(re.search(r'PAX-A: (\\d+)', content).group(1))\n",
    "            results['Number of PAX B'] = int(re.search(r'PAX-B: (\\d+)', content).group(1))\n",
    "            results['Number of PAX C'] = int(re.search(r'PAX-C: (\\d+)', content).group(1))\n",
    "            results['Number of PAX D'] = int(re.search(r'PAX-D: (\\d+)', content).group(1))\n",
    "            results['Number of PAX E'] = int(re.search(r'PAX-E: (\\d+)', content).group(1))\n",
    "            results['Number of PAX F'] = int(re.search(r'PAX-F: (\\d+)', content).group(1))\n",
    "            results['Number of PAX G'] = int(re.search(r'PAX-G: (\\d+)', content).group(1))\n",
    "            total_pax = int(re.search(r'Total PAX: (\\d+)', content).group(1))\n",
    "            results['Total PAX'] = total_pax\n",
    "\n",
    "            items_fit = int(re.search(r'(\\d+) / \\d+ items fit the dimensions of the ULDs', content).group(1))\n",
    "            results['Number of items'] = items_fit\n",
    "\n",
    "        # Read and process the Results.txt file\n",
    "        with open(results_file, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "            fuel_data = re.search(r\"Resulting in a fuel deviation of ([\\-\\d.]+)% or ([\\-\\d.]+) kg\", content)\n",
    "            if fuel_data:\n",
    "                fuel_percentage = float(fuel_data.group(1)) / 100\n",
    "                fuel_kg = float(fuel_data.group(2))\n",
    "\n",
    "                self.fuel_reduction_percentage = fuel_percentage\n",
    "                self.fuel_reduction_kg = fuel_kg\n",
    "\n",
    "            uld_data = re.search(r\"(\\d+) ULDs are built by the model\\n(\\d+) ULDs were actually built\", content)\n",
    "            if uld_data:\n",
    "                self.uld_built_by_model = int(uld_data.group(1))\n",
    "                self.uld_actually_used = int(uld_data.group(2))\n",
    "\n",
    "            mac_data = re.search(r\"%MAC ZFW is ([\\d.]+)\", content)\n",
    "            if mac_data:\n",
    "                self.MAC = float(mac_data.group(1))\n",
    "\n",
    "            mac_actual = re.search(r'The actual %MAC ZFW for this flight was ([\\d.]+)', content)\n",
    "            if mac_actual:\n",
    "                self.MAC_actual = float(mac_actual.group(1))\n",
    "\n",
    "            weight_uld_comp_1 = 0\n",
    "            weight_uld_comp_2 = 0\n",
    "            weight_uld_comp_3 = 0\n",
    "            weight_uld_comp_4 = 0\n",
    "            count_uld_comp_1 = 0\n",
    "            count_uld_comp_2 = 0\n",
    "            count_uld_comp_3 = 0\n",
    "            count_uld_comp_4 = 0\n",
    "\n",
    "            weight_bax_comp_1 = 0\n",
    "            weight_bax_comp_2 = 0\n",
    "            weight_bax_comp_3 = 0\n",
    "            weight_bax_comp_4 = 0\n",
    "            count_bax_comp_1 = 0\n",
    "            count_bax_comp_2 = 0\n",
    "            count_bax_comp_3 = 0\n",
    "            count_bax_comp_4 = 0\n",
    "\n",
    "            pattern = r'ULD (\\w+-?\\d*) with weight ([\\d.]+) kg.*position (\\d+)'\n",
    "\n",
    "            for match in re.finditer(pattern, content):\n",
    "                uld_type = match.group(1)\n",
    "                weight = float(match.group(2))\n",
    "                compartment = int(match.group(3)[0])\n",
    "\n",
    "                if 'BAX' not in str(uld_type):\n",
    "                    if compartment == 1:\n",
    "                        count_uld_comp_1 += 1\n",
    "                        weight_uld_comp_1 += weight\n",
    "                    elif compartment == 2:\n",
    "                        count_uld_comp_2 += 1\n",
    "                        weight_uld_comp_2 += weight\n",
    "                    elif compartment == 3:\n",
    "                        count_uld_comp_3 += 1\n",
    "                        weight_uld_comp_3 += weight\n",
    "                    elif compartment == 4:\n",
    "                        count_uld_comp_4 += 1\n",
    "                        weight_uld_comp_4 += weight\n",
    "\n",
    "                if 'BAX' in str(uld_type):\n",
    "                    if compartment == 1:\n",
    "                        count_bax_comp_1 += 1\n",
    "                        weight_bax_comp_1 += weight\n",
    "                    elif compartment == 2:\n",
    "                        count_bax_comp_2 += 1\n",
    "                        weight_bax_comp_2 += weight\n",
    "                    elif compartment == 3:\n",
    "                        count_bax_comp_3 += 1\n",
    "                        weight_bax_comp_3 += weight\n",
    "                    elif compartment == 4:\n",
    "                        count_bax_comp_4 += 1\n",
    "                        weight_bax_comp_4 += weight\n",
    "\n",
    "            results['Aircraft Type'] = self.aircraft_type\n",
    "            results['Aircraft Registration'] = self.aircraft_registration\n",
    "            results['%MAC ZFW'] = self.MAC\n",
    "            results['Actual %MAC ZFW'] = self.MAC_actual\n",
    "            results['Fuel Deviation Percentage'] = self.fuel_reduction_percentage\n",
    "            results['Fuel Deviation'] = self.fuel_reduction_kg\n",
    "            results['TOW'] = self.TOW\n",
    "            results['ULDs Built by Model'] = self.uld_built_by_model\n",
    "            results['ULDs Actually Used'] = self.uld_actually_used\n",
    "            results['Weight in Comp 1'] = float(re.search(r'Weight in Compartment 1: ([\\d.]+)', content).group(1))\n",
    "            results['Weight in Comp 2'] = float(re.search(r'Weight in Compartment 2: ([\\d.]+)', content).group(1))\n",
    "            results['Weight in Comp 3'] = float(re.search(r'Weight in Compartment 3: ([\\d.]+)', content).group(1))\n",
    "            results['Weight in Comp 4'] = float(re.search(r'Weight in Compartment 4: ([\\d.]+)', content).group(1))\n",
    "            results['Number of ULDs in Comp 1'] = count_uld_comp_1\n",
    "            results['Number of BAX ULDs in Comp 1'] = count_bax_comp_1\n",
    "            results['Weight ULDs in Comp 1'] = weight_uld_comp_1\n",
    "            results['Weight BAX ULDs in Comp 1'] = weight_bax_comp_1\n",
    "            results['Number of ULDs in Comp 2'] = count_uld_comp_2\n",
    "            results['Number of BAX ULDs in Comp 2'] = count_bax_comp_2\n",
    "            results['Weight ULDs in Comp 2'] = weight_uld_comp_2\n",
    "            results['Weight BAX ULDs in Comp 2'] = weight_bax_comp_2\n",
    "            results['Number of ULDs in Comp 3'] = count_uld_comp_3\n",
    "            results['Number of BAX ULDs in Comp 3'] = count_bax_comp_3\n",
    "            results['Weight ULDs in Comp 3'] = weight_uld_comp_3\n",
    "            results['Weight BAX ULDs in Comp 3'] = weight_bax_comp_3\n",
    "            results['Number of ULDs in Comp 4'] = count_uld_comp_4\n",
    "            results['Number of BAX ULDs in Comp 4'] = count_bax_comp_4\n",
    "            results['Weight ULDs in Comp 4'] = weight_uld_comp_4\n",
    "            results['Weight BAX ULDs in Comp 4'] = weight_bax_comp_4\n",
    "\n",
    "        with open(model_info_file, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "            total_time_data = re.search(r\"Total time: ([\\d.]+) seconds\", content)\n",
    "            if total_time_data:\n",
    "                self.total_run_time = float(total_time_data.group(1))\n",
    "\n",
    "\n",
    "        results['Total Run Time'] = self.total_run_time\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultsReaderBAXFixed():\n",
    "    def __init__(self, departure_airport = None, arrival_airport = None, month = None, year = None):\n",
    "        self.departure_airport = departure_airport\n",
    "        self.arrival_airport = arrival_airport\n",
    "        self.month = month\n",
    "        self.year = year\n",
    "        self.aircraft_type = None\n",
    "        self.aircraft_registration = None\n",
    "        self.fuel_reduction_percentage = 0\n",
    "        self.fuel_reduction_kg = 0\n",
    "        self.uld_built_by_model = 0\n",
    "        self.uld_actually_used = 0\n",
    "        self.total_run_time = 0\n",
    "        self.total_1D_BPP_time = 0\n",
    "        self.total_3D_BPP_time = 0\n",
    "        self.total_WB_time = 0\n",
    "        self.MAC = 0\n",
    "        self.MAC_actual = 0\n",
    "        self.TOW = 0\n",
    "\n",
    "\n",
    "    def read_all_results(self):\n",
    "        \"\"\"\n",
    "        Read all the results from the results folder\n",
    "        \"\"\"\n",
    "        results = []\n",
    "\n",
    "        base_dir = 'Results_BAX_Fixed'\n",
    "\n",
    "        for root, dirs, files in os.walk(base_dir):\n",
    "            for dir_name in dirs:\n",
    "                if dir_name.startswith('Results '):  # Check if directory name starts with 'Results'\n",
    "                    full_path = os.path.join(root, dir_name)\n",
    "                    pattern = os.path.join(full_path, 'Flight *')\n",
    "                    flights = glob.glob(pattern)\n",
    "\n",
    "                    for flight in flights:\n",
    "                        result = self.read_individual_flight_results(flight)\n",
    "                        if result:\n",
    "                            results.append(result)\n",
    "        \n",
    "        df = pd.DataFrame(results)\n",
    "\n",
    "        sum_data = {\n",
    "            'Flight Number': 'Total',\n",
    "            'Flight Date': '-',\n",
    "            'Fuel Deviation Percentage': '-',\n",
    "            'Fuel Deviation': df['Fuel Deviation'].sum(),\n",
    "            'TOW': df['TOW'].sum(),\n",
    "            'ULDs Built by Model': df['ULDs Built by Model'].sum(),\n",
    "            'ULDs Actually Used': df['ULDs Actually Used'].sum(),\n",
    "            '%MAC ZFW': '-',\n",
    "            'Actual %MAC ZFW': '-',\n",
    "            'Total Run Time': df['Total Run Time'].sum(),\n",
    "            'Number of BAX ULDs': df['Number of BAX ULDs'].sum(),\n",
    "            'Number of BUP ULDs': df['Number of BUP ULDs'].sum(),\n",
    "            'Number of T ULDs': df['Number of T ULDs'].sum(),\n",
    "            'Number of PAX A': '-',\n",
    "            'Number of PAX B': '-',\n",
    "            'Number of PAX C': '-',\n",
    "            'Number of PAX D': '-',\n",
    "            'Number of PAX E': '-',\n",
    "            'Number of PAX F': '-',\n",
    "            'Number of PAX G': '-',\n",
    "            'Total PAX': '-',\n",
    "            'Number of items': df['Number of items'].sum(),\n",
    "            'Weight in Comp 1': df['Weight in Comp 1'].sum(),\n",
    "            'Weight in Comp 2': df['Weight in Comp 2'].sum(),\n",
    "            'Weight in Comp 3': df['Weight in Comp 3'].sum(),\n",
    "            'Weight in Comp 4': df['Weight in Comp 4'].sum(),\n",
    "            'Number of ULDs in Comp 1': df['Number of ULDs in Comp 1'].sum(),\n",
    "            'Number of BAX ULDs in Comp 1': df['Number of BAX ULDs in Comp 1'].sum(),\n",
    "            'Weight ULDs in Comp 1': df['Weight ULDs in Comp 1'].sum(),\n",
    "            'Weight BAX ULDs in Comp 1': df['Weight BAX ULDs in Comp 1'].sum(),\n",
    "            'Number of ULDs in Comp 2': df['Number of ULDs in Comp 2'].sum(),\n",
    "            'Number of BAX ULDs in Comp 2': df['Number of BAX ULDs in Comp 2'].sum(),\n",
    "            'Weight ULDs in Comp 2': df['Weight ULDs in Comp 2'].sum(),\n",
    "            'Weight BAX ULDs in Comp 2': df['Weight BAX ULDs in Comp 2'].sum(),\n",
    "            'Number of ULDs in Comp 3': df['Number of ULDs in Comp 3'].sum(),\n",
    "            'Number of BAX ULDs in Comp 3': df['Number of BAX ULDs in Comp 3'].sum(),\n",
    "            'Weight ULDs in Comp 3': df['Weight ULDs in Comp 3'].sum(),\n",
    "            'Weight BAX ULDs in Comp 3': df['Weight BAX ULDs in Comp 3'].sum(),\n",
    "            'Number of ULDs in Comp 4': df['Number of ULDs in Comp 4'].sum(),\n",
    "            'Number of BAX ULDs in Comp 4': df['Number of BAX ULDs in Comp 4'].sum(),\n",
    "            'Weight ULDs in Comp 4': df['Weight ULDs in Comp 4'].sum(),\n",
    "            'Weight BAX ULDs in Comp 4': df['Weight BAX ULDs in Comp 4'].sum()\n",
    "        }\n",
    "\n",
    "        average_data = {\n",
    "            'Flight Number': 'Average',\n",
    "            'Flight Date': '-',\n",
    "            'Fuel Deviation Percentage': df['Fuel Deviation Percentage'].mean(),\n",
    "            'Fuel Deviation': df['Fuel Deviation'].mean(),\n",
    "            'TOW': df['TOW'].mean(),\n",
    "            'ULDs Built by Model': df['ULDs Built by Model'].mean(),\n",
    "            'ULDs Actually Used': df['ULDs Actually Used'].mean(),\n",
    "            '%MAC ZFW': df['%MAC ZFW'].mean(),\n",
    "            'Actual %MAC ZFW': df['Actual %MAC ZFW'].mean(),\n",
    "            'Total Run Time': df['Total Run Time'].mean(),\n",
    "            'Number of BAX ULDs': df['Number of BAX ULDs'].mean(),\n",
    "            'Number of BUP ULDs': df['Number of BUP ULDs'].mean(),\n",
    "            'Number of T ULDs': df['Number of T ULDs'].mean(),\n",
    "            'Number of PAX A': df['Number of PAX A'].mean(),\n",
    "            'Number of PAX B': df['Number of PAX B'].mean(),\n",
    "            'Number of PAX C': df['Number of PAX C'].mean(),\n",
    "            'Number of PAX D': df['Number of PAX D'].mean(),\n",
    "            'Number of PAX E': df['Number of PAX E'].mean(),\n",
    "            'Number of PAX F': df['Number of PAX F'].mean(),\n",
    "            'Number of PAX G': df['Number of PAX G'].mean(),\n",
    "            'Total PAX': df['Total PAX'].mean(),\n",
    "            'Number of items': df['Number of items'].mean(),\n",
    "            'Weight in Comp 1': df['Weight in Comp 1'].mean(),\n",
    "            'Weight in Comp 2': df['Weight in Comp 2'].mean(),\n",
    "            'Weight in Comp 3': df['Weight in Comp 3'].mean(),\n",
    "            'Weight in Comp 4': df['Weight in Comp 4'].mean(),\n",
    "            'Number of ULDs in Comp 1': df['Number of ULDs in Comp 1'].mean(),\n",
    "            'Number of BAX ULDs in Comp 1': df['Number of BAX ULDs in Comp 1'].mean(),\n",
    "            'Weight ULDs in Comp 1': df['Weight ULDs in Comp 1'].mean(),\n",
    "            'Weight BAX ULDs in Comp 1': df['Weight BAX ULDs in Comp 1'].mean(),\n",
    "            'Number of ULDs in Comp 2': df['Number of ULDs in Comp 2'].mean(),\n",
    "            'Number of BAX ULDs in Comp 2': df['Number of BAX ULDs in Comp 2'].mean(),\n",
    "            'Weight ULDs in Comp 2': df['Weight ULDs in Comp 2'].mean(),\n",
    "            'Weight BAX ULDs in Comp 2': df['Weight BAX ULDs in Comp 2'].mean(),\n",
    "            'Number of ULDs in Comp 3': df['Number of ULDs in Comp 3'].mean(),\n",
    "            'Number of BAX ULDs in Comp 3': df['Number of BAX ULDs in Comp 3'].mean(),\n",
    "            'Weight ULDs in Comp 3': df['Weight ULDs in Comp 3'].mean(),\n",
    "            'Weight BAX ULDs in Comp 3': df['Weight BAX ULDs in Comp 3'].mean(),\n",
    "            'Number of ULDs in Comp 4': df['Number of ULDs in Comp 4'].mean(),\n",
    "            'Number of BAX ULDs in Comp 4': df['Number of BAX ULDs in Comp 4'].mean(),\n",
    "            'Weight ULDs in Comp 4': df['Weight ULDs in Comp 4'].mean(),\n",
    "            'Weight BAX ULDs in Comp 4': df['Weight BAX ULDs in Comp 4'].mean()\n",
    "        }\n",
    "\n",
    "        sum_df = pd.DataFrame([sum_data])\n",
    "        average_df = pd.DataFrame([average_data])\n",
    "\n",
    "        df = pd.concat([df, sum_df, average_df], ignore_index=True)\n",
    "\n",
    "        col_order = ['Flight Number', 'Flight Date', 'Aircraft Type', 'Aircraft Registration', '%MAC ZFW', 'Actual %MAC ZFW', 'Fuel Deviation Percentage',\n",
    "        'Fuel Deviation', 'TOW', 'ULDs Built by Model', 'ULDs Actually Used', 'Total Run Time',\n",
    "        'Number of BAX ULDs', 'Number of BUP ULDs','Number of T ULDs', 'Number of PAX A', 'Number of PAX B', 'Number of PAX C',\n",
    "        'Number of PAX D', 'Number of PAX E', 'Number of PAX F', 'Number of PAX G', 'Total PAX', 'Number of items',\n",
    "        'Weight in Comp 1', 'Weight in Comp 2', 'Weight in Comp 3', 'Weight in Comp 4', 'Number of ULDs in Comp 1',\n",
    "        'Number of BAX ULDs in Comp 1',\t'Weight ULDs in Comp 1', 'Weight BAX ULDs in Comp 1', 'Number of ULDs in Comp 2',\n",
    "        'Number of BAX ULDs in Comp 2',\t'Weight ULDs in Comp 2', 'Weight BAX ULDs in Comp 2', 'Number of ULDs in Comp 3',\n",
    "        'Number of BAX ULDs in Comp 3', 'Weight ULDs in Comp 3', 'Weight BAX ULDs in Comp 3', 'Number of ULDs in Comp 4',\t\n",
    "        'Number of BAX ULDs in Comp 4', 'Weight ULDs in Comp 4', 'Weight BAX ULDs in Comp 4'\n",
    "        ]\n",
    "\n",
    "        df = df[col_order]\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    def read_results(self):\n",
    "        \"\"\"\n",
    "        Read the results from the results folder and display them in a DataFrame\n",
    "        \"\"\"\n",
    "\n",
    "        base_dir = 'Results_BAX_Fixed'\n",
    "        month_folder_name = f'Results {self.departure_airport}{self.arrival_airport} {self.month} {self.year}'\n",
    "        month_folder = os.path.join(base_dir, month_folder_name)\n",
    "        pattern = os.path.join(month_folder, 'Flight *')\n",
    "\n",
    "        flights = glob.glob(pattern)\n",
    "        results = []\n",
    "\n",
    "\n",
    "        for flight in flights:\n",
    "            result = self.read_individual_flight_results(flight)\n",
    "            if result is not None:\n",
    "                results.append(result)\n",
    "\n",
    "\n",
    "        df = pd.DataFrame(results)\n",
    "\n",
    "    \n",
    "        sum_data = {\n",
    "            'Flight Number': 'Total',\n",
    "            'Flight Date': '-',\n",
    "            'Fuel Deviation Percentage': '-',\n",
    "            'Fuel Deviation': df['Fuel Deviation'].sum(),\n",
    "            'TOW': df['TOW'].sum(),\n",
    "            'ULDs Built by Model': df['ULDs Built by Model'].sum(),\n",
    "            'ULDs Actually Used': df['ULDs Actually Used'].sum(),\n",
    "            '%MAC ZFW': '-',\n",
    "            'Actual %MAC ZFW': '-',\n",
    "            'Total Run Time': df['Total Run Time'].sum(),\n",
    "            'Number of BAX ULDs': df['Number of BAX ULDs'].sum(),\n",
    "            'Number of BUP ULDs': df['Number of BUP ULDs'].sum(),\n",
    "            'Number of T ULDs': df['Number of T ULDs'].sum(),\n",
    "            'Number of PAX A': '-',\n",
    "            'Number of PAX B': '-',\n",
    "            'Number of PAX C': '-',\n",
    "            'Number of PAX D': '-',\n",
    "            'Number of PAX E': '-',\n",
    "            'Number of PAX F': '-',\n",
    "            'Number of PAX G': '-',\n",
    "            'Total PAX': '-',\n",
    "            'Number of items': df['Number of items'].sum(),\n",
    "            'Weight in Comp 1': df['Weight in Comp 1'].sum(),\n",
    "            'Weight in Comp 2': df['Weight in Comp 2'].sum(),\n",
    "            'Weight in Comp 3': df['Weight in Comp 3'].sum(),\n",
    "            'Weight in Comp 4': df['Weight in Comp 4'].sum(),\n",
    "            'Number of ULDs in Comp 1': df['Number of ULDs in Comp 1'].sum(),\n",
    "            'Number of BAX ULDs in Comp 1': df['Number of BAX ULDs in Comp 1'].sum(),\n",
    "            'Weight ULDs in Comp 1': df['Weight ULDs in Comp 1'].sum(),\n",
    "            'Weight BAX ULDs in Comp 1': df['Weight BAX ULDs in Comp 1'].sum(),\n",
    "            'Number of ULDs in Comp 2': df['Number of ULDs in Comp 2'].sum(),\n",
    "            'Number of BAX ULDs in Comp 2': df['Number of BAX ULDs in Comp 2'].sum(),\n",
    "            'Weight ULDs in Comp 2': df['Weight ULDs in Comp 2'].sum(),\n",
    "            'Weight BAX ULDs in Comp 2': df['Weight BAX ULDs in Comp 2'].sum(),\n",
    "            'Number of ULDs in Comp 3': df['Number of ULDs in Comp 3'].sum(),\n",
    "            'Number of BAX ULDs in Comp 3': df['Number of BAX ULDs in Comp 3'].sum(),\n",
    "            'Weight ULDs in Comp 3': df['Weight ULDs in Comp 3'].sum(),\n",
    "            'Weight BAX ULDs in Comp 3': df['Weight BAX ULDs in Comp 3'].sum(),\n",
    "            'Number of ULDs in Comp 4': df['Number of ULDs in Comp 4'].sum(),\n",
    "            'Number of BAX ULDs in Comp 4': df['Number of BAX ULDs in Comp 4'].sum(),\n",
    "            'Weight ULDs in Comp 4': df['Weight ULDs in Comp 4'].sum(),\n",
    "            'Weight BAX ULDs in Comp 4': df['Weight BAX ULDs in Comp 4'].sum()\n",
    "        }\n",
    "\n",
    "        average_data = {\n",
    "            'Flight Number': 'Average',\n",
    "            'Flight Date': '-',\n",
    "            'Fuel Deviation Percentage': df['Fuel Deviation Percentage'].mean(),\n",
    "            'Fuel Deviation': df['Fuel Deviation'].mean(),\n",
    "            'TOW': df['TOW'].mean(),\n",
    "            'ULDs Built by Model': df['ULDs Built by Model'].mean(),\n",
    "            'ULDs Actually Used': df['ULDs Actually Used'].mean(),\n",
    "            '%MAC ZFW': df['%MAC ZFW'].mean(),\n",
    "            'Actual %MAC ZFW': df['Actual %MAC ZFW'].mean(),\n",
    "            'Total Run Time': df['Total Run Time'].mean(),\n",
    "            'Number of BAX ULDs': df['Number of BAX ULDs'].mean(),\n",
    "            'Number of BUP ULDs': df['Number of BUP ULDs'].mean(),\n",
    "            'Number of T ULDs': df['Number of T ULDs'].mean(),\n",
    "            'Number of PAX A': df['Number of PAX A'].mean(),\n",
    "            'Number of PAX B': df['Number of PAX B'].mean(),\n",
    "            'Number of PAX C': df['Number of PAX C'].mean(),\n",
    "            'Number of PAX D': df['Number of PAX D'].mean(),\n",
    "            'Number of PAX E': df['Number of PAX E'].mean(),\n",
    "            'Number of PAX F': df['Number of PAX F'].mean(),\n",
    "            'Number of PAX G': df['Number of PAX G'].mean(),\n",
    "            'Total PAX': df['Total PAX'].mean(),\n",
    "            'Number of items': df['Number of items'].mean(),\n",
    "            'Weight in Comp 1': df['Weight in Comp 1'].mean(),\n",
    "            'Weight in Comp 2': df['Weight in Comp 2'].mean(),\n",
    "            'Weight in Comp 3': df['Weight in Comp 3'].mean(),\n",
    "            'Weight in Comp 4': df['Weight in Comp 4'].mean(),\n",
    "            'Number of ULDs in Comp 1': df['Number of ULDs in Comp 1'].mean(),\n",
    "            'Number of BAX ULDs in Comp 1': df['Number of BAX ULDs in Comp 1'].mean(),\n",
    "            'Weight ULDs in Comp 1': df['Weight ULDs in Comp 1'].mean(),\n",
    "            'Weight BAX ULDs in Comp 1': df['Weight BAX ULDs in Comp 1'].mean(),\n",
    "            'Number of ULDs in Comp 2': df['Number of ULDs in Comp 2'].mean(),\n",
    "            'Number of BAX ULDs in Comp 2': df['Number of BAX ULDs in Comp 2'].mean(),\n",
    "            'Weight ULDs in Comp 2': df['Weight ULDs in Comp 2'].mean(),\n",
    "            'Weight BAX ULDs in Comp 2': df['Weight BAX ULDs in Comp 2'].mean(),\n",
    "            'Number of ULDs in Comp 3': df['Number of ULDs in Comp 3'].mean(),\n",
    "            'Number of BAX ULDs in Comp 3': df['Number of BAX ULDs in Comp 3'].mean(),\n",
    "            'Weight ULDs in Comp 3': df['Weight ULDs in Comp 3'].mean(),\n",
    "            'Weight BAX ULDs in Comp 3': df['Weight BAX ULDs in Comp 3'].mean(),\n",
    "            'Number of ULDs in Comp 4': df['Number of ULDs in Comp 4'].mean(),\n",
    "            'Number of BAX ULDs in Comp 4': df['Number of BAX ULDs in Comp 4'].mean(),\n",
    "            'Weight ULDs in Comp 4': df['Weight ULDs in Comp 4'].mean(),\n",
    "            'Weight BAX ULDs in Comp 4': df['Weight BAX ULDs in Comp 4'].mean()\n",
    "            \n",
    "        }\n",
    "\n",
    "        sum_df = pd.DataFrame([sum_data])\n",
    "        average_df = pd.DataFrame([average_data])\n",
    "\n",
    "        df = pd.concat([df, sum_df, average_df], ignore_index=True)\n",
    "\n",
    "        col_order = ['Flight Number', 'Flight Date', 'Aircraft Type', 'Aircraft Registration', '%MAC ZFW', 'Actual %MAC ZFW', 'Fuel Deviation Percentage',\n",
    "        'Fuel Deviation', 'TOW', 'ULDs Built by Model', 'ULDs Actually Used', 'Total Run Time',\n",
    "        'Number of BAX ULDs', 'Number of BUP ULDs','Number of T ULDs', 'Number of PAX A', 'Number of PAX B', 'Number of PAX C',\n",
    "        'Number of PAX D', 'Number of PAX E', 'Number of PAX F', 'Number of PAX G', 'Total PAX', 'Number of items',\n",
    "        'Weight in Comp 1', 'Weight in Comp 2', 'Weight in Comp 3', 'Weight in Comp 4', 'Number of ULDs in Comp 1',\n",
    "        'Number of BAX ULDs in Comp 1',\t'Weight ULDs in Comp 1', 'Weight BAX ULDs in Comp 1', 'Number of ULDs in Comp 2',\n",
    "        'Number of BAX ULDs in Comp 2',\t'Weight ULDs in Comp 2', 'Weight BAX ULDs in Comp 2', 'Number of ULDs in Comp 3',\n",
    "        'Number of BAX ULDs in Comp 3', 'Weight ULDs in Comp 3', 'Weight BAX ULDs in Comp 3', 'Number of ULDs in Comp 4',\t\n",
    "        'Number of BAX ULDs in Comp 4', 'Weight ULDs in Comp 4', 'Weight BAX ULDs in Comp 4'\n",
    "        ]\n",
    "\n",
    "        df = df[col_order]\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def style_baseline_results(self, df):\n",
    "        \"\"\"  \n",
    "        Style the results DataFrame\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to style.\n",
    "        \"\"\"\n",
    "        \n",
    "        last_two_indices = df.tail(2).index\n",
    "\n",
    "        df.replace('-', np.nan, inplace=True)\n",
    "\n",
    "        styled_df = (df.style\n",
    "                    .apply(lambda x: ['font-weight: bold;' if x.name in last_two_indices else '' for _ in x], axis=1)\n",
    "                    .format({\n",
    "                        'Fuel Deviation Percentage': '{:.3%}',\n",
    "                        'Fuel Deviation': '{:,.3f} kg',\n",
    "                        'TOW': '{:,.1f} kg',\n",
    "                        'Total Run Time': '{:.2f} s',\n",
    "                        '%MAC ZFW': '{:.4f}',\n",
    "                        'Actual %MAC ZFW': '{:.4f}',\n",
    "                        'ULDs Built by Model': '{:,.0f}',\n",
    "                        'ULDs Actually Used': '{:,.0f}',\n",
    "                        'Number of BAX ULDs': '{:,.0f}',\n",
    "                        'Number of BUP ULDs': '{:,.0f}',\n",
    "                        'Number of T ULDs': '{:,.0f}',\n",
    "                        'Number of PAX A': '{:,.0f}',\n",
    "                        'Number of PAX B': '{:,.0f}',\n",
    "                        'Number of PAX C': '{:,.0f}',\n",
    "                        'Number of PAX D': '{:,.0f}',\n",
    "                        'Number of PAX E': '{:,.0f}',\n",
    "                        'Number of PAX F': '{:,.0f}',\n",
    "                        'Number of PAX G': '{:,.0f}',\n",
    "                        'Total PAX': '{:,.0f}',\n",
    "                        'Number of items': '{:,.0f}',\n",
    "                        'Weight in Comp 1': '{:,.1f} kg',\n",
    "                        'Weight in Comp 2': '{:,.1f} kg',\n",
    "                        'Weight in Comp 3': '{:,.1f} kg',\n",
    "                        'Weight in Comp 4': '{:,.1f} kg',\n",
    "                        'Number of ULDs in Comp 1': '{:,.0f}',\n",
    "                        'Number of BAX ULDs in Comp 1': '{:,.0f}',\n",
    "                        'Weight ULDs in Comp 1': '{:,.1f} kg',\n",
    "                        'Weight BAX ULDs in Comp 1': '{:,.1f} kg',\n",
    "                        'Number of ULDs in Comp 2': '{:,.0f}',\n",
    "                        'Number of BAX ULDs in Comp 2': '{:,.0f}',\n",
    "                        'Weight ULDs in Comp 2': '{:,.1f} kg',\n",
    "                        'Weight BAX ULDs in Comp 2': '{:,.1f} kg',\n",
    "                        'Number of ULDs in Comp 3': '{:,.0f}',\n",
    "                        'Number of BAX ULDs in Comp 3': '{:,.0f}',\n",
    "                        'Weight ULDs in Comp 3': '{:,.1f} kg',\n",
    "                        'Weight BAX ULDs in Comp 3': '{:,.1f} kg',\n",
    "                        'Number of ULDs in Comp 4': '{:,.0f}',\n",
    "                        'Number of BAX ULDs in Comp 4': '{:,.0f}',\n",
    "                        'Weight ULDs in Comp 4': '{:,.1f} kg',\n",
    "                        'Weight BAX ULDs in Comp 4': '{:,.1f} kg',\n",
    "                    }, na_rep='')\n",
    "                    .hide(axis='index')\n",
    "                    # Apply bar only to numeric columns that do not have 'Total' or 'Average' in the index\n",
    "                    .set_table_styles({\n",
    "                        'A': [{'selector': 'th', 'props': [('text-align', 'left')]}],\n",
    "                        'B': [{'selector': 'td', 'props': [('text-align', 'center')]}]\n",
    "                    }, overwrite=False)\n",
    "                    .set_properties(subset=['Flight Number'], **{'text-align': 'left'})\n",
    "                    .set_table_attributes('style=\"font-size: 13px; border: 1px solid black;\"')\n",
    "                    .set_caption(f\"Results for {self.departure_airport} to {self.arrival_airport} in {self.month} {self.year}\"))\n",
    "        \n",
    "            \n",
    "        return styled_df\n",
    "    \n",
    "\n",
    "    def read_individual_flight_results(self, flight_folder):\n",
    "        \"\"\"\n",
    "        Read the results for an individual flight\n",
    "\n",
    "        Args:\n",
    "            flight_folder (str): The folder path to the flight results.\n",
    "        \"\"\"\n",
    "        model_info_file = os.path.join(flight_folder, 'Model_Information.txt')\n",
    "        if not os.path.exists(model_info_file):\n",
    "            return None\n",
    "        \n",
    "        flight_number = os.path.basename(flight_folder).split(' ')[1]\n",
    "        flight_date = os.path.basename(flight_folder).split(' ')[3:6]\n",
    "        flight_date = ' '.join(flight_date)\n",
    "\n",
    "\n",
    "        results = {\n",
    "            'Flight Number': flight_number,\n",
    "            'Flight Date': flight_date,\n",
    "        }\n",
    "\n",
    "        results_file = os.path.join(flight_folder, 'Results.txt')\n",
    "        model_info_file = os.path.join(flight_folder, 'Model_Information.txt')\n",
    "        general_info_file = os.path.join(flight_folder, 'General_Information.txt')\n",
    "        CG_info_file = os.path.join(flight_folder, 'CG_envelope.png')\n",
    "\n",
    "        with open(general_info_file, 'r') as file:\n",
    "            content = file.read()\n",
    "            aircraft_type_match = re.search(r'Aircraft Type: ([\\d\\w]+) ', content)\n",
    "            if aircraft_type_match:\n",
    "                self.aircraft_type = aircraft_type_match.group(1)\n",
    "\n",
    "            aircraft_registration_match = re.search(r'Flight Number: ([\\w\\d]+) ([\\w\\d]+)', content)\n",
    "            if aircraft_registration_match:\n",
    "                self.aircraft_registration = aircraft_registration_match.group(2)\n",
    "\n",
    "            TOW_match = re.search(r'TOW: ([\\d.]+) kg', content)\n",
    "            if TOW_match:\n",
    "                self.TOW = float(TOW_match.group(1))\n",
    "            \n",
    "            results['Number of BAX ULDs'] = int(re.search(r'Number of BAX ULDs: (\\d+)', content).group(1))\n",
    "            results['Number of BUP ULDs'] = int(re.search(r'Number of BUP ULDs: (\\d+)', content).group(1))\n",
    "            results['Number of T ULDs'] = int(re.search(r'Number of T ULDs: (\\d+)', content).group(1))\n",
    "            \n",
    "            results['Number of PAX A'] = int(re.search(r'PAX-A: (\\d+)', content).group(1))\n",
    "            results['Number of PAX B'] = int(re.search(r'PAX-B: (\\d+)', content).group(1))\n",
    "            results['Number of PAX C'] = int(re.search(r'PAX-C: (\\d+)', content).group(1))\n",
    "            results['Number of PAX D'] = int(re.search(r'PAX-D: (\\d+)', content).group(1))\n",
    "            results['Number of PAX E'] = int(re.search(r'PAX-E: (\\d+)', content).group(1))\n",
    "            results['Number of PAX F'] = int(re.search(r'PAX-F: (\\d+)', content).group(1))\n",
    "            results['Number of PAX G'] = int(re.search(r'PAX-G: (\\d+)', content).group(1))\n",
    "            total_pax = int(re.search(r'Total PAX: (\\d+)', content).group(1))\n",
    "            results['Total PAX'] = total_pax\n",
    "\n",
    "            items_fit = int(re.search(r'(\\d+) / \\d+ items fit the dimensions of the ULDs', content).group(1))\n",
    "            results['Number of items'] = items_fit\n",
    "\n",
    "        # Read and process the Results.txt file\n",
    "        with open(results_file, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "            fuel_data = re.search(r\"Resulting in a fuel deviation of ([\\-\\d.]+)% or ([\\-\\d.]+) kg\", content)\n",
    "            if fuel_data:\n",
    "                fuel_percentage = float(fuel_data.group(1)) / 100\n",
    "                fuel_kg = float(fuel_data.group(2))\n",
    "\n",
    "                self.fuel_reduction_percentage = fuel_percentage\n",
    "                self.fuel_reduction_kg = fuel_kg\n",
    "\n",
    "            uld_data = re.search(r\"(\\d+) ULDs are built by the model\\n(\\d+) ULDs were actually built\", content)\n",
    "            if uld_data:\n",
    "                self.uld_built_by_model = int(uld_data.group(1))\n",
    "                self.uld_actually_used = int(uld_data.group(2))\n",
    "\n",
    "            mac_data = re.search(r\"%MAC ZFW is ([\\d.]+)\", content)\n",
    "            if mac_data:\n",
    "                self.MAC = float(mac_data.group(1))\n",
    "\n",
    "            mac_actual = re.search(r'The actual %MAC ZFW for this flight was ([\\d.]+)', content)\n",
    "            if mac_actual:\n",
    "                self.MAC_actual = float(mac_actual.group(1))\n",
    "\n",
    "            weight_uld_comp_1 = 0\n",
    "            weight_uld_comp_2 = 0\n",
    "            weight_uld_comp_3 = 0\n",
    "            weight_uld_comp_4 = 0\n",
    "            count_uld_comp_1 = 0\n",
    "            count_uld_comp_2 = 0\n",
    "            count_uld_comp_3 = 0\n",
    "            count_uld_comp_4 = 0\n",
    "\n",
    "            weight_bax_comp_1 = 0\n",
    "            weight_bax_comp_2 = 0\n",
    "            weight_bax_comp_3 = 0\n",
    "            weight_bax_comp_4 = 0\n",
    "            count_bax_comp_1 = 0\n",
    "            count_bax_comp_2 = 0\n",
    "            count_bax_comp_3 = 0\n",
    "            count_bax_comp_4 = 0\n",
    "\n",
    "            pattern = r'ULD (\\w+-?\\d*) with weight ([\\d.]+) kg.*position (\\d+)'\n",
    "\n",
    "            for match in re.finditer(pattern, content):\n",
    "                uld_type = match.group(1)\n",
    "                weight = float(match.group(2))\n",
    "                compartment = int(match.group(3)[0])\n",
    "\n",
    "                if 'BAX' not in str(uld_type):\n",
    "                    if compartment == 1:\n",
    "                        count_uld_comp_1 += 1\n",
    "                        weight_uld_comp_1 += weight\n",
    "                    elif compartment == 2:\n",
    "                        count_uld_comp_2 += 1\n",
    "                        weight_uld_comp_2 += weight\n",
    "                    elif compartment == 3:\n",
    "                        count_uld_comp_3 += 1\n",
    "                        weight_uld_comp_3 += weight\n",
    "                    elif compartment == 4:\n",
    "                        count_uld_comp_4 += 1\n",
    "                        weight_uld_comp_4 += weight\n",
    "\n",
    "                if 'BAX' in str(uld_type):\n",
    "                    if compartment == 1:\n",
    "                        count_bax_comp_1 += 1\n",
    "                        weight_bax_comp_1 += weight\n",
    "                    elif compartment == 2:\n",
    "                        count_bax_comp_2 += 1\n",
    "                        weight_bax_comp_2 += weight\n",
    "                    elif compartment == 3:\n",
    "                        count_bax_comp_3 += 1\n",
    "                        weight_bax_comp_3 += weight\n",
    "                    elif compartment == 4:\n",
    "                        count_bax_comp_4 += 1\n",
    "                        weight_bax_comp_4 += weight\n",
    "\n",
    "            results['Aircraft Type'] = self.aircraft_type\n",
    "            results['Aircraft Registration'] = self.aircraft_registration\n",
    "            results['%MAC ZFW'] = self.MAC\n",
    "            results['Actual %MAC ZFW'] = self.MAC_actual\n",
    "            results['Fuel Deviation Percentage'] = self.fuel_reduction_percentage\n",
    "            results['Fuel Deviation'] = self.fuel_reduction_kg\n",
    "            results['TOW'] = self.TOW\n",
    "            results['ULDs Built by Model'] = self.uld_built_by_model\n",
    "            results['ULDs Actually Used'] = self.uld_actually_used\n",
    "            results['Weight in Comp 1'] = float(re.search(r'Weight in Compartment 1: ([\\d.]+)', content).group(1))\n",
    "            results['Weight in Comp 2'] = float(re.search(r'Weight in Compartment 2: ([\\d.]+)', content).group(1))\n",
    "            results['Weight in Comp 3'] = float(re.search(r'Weight in Compartment 3: ([\\d.]+)', content).group(1))\n",
    "            results['Weight in Comp 4'] = float(re.search(r'Weight in Compartment 4: ([\\d.]+)', content).group(1))\n",
    "            results['Number of ULDs in Comp 1'] = count_uld_comp_1\n",
    "            results['Number of BAX ULDs in Comp 1'] = count_bax_comp_1\n",
    "            results['Weight ULDs in Comp 1'] = weight_uld_comp_1\n",
    "            results['Weight BAX ULDs in Comp 1'] = weight_bax_comp_1\n",
    "            results['Number of ULDs in Comp 2'] = count_uld_comp_2\n",
    "            results['Number of BAX ULDs in Comp 2'] = count_bax_comp_2\n",
    "            results['Weight ULDs in Comp 2'] = weight_uld_comp_2\n",
    "            results['Weight BAX ULDs in Comp 2'] = weight_bax_comp_2\n",
    "            results['Number of ULDs in Comp 3'] = count_uld_comp_3\n",
    "            results['Number of BAX ULDs in Comp 3'] = count_bax_comp_3\n",
    "            results['Weight ULDs in Comp 3'] = weight_uld_comp_3\n",
    "            results['Weight BAX ULDs in Comp 3'] = weight_bax_comp_3\n",
    "            results['Number of ULDs in Comp 4'] = count_uld_comp_4\n",
    "            results['Number of BAX ULDs in Comp 4'] = count_bax_comp_4\n",
    "            results['Weight ULDs in Comp 4'] = weight_uld_comp_4\n",
    "            results['Weight BAX ULDs in Comp 4'] = weight_bax_comp_4\n",
    "\n",
    "        with open(model_info_file, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "            total_time_data = re.search(r\"Total time: ([\\d.]+) seconds\", content)\n",
    "            if total_time_data:\n",
    "                self.total_run_time = float(total_time_data.group(1))\n",
    "\n",
    "\n",
    "        results['Total Run Time'] = self.total_run_time\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedResults():\n",
    "    def __init__(self):\n",
    "        self.results_reader = ResultsReader()\n",
    "        self.results_reader_baseline = ResultsReaderBaseline()\n",
    "        self.results_reader_optimized_actual = ResultsReaderOptimizedActual()\n",
    "        self.results_reader_bax_fixed = ResultsReaderBAXFixed()\n",
    "        self.model_results = self.results_reader.read_all_results()\n",
    "        self.baseline_results = self.results_reader_baseline.read_all_results()\n",
    "        self.optimized_actual_results = self.results_reader_optimized_actual.read_all_results()\n",
    "        self.bax_fixed_results = self.results_reader_bax_fixed.read_all_results()   \n",
    "        self.combined_results = None\n",
    "        self.combined_results_MAC = None\n",
    "        self.combined_results_fuel_deviation = None\n",
    "\n",
    "    def compare_results(self):\n",
    "        \"\"\"\n",
    "        Compare the results of the model with the baseline results\n",
    "        \"\"\"\n",
    "        comparison = self.model_results.merge(self.baseline_results, on=['Flight Number', 'Flight Date', 'Aircraft Type', 'Aircraft Registration', 'TOW'], suffixes=('_model', '_baseline'))\n",
    "        self.optimized_actual_results.columns = [col + '_optimized_actual' if col not in ['Flight Number', 'Flight Date', 'Aircraft Type', 'Aircraft Registration', 'TOW'] else col for col in self.optimized_actual_results.columns]\n",
    "        comparison = comparison.merge(self.optimized_actual_results, on=['Flight Number', 'Flight Date', 'Aircraft Type', 'Aircraft Registration', 'TOW'], suffixes=('', '_optimized_actual'))\n",
    "        self.bax_fixed_results.columns = [col + '_bax_fixed' if col not in ['Flight Number', 'Flight Date', 'Aircraft Type', 'Aircraft Registration', 'TOW'] else col for col in self.bax_fixed_results.columns]\n",
    "        comparison = comparison.merge(self.bax_fixed_results, on=['Flight Number', 'Flight Date', 'Aircraft Type', 'Aircraft Registration', 'TOW'], suffixes=('', '_bax_fixed'))\n",
    "\n",
    "        data_analysis = Data_Analysis()\n",
    "        df_COL_CRT = data_analysis.COL_and_CRT_analysis()\n",
    "\n",
    "        comparison = comparison.merge(df_COL_CRT, on=['Flight Number', 'Flight Date'], suffixes=('', ''))\n",
    "        comparison.dropna()\n",
    "        comparison = comparison[:-2]\n",
    "\n",
    "        columns_full = ['Flight Number', 'Flight Date', 'Aircraft Type', 'Aircraft Registration', 'TOW','IsCOL', 'IsCRT', 'IsCOLandCRT', '%MAC ZFW_model', 'Actual %MAC ZFW_model', 'Fuel Deviation Percentage_model', 'Fuel Deviation_model', 'ULDs Built by Model_model', \n",
    "        'ULDs Actually Used_model', 'Total Run Time_model', 'Number of BAX ULDs_model', 'Number of BUP ULDs_model', 'Number of T ULDs_model', \n",
    "        'Number of PAX A_model', 'Number of PAX B_model', 'Number of PAX C_model', 'Number of PAX D_model', 'Number of PAX E_model', 'Number of PAX F_model', 'Number of PAX G_model', 'Total PAX_model', \n",
    "        'Number of items_model', 'Weight in Comp 1_model', 'Weight in Comp 2_model', 'Weight in Comp 3_model', 'Weight in Comp 4_model', 'Number of ULDs in Comp 1_model', 'Number of BAX ULDs in Comp 1_model', \n",
    "        'Weight ULDs in Comp 1_model', 'Weight BAX ULDs in Comp 1_model', 'Number of ULDs in Comp 2_model', 'Number of BAX ULDs in Comp 2_model', 'Weight ULDs in Comp 2_model', 'Weight BAX ULDs in Comp 2_model', \n",
    "        'Number of ULDs in Comp 3_model', 'Number of BAX ULDs in Comp 3_model', 'Weight ULDs in Comp 3_model', 'Weight BAX ULDs in Comp 3_model', 'Number of ULDs in Comp 4_model', 'Number of BAX ULDs in Comp 4_model', \n",
    "        'Weight ULDs in Comp 4_model', 'Weight BAX ULDs in Comp 4_model', '%MAC ZFW_baseline', 'Fuel Deviation Percentage_baseline', 'Fuel Deviation_baseline', 'ULDs Built by Model_baseline', \n",
    "        'ULDs Actually Used_baseline', 'Total Run Time_baseline', 'Number of BAX ULDs_baseline', 'Number of BUP ULDs_baseline', 'Number of T ULDs_baseline', \n",
    "        'Number of PAX A_baseline', 'Number of PAX B_baseline', 'Number of PAX C_baseline', 'Number of PAX D_baseline', 'Number of PAX E_baseline', 'Number of PAX F_baseline', 'Number of PAX G_baseline', 'Total PAX_baseline', \n",
    "        'Number of items_baseline', 'Weight in Comp 1_baseline', 'Weight in Comp 2_baseline', 'Weight in Comp 3_baseline', 'Weight in Comp 4_baseline', 'Number of ULDs in Comp 1_baseline', 'Number of BAX ULDs in Comp 1_baseline', \n",
    "        'Weight ULDs in Comp 1_baseline', 'Weight BAX ULDs in Comp 1_baseline', 'Number of ULDs in Comp 2_baseline', 'Number of BAX ULDs in Comp 2_baseline', 'Weight ULDs in Comp 2_baseline', 'Weight BAX ULDs in Comp 2_baseline', \n",
    "        'Number of ULDs in Comp 3_baseline', 'Number of BAX ULDs in Comp 3_baseline', 'Weight ULDs in Comp 3_baseline', 'Weight BAX ULDs in Comp 3_baseline', 'Number of ULDs in Comp 4_baseline', 'Number of BAX ULDs in Comp 4_baseline', \n",
    "        'Weight ULDs in Comp 4_baseline', 'Weight BAX ULDs in Comp 4_baseline', '%MAC ZFW_optimized_actual', 'Fuel Deviation Percentage_optimized_actual', 'Fuel Deviation_optimized_actual', \n",
    "        'ULDs Built by Model_optimized_actual', 'ULDs Actually Used_optimized_actual', 'Total Run Time_optimized_actual', 'Number of BAX ULDs_optimized_actual', 'Number of BUP ULDs_optimized_actual', 'Number of T ULDs_optimized_actual', \n",
    "        'Number of PAX A_optimized_actual', 'Number of PAX B_optimized_actual', 'Number of PAX C_optimized_actual', 'Number of PAX D_optimized_actual', 'Number of PAX E_optimized_actual', 'Number of PAX F_optimized_actual', \n",
    "        'Number of PAX G_optimized_actual', 'Total PAX_optimized_actual', 'Number of items_optimized_actual', 'Weight in Comp 1_optimized_actual', 'Weight in Comp 2_optimized_actual', 'Weight in Comp 3_optimized_actual', \n",
    "        'Weight in Comp 4_optimized_actual', 'Number of ULDs in Comp 1_optimized_actual', 'Number of BAX ULDs in Comp 1_optimized_actual', 'Weight ULDs in Comp 1_optimized_actual', 'Weight BAX ULDs in Comp 1_optimized_actual', \n",
    "        'Number of ULDs in Comp 2_optimized_actual', 'Number of BAX ULDs in Comp 2_optimized_actual', 'Weight ULDs in Comp 2_optimized_actual', 'Weight BAX ULDs in Comp 2_optimized_actual', 'Number of ULDs in Comp 3_optimized_actual', \n",
    "        'Number of BAX ULDs in Comp 3_optimized_actual', 'Weight ULDs in Comp 3_optimized_actual', 'Weight BAX ULDs in Comp 3_optimized_actual', 'Number of ULDs in Comp 4_optimized_actual', 'Number of BAX ULDs in Comp 4_optimized_actual', \n",
    "        'Weight ULDs in Comp 4_optimized_actual', 'Weight BAX ULDs in Comp 4_optimized_actual', '%MAC ZFW_bax_fixed', 'Actual %MAC ZFW_bax_fixed', 'Fuel Deviation Percentage_bax_fixed', 'Fuel Deviation_bax_fixed', 'ULDs Built by Model_bax_fixed', \n",
    "        'ULDs Actually Used_bax_fixed', 'Total Run Time_bax_fixed', 'Number of BAX ULDs_bax_fixed', 'Number of BUP ULDs_bax_fixed', 'Number of T ULDs_bax_fixed', \n",
    "        'Number of PAX A_bax_fixed', 'Number of PAX B_bax_fixed', 'Number of PAX C_bax_fixed', 'Number of PAX D_bax_fixed', 'Number of PAX E_bax_fixed', 'Number of PAX F_bax_fixed', 'Number of PAX G_bax_fixed', 'Total PAX_bax_fixed', \n",
    "        'Number of items_bax_fixed', 'Weight in Comp 1_bax_fixed', 'Weight in Comp 2_bax_fixed', 'Weight in Comp 3_bax_fixed', 'Weight in Comp 4_bax_fixed', 'Number of ULDs in Comp 1_bax_fixed', 'Number of BAX ULDs in Comp 1_bax_fixed', \n",
    "        'Weight ULDs in Comp 1_bax_fixed', 'Weight BAX ULDs in Comp 1_bax_fixed', 'Number of ULDs in Comp 2_bax_fixed', 'Number of BAX ULDs in Comp 2_bax_fixed', 'Weight ULDs in Comp 2_bax_fixed', 'Weight BAX ULDs in Comp 2_bax_fixed', \n",
    "        'Number of ULDs in Comp 3_bax_fixed', 'Number of BAX ULDs in Comp 3_bax_fixed', 'Weight ULDs in Comp 3_bax_fixed', 'Weight BAX ULDs in Comp 3_bax_fixed', 'Number of ULDs in Comp 4_bax_fixed', 'Number of BAX ULDs in Comp 4_bax_fixed', \n",
    "        'Weight ULDs in Comp 4_bax_fixed', 'Weight BAX ULDs in Comp 4_bax_fixed']\n",
    "\n",
    "        comparison_full = comparison[columns_full].copy()\n",
    "        comparison_full.rename(columns = {'Actual %MAC ZFW_model': 'Actual %MAC ZFW'}, inplace=True)\n",
    "\n",
    "        columns_general_MAC = ['Flight Number', 'Flight Date', 'Aircraft Type', '%MAC ZFW_model', '%MAC ZFW_baseline', '%MAC ZFW_optimized_actual', '%MAC ZFW_bax_fixed', 'Actual %MAC ZFW_model']\n",
    "        columns_fuel_deviation = ['Flight Number', 'Flight Date', 'Aircraft Type', 'Fuel Deviation Percentage_model', 'Fuel Deviation Percentage_baseline', 'Fuel Deviation Percentage_optimized_actual', 'Fuel Deviation Percentage_bax_fixed',\n",
    "                                  'Fuel Deviation_model', 'Fuel Deviation_baseline', 'Fuel Deviation_optimized_actual', 'Fuel Deviation_bax_fixed']\n",
    "\n",
    "        comparison_MAC = comparison[columns_general_MAC].copy()\n",
    "        comparison_MAC.rename(columns = {'Actual %MAC ZFW_model': 'Actual %MAC ZFW'}, inplace=True)\n",
    "        cols_to_convert_MAC = ['%MAC ZFW_model', '%MAC ZFW_baseline', '%MAC ZFW_optimized_actual', '%MAC ZFW_bax_fixed', 'Actual %MAC ZFW']\n",
    "        comparison_MAC[cols_to_convert_MAC] = comparison_MAC[cols_to_convert_MAC].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "        comparison_fuel_deviation = comparison[columns_fuel_deviation].copy()\n",
    "        cols_to_convert_fuel_deviation = ['Fuel Deviation Percentage_model', 'Fuel Deviation Percentage_baseline', 'Fuel Deviation Percentage_optimized_actual', 'Fuel Deviation Percentage_bax_fixed',\n",
    "                                           'Fuel Deviation_model', 'Fuel Deviation_baseline', 'Fuel Deviation_optimized_actual', 'Fuel Deviation_bax_fixed']\n",
    "\n",
    "\n",
    "\n",
    "        average_data_general_MAC = {\n",
    "            'Flight Number': 'Average',\n",
    "            'Flight Date': '-',\n",
    "            'Aircraft Type': '-',\n",
    "            'Aircraft Registration': '-',\n",
    "            '%MAC ZFW_model': comparison_MAC['%MAC ZFW_model'].mean(),\n",
    "            '%MAC ZFW_baseline': comparison_MAC['%MAC ZFW_baseline'].mean(),\n",
    "            '%MAC ZFW_optimized_actual': comparison_MAC['%MAC ZFW_optimized_actual'].mean(),\n",
    "            '%MAC ZFW_bax_fixed': comparison_MAC['%MAC ZFW_bax_fixed'].mean(),\n",
    "            'Actual %MAC ZFW': comparison_MAC['Actual %MAC ZFW'].mean()\n",
    "        }\n",
    "\n",
    "        average_data_fuel_deviation = {\n",
    "            'Flight Number': 'Average',\n",
    "            'Flight Date': '-',\n",
    "            'Aircraft Type': '-',\n",
    "            'Aircraft Registration': '-',\n",
    "            'Fuel Deviation Percentage_model': comparison_fuel_deviation['Fuel Deviation Percentage_model'].mean(),\n",
    "            'Fuel Deviation Percentage_baseline': comparison_fuel_deviation['Fuel Deviation Percentage_baseline'].mean(),\n",
    "            'Fuel Deviation Percentage_optimized_actual': comparison_fuel_deviation['Fuel Deviation Percentage_optimized_actual'].mean(),\n",
    "            'Fuel Deviation Percentage_bax_fixed': comparison_fuel_deviation['Fuel Deviation Percentage_bax_fixed'].mean(),\n",
    "            'Fuel Deviation_model': comparison_fuel_deviation['Fuel Deviation_model'].mean(),\n",
    "            'Fuel Deviation_baseline': comparison_fuel_deviation['Fuel Deviation_baseline'].mean(),\n",
    "            'Fuel Deviation_optimized_actual': comparison_fuel_deviation['Fuel Deviation_optimized_actual'].mean(),\n",
    "            'Fuel Deviation_bax_fixed': comparison_fuel_deviation['Fuel Deviation_bax_fixed'].mean()\n",
    "        }\n",
    "\n",
    "        sum_data_fuel_deviation = {\n",
    "            'Flight Number': 'Total',\n",
    "            'Flight Date': '-',\n",
    "            'Aircraft Type': '-',\n",
    "            'Aircraft Registration': '-',\n",
    "            'Fuel Deviation Percentage_model': '-',\n",
    "            'Fuel Deviation Percentage_baseline': '-',\n",
    "            'Fuel Deviation Percentage_optimized_actual': '-',\n",
    "            'Fuel Deviation Percentage_bax_fixed': '-',\n",
    "            'Fuel Deviation_model': comparison_fuel_deviation['Fuel Deviation_model'].sum(),\n",
    "            'Fuel Deviation_baseline': comparison_fuel_deviation['Fuel Deviation_baseline'].sum(),\n",
    "            'Fuel Deviation_optimized_actual': comparison_fuel_deviation['Fuel Deviation_optimized_actual'].sum(),\n",
    "            'Fuel Deviation_bax_fixed': comparison_fuel_deviation['Fuel Deviation_bax_fixed'].sum()\n",
    "        }\n",
    "\n",
    "        sum_data_full = {\n",
    "            'Flight Number': 'Total',\n",
    "            'Flight Date': '-',\n",
    "            'TOW': comparison_full['TOW'].sum(),\n",
    "            'Fuel Deviation Percentage_model': '-',\n",
    "            'Fuel Deviation_model': comparison_full['Fuel Deviation_model'].sum(),\n",
    "            'ULDs Built by Model_model': comparison_full['ULDs Built by Model_model'].sum(),\n",
    "            'ULDs Actually Used_model': comparison_full['ULDs Actually Used_model'].sum(),\n",
    "            '%MAC ZFW_model': '-',\n",
    "            'Actual %MAC ZFW': '-',\n",
    "            'Total Run Time_model': comparison_full['Total Run Time_model'].sum(),\n",
    "            'Number of BAX ULDs_model': comparison_full['Number of BAX ULDs_model'].sum(),\n",
    "            'Number of BUP ULDs_model': comparison_full['Number of BUP ULDs_model'].sum(),\n",
    "            'Number of T ULDs_model': comparison_full['Number of T ULDs_model'].sum(),\n",
    "            'Number of PAX A_model': '-',\n",
    "            'Number of PAX B_model': '-',\n",
    "            'Number of PAX C_model': '-',\n",
    "            'Number of PAX D_model': '-',\n",
    "            'Number of PAX E_model': '-',\n",
    "            'Number of PAX F_model': '-',\n",
    "            'Number of PAX G_model': '-',\n",
    "            'Total PAX_model': '-',\n",
    "            'Number of items_model': comparison_full['Number of items_model'].sum(),\n",
    "            'Weight in Comp 1_model': comparison_full['Weight in Comp 1_model'].sum(),\n",
    "            'Weight in Comp 2_model': comparison_full['Weight in Comp 2_model'].sum(),\n",
    "            'Weight in Comp 3_model': comparison_full['Weight in Comp 3_model'].sum(),\n",
    "            'Weight in Comp 4_model': comparison_full['Weight in Comp 4_model'].sum(),\n",
    "            'Number of ULDs in Comp 1_model': comparison_full['Number of ULDs in Comp 1_model'].sum(),\n",
    "            'Number of BAX ULDs in Comp 1_model': comparison_full['Number of BAX ULDs in Comp 1_model'].sum(),\n",
    "            'Weight ULDs in Comp 1_model': comparison_full['Weight ULDs in Comp 1_model'].sum(),\n",
    "            'Weight BAX ULDs in Comp 1_model': comparison_full['Weight BAX ULDs in Comp 1_model'].sum(),\n",
    "            'Number of ULDs in Comp 2_model': comparison_full['Number of ULDs in Comp 2_model'].sum(),\n",
    "            'Number of BAX ULDs in Comp 2_model': comparison_full['Number of BAX ULDs in Comp 2_model'].sum(),\n",
    "            'Weight ULDs in Comp 2_model': comparison_full['Weight ULDs in Comp 2_model'].sum(),\n",
    "            'Weight BAX ULDs in Comp 2_model': comparison_full['Weight BAX ULDs in Comp 2_model'].sum(),\n",
    "            'Number of ULDs in Comp 3_model': comparison_full['Number of ULDs in Comp 3_model'].sum(),\n",
    "            'Number of BAX ULDs in Comp 3_model': comparison_full['Number of BAX ULDs in Comp 3_model'].sum(),\n",
    "            'Weight ULDs in Comp 3_model': comparison_full['Weight ULDs in Comp 3_model'].sum(),\n",
    "            'Weight BAX ULDs in Comp 3_model': comparison_full['Weight BAX ULDs in Comp 3_model'].sum(),\n",
    "            'Number of ULDs in Comp 4_model': comparison_full['Number of ULDs in Comp 4_model'].sum(),\n",
    "            'Number of BAX ULDs in Comp 4_model': comparison_full['Number of BAX ULDs in Comp 4_model'].sum(),\n",
    "            'Weight ULDs in Comp 4_model': comparison_full['Weight ULDs in Comp 4_model'].sum(),\n",
    "            'Weight BAX ULDs in Comp 4_model': comparison_full['Weight BAX ULDs in Comp 4_model'].sum(),\n",
    "            'Fuel Deviation Percentage_baseline': '-',\n",
    "            'Fuel Deviation_baseline': comparison_full['Fuel Deviation_baseline'].sum(),\n",
    "            'ULDs Built by Model_baseline': comparison_full['ULDs Built by Model_baseline'].sum(),\n",
    "            'ULDs Actually Used_baseline': comparison_full['ULDs Actually Used_baseline'].sum(),\n",
    "            '%MAC ZFW_baseline': '-',\n",
    "            'Total Run Time_baseline': comparison_full['Total Run Time_baseline'].sum(),\n",
    "            'Number of BAX ULDs_baseline': comparison_full['Number of BAX ULDs_baseline'].sum(),\n",
    "            'Number of BUP ULDs_baseline': comparison_full['Number of BUP ULDs_baseline'].sum(),\n",
    "            'Number of T ULDs_baseline': comparison_full['Number of T ULDs_baseline'].sum(),\n",
    "            'Number of PAX A_baseline': '-',\n",
    "            'Number of PAX B_baseline': '-',\n",
    "            'Number of PAX C_baseline': '-',\n",
    "            'Number of PAX D_baseline': '-',\n",
    "            'Number of PAX E_baseline': '-',\n",
    "            'Number of PAX F_baseline': '-',\n",
    "            'Number of PAX G_baseline': '-',\n",
    "            'Total PAX_baseline': '-',\n",
    "            'Number of items_baseline': comparison_full['Number of items_baseline'].sum(),\n",
    "            'Weight in Comp 1_baseline': comparison_full['Weight in Comp 1_baseline'].sum(),\n",
    "            'Weight in Comp 2_baseline': comparison_full['Weight in Comp 2_baseline'].sum(),\n",
    "            'Weight in Comp 3_baseline': comparison_full['Weight in Comp 3_baseline'].sum(),\n",
    "            'Weight in Comp 4_baseline': comparison_full['Weight in Comp 4_baseline'].sum(),\n",
    "            'Number of ULDs in Comp 1_baseline': comparison_full['Number of ULDs in Comp 1_baseline'].sum(),\n",
    "            'Number of BAX ULDs in Comp 1_baseline': comparison_full['Number of BAX ULDs in Comp 1_baseline'].sum(),\n",
    "            'Weight ULDs in Comp 1_baseline': comparison_full['Weight ULDs in Comp 1_baseline'].sum(),\n",
    "            'Weight BAX ULDs in Comp 1_baseline': comparison_full['Weight BAX ULDs in Comp 1_baseline'].sum(),\n",
    "            'Number of ULDs in Comp 2_baseline': comparison_full['Number of ULDs in Comp 2_baseline'].sum(),\n",
    "            'Number of BAX ULDs in Comp 2_baseline': comparison_full['Number of BAX ULDs in Comp 2_baseline'].sum(),\n",
    "            'Weight ULDs in Comp 2_baseline': comparison_full['Weight ULDs in Comp 2_baseline'].sum(),\n",
    "            'Weight BAX ULDs in Comp 2_baseline': comparison_full['Weight BAX ULDs in Comp 2_baseline'].sum(),\n",
    "            'Number of ULDs in Comp 3_baseline': comparison_full['Number of ULDs in Comp 3_baseline'].sum(),\n",
    "            'Number of BAX ULDs in Comp 3_baseline': comparison_full['Number of BAX ULDs in Comp 3_baseline'].sum(),\n",
    "            'Weight ULDs in Comp 3_baseline': comparison_full['Weight ULDs in Comp 3_baseline'].sum(),\n",
    "            'Weight BAX ULDs in Comp 3_baseline': comparison_full['Weight BAX ULDs in Comp 3_baseline'].sum(),\n",
    "            'Number of ULDs in Comp 4_baseline': comparison_full['Number of ULDs in Comp 4_baseline'].sum(),\n",
    "            'Number of BAX ULDs in Comp 4_baseline': comparison_full['Number of BAX ULDs in Comp 4_baseline'].sum(),\n",
    "            'Weight ULDs in Comp 4_baseline': comparison_full['Weight ULDs in Comp 4_baseline'].sum(),\n",
    "            'Weight BAX ULDs in Comp 4_baseline': comparison_full['Weight BAX ULDs in Comp 4_baseline'].sum(),\n",
    "            'Fuel Deviation Percentage_optimized_actual': '-',\n",
    "            'Fuel Deviation_optimized_actual': comparison_full['Fuel Deviation_optimized_actual'].sum(),\n",
    "            'ULDs Built by Model_optimized_actual': comparison_full['ULDs Built by Model_optimized_actual'].sum(),\n",
    "            'ULDs Actually Used_optimized_actual': comparison_full['ULDs Actually Used_optimized_actual'].sum(),\n",
    "            '%MAC ZFW_optimized_actual': '-',\n",
    "            'Total Run Time_optimized_actual': comparison_full['Total Run Time_optimized_actual'].sum(),\n",
    "            'Number of BAX ULDs_optimized_actual': comparison_full['Number of BAX ULDs_optimized_actual'].sum(),\n",
    "            'Number of BUP ULDs_optimized_actual': comparison_full['Number of BUP ULDs_optimized_actual'].sum(),\n",
    "            'Number of T ULDs_optimized_actual': comparison_full['Number of T ULDs_optimized_actual'].sum(),\n",
    "            'Number of PAX A_optimized_actual': '-',\n",
    "            'Number of PAX B_optimized_actual': '-',\n",
    "            'Number of PAX C_optimized_actual': '-',\n",
    "            'Number of PAX D_optimized_actual': '-',\n",
    "            'Number of PAX E_optimized_actual': '-',\n",
    "            'Number of PAX F_optimized_actual': '-',\n",
    "            'Number of PAX G_optimized_actual': '-',\n",
    "            'Total PAX_optimized_actual': '-',\n",
    "            'Number of items_optimized_actual': comparison_full['Number of items_optimized_actual'].sum(),\n",
    "            'Weight in Comp 1_optimized_actual': comparison_full['Weight in Comp 1_optimized_actual'].sum(),\n",
    "            'Weight in Comp 2_optimized_actual': comparison_full['Weight in Comp 2_optimized_actual'].sum(),\n",
    "            'Weight in Comp 3_optimized_actual': comparison_full['Weight in Comp 3_optimized_actual'].sum(),\n",
    "            'Weight in Comp 4_optimized_actual': comparison_full['Weight in Comp 4_optimized_actual'].sum(),\n",
    "            'Number of ULDs in Comp 1_optimized_actual': comparison_full['Number of ULDs in Comp 1_optimized_actual'].sum(),\n",
    "            'Number of BAX ULDs in Comp 1_optimized_actual': comparison_full['Number of BAX ULDs in Comp 1_optimized_actual'].sum(),\n",
    "            'Weight ULDs in Comp 1_optimized_actual': comparison_full['Weight ULDs in Comp 1_optimized_actual'].sum(),\n",
    "            'Weight BAX ULDs in Comp 1_optimized_actual': comparison_full['Weight BAX ULDs in Comp 1_optimized_actual'].sum(),\n",
    "            'Number of ULDs in Comp 2_optimized_actual': comparison_full['Number of ULDs in Comp 2_optimized_actual'].sum(),\n",
    "            'Number of BAX ULDs in Comp 2_optimized_actual': comparison_full['Number of BAX ULDs in Comp 2_optimized_actual'].sum(),\n",
    "            'Weight ULDs in Comp 2_optimized_actual': comparison_full['Weight ULDs in Comp 2_optimized_actual'].sum(),\n",
    "            'Weight BAX ULDs in Comp 2_optimized_actual': comparison_full['Weight BAX ULDs in Comp 2_optimized_actual'].sum(),\n",
    "            'Number of ULDs in Comp 3_optimized_actual': comparison_full['Number of ULDs in Comp 3_optimized_actual'].sum(),\n",
    "            'Number of BAX ULDs in Comp 3_optimized_actual': comparison_full['Number of BAX ULDs in Comp 3_optimized_actual'].sum(),\n",
    "            'Weight ULDs in Comp 3_optimized_actual': comparison_full['Weight ULDs in Comp 3_optimized_actual'].sum(),\n",
    "            'Weight BAX ULDs in Comp 3_optimized_actual': comparison_full['Weight BAX ULDs in Comp 3_optimized_actual'].sum(),\n",
    "            'Number of ULDs in Comp 4_optimized_actual': comparison_full['Number of ULDs in Comp 4_optimized_actual'].sum(),\n",
    "            'Number of BAX ULDs in Comp 4_optimized_actual': comparison_full['Number of BAX ULDs in Comp 4_optimized_actual'].sum(),\n",
    "            'Weight ULDs in Comp 4_optimized_actual': comparison_full['Weight ULDs in Comp 4_optimized_actual'].sum(),\n",
    "            'Weight BAX ULDs in Comp 4_optimized_actual': comparison_full['Weight BAX ULDs in Comp 4_optimized_actual'].sum(),\n",
    "            'Fuel Deviation_bax_fixed': comparison_full['Fuel Deviation_bax_fixed'].sum(),\n",
    "            'ULDs Built by Model_bax_fixed': comparison_full['ULDs Built by Model_bax_fixed'].sum(),\n",
    "            'ULDs Actually Used_bax_fixed': comparison_full['ULDs Actually Used_bax_fixed'].sum(),\n",
    "            '%MAC ZFW_bax_fixed': '-',\n",
    "            'Actual %MAC ZFW': '-',\n",
    "            'Total Run Time_bax_fixed': comparison_full['Total Run Time_bax_fixed'].sum(),\n",
    "            'Number of BAX ULDs_bax_fixed': comparison_full['Number of BAX ULDs_bax_fixed'].sum(),\n",
    "            'Number of BUP ULDs_bax_fixed': comparison_full['Number of BUP ULDs_bax_fixed'].sum(),\n",
    "            'Number of T ULDs_bax_fixed': comparison_full['Number of T ULDs_bax_fixed'].sum(),\n",
    "            'Number of PAX A_bax_fixed': '-',\n",
    "            'Number of PAX B_bax_fixed': '-',\n",
    "            'Number of PAX C_bax_fixed': '-',\n",
    "            'Number of PAX D_bax_fixed': '-',\n",
    "            'Number of PAX E_bax_fixed': '-',\n",
    "            'Number of PAX F_bax_fixed': '-',\n",
    "            'Number of PAX G_bax_fixed': '-',\n",
    "            'Total PAX_bax_fixed': '-',\n",
    "            'Number of items_bax_fixed': comparison_full['Number of items_bax_fixed'].sum(),\n",
    "            'Weight in Comp 1_bax_fixed': comparison_full['Weight in Comp 1_bax_fixed'].sum(),\n",
    "            'Weight in Comp 2_bax_fixed': comparison_full['Weight in Comp 2_bax_fixed'].sum(),\n",
    "            'Weight in Comp 3_bax_fixed': comparison_full['Weight in Comp 3_bax_fixed'].sum(),\n",
    "            'Weight in Comp 4_bax_fixed': comparison_full['Weight in Comp 4_bax_fixed'].sum(),\n",
    "            'Number of ULDs in Comp 1_bax_fixed': comparison_full['Number of ULDs in Comp 1_bax_fixed'].sum(),\n",
    "            'Number of BAX ULDs in Comp 1_bax_fixed': comparison_full['Number of BAX ULDs in Comp 1_bax_fixed'].sum(),\n",
    "            'Weight ULDs in Comp 1_bax_fixed': comparison_full['Weight ULDs in Comp 1_bax_fixed'].sum(),\n",
    "            'Weight BAX ULDs in Comp 1_bax_fixed': comparison_full['Weight BAX ULDs in Comp 1_bax_fixed'].sum(),\n",
    "            'Number of ULDs in Comp 2_bax_fixed': comparison_full['Number of ULDs in Comp 2_bax_fixed'].sum(),\n",
    "            'Number of BAX ULDs in Comp 2_bax_fixed': comparison_full['Number of BAX ULDs in Comp 2_bax_fixed'].sum(),\n",
    "            'Weight ULDs in Comp 2_bax_fixed': comparison_full['Weight ULDs in Comp 2_bax_fixed'].sum(),\n",
    "            'Weight BAX ULDs in Comp 2_bax_fixed': comparison_full['Weight BAX ULDs in Comp 2_bax_fixed'].sum(),\n",
    "            'Number of ULDs in Comp 3_bax_fixed': comparison_full['Number of ULDs in Comp 3_bax_fixed'].sum(),\n",
    "            'Number of BAX ULDs in Comp 3_bax_fixed': comparison_full['Number of BAX ULDs in Comp 3_bax_fixed'].sum(),\n",
    "            'Weight ULDs in Comp 3_bax_fixed': comparison_full['Weight ULDs in Comp 3_bax_fixed'].sum(),\n",
    "            'Weight BAX ULDs in Comp 3_bax_fixed': comparison_full['Weight BAX ULDs in Comp 3_bax_fixed'].sum(),\n",
    "            'Number of ULDs in Comp 4_bax_fixed': comparison_full['Number of ULDs in Comp 4_bax_fixed'].sum(),\n",
    "            'Number of BAX ULDs in Comp 4_bax_fixed': comparison_full['Number of BAX ULDs in Comp 4_bax_fixed'].sum(),\n",
    "            'Weight ULDs in Comp 4_bax_fixed': comparison_full['Weight ULDs in Comp 4_bax_fixed'].sum(),\n",
    "            'Weight BAX ULDs in Comp 4_bax_fixed': comparison_full['Weight BAX ULDs in Comp 4_bax_fixed'].sum()\n",
    "        }\n",
    "\n",
    "        average_data_full = {\n",
    "            'Flight Number': 'Average',\n",
    "            'Flight Date': '-',\n",
    "            'TOW': comparison_full['TOW'].mean(),\n",
    "            'Fuel Deviation Percentage_model': comparison_full['Fuel Deviation Percentage_model'].mean(),\n",
    "            'Fuel Deviation_model': comparison_full['Fuel Deviation_model'].mean(),\n",
    "            'ULDs Built by Model_model': comparison_full['ULDs Built by Model_model'].mean(),\n",
    "            'ULDs Actually Used_model': comparison_full['ULDs Actually Used_model'].mean(),\n",
    "            '%MAC ZFW_model': comparison_full['%MAC ZFW_model'].mean(),\n",
    "            'Total Run Time_model': comparison_full['Total Run Time_model'].mean(),\n",
    "            'Number of BAX ULDs_model': comparison_full['Number of BAX ULDs_model'].mean(),\n",
    "            'Number of BUP ULDs_model': comparison_full['Number of BUP ULDs_model'].mean(),\n",
    "            'Number of T ULDs_model': comparison_full['Number of T ULDs_model'].mean(),\n",
    "            'Number of PAX A_model': comparison_full['Number of PAX A_model'].mean(),\n",
    "            'Number of PAX B_model': comparison_full['Number of PAX B_model'].mean(),\n",
    "            'Number of PAX C_model': comparison_full['Number of PAX C_model'].mean(),\n",
    "            'Number of PAX D_model': comparison_full['Number of PAX D_model'].mean(),\n",
    "            'Number of PAX E_model': comparison_full['Number of PAX E_model'].mean(),\n",
    "            'Number of PAX F_model': comparison_full['Number of PAX F_model'].mean(),\n",
    "            'Number of PAX G_model': comparison_full['Number of PAX G_model'].mean(),\n",
    "            'Total PAX_model': comparison_full['Total PAX_model'].mean(),\n",
    "            'Number of items_model': comparison_full['Number of items_model'].mean(),\n",
    "            'Weight in Comp 1_model': comparison_full['Weight in Comp 1_model'].mean(),\n",
    "            'Weight in Comp 2_model': comparison_full['Weight in Comp 2_model'].mean(),\n",
    "            'Weight in Comp 3_model': comparison_full['Weight in Comp 3_model'].mean(),\n",
    "            'Weight in Comp 4_model': comparison_full['Weight in Comp 4_model'].mean(),\n",
    "            'Number of ULDs in Comp 1_model': comparison_full['Number of ULDs in Comp 1_model'].mean(),\n",
    "            'Number of BAX ULDs in Comp 1_model': comparison_full['Number of BAX ULDs in Comp 1_model'].mean(),\n",
    "            'Weight ULDs in Comp 1_model': comparison_full['Weight ULDs in Comp 1_model'].mean(),\n",
    "            'Weight BAX ULDs in Comp 1_model': comparison_full['Weight BAX ULDs in Comp 1_model'].mean(),\n",
    "            'Number of ULDs in Comp 2_model': comparison_full['Number of ULDs in Comp 2_model'].mean(),\n",
    "            'Number of BAX ULDs in Comp 2_model': comparison_full['Number of BAX ULDs in Comp 2_model'].mean(),\n",
    "            'Weight ULDs in Comp 2_model': comparison_full['Weight ULDs in Comp 2_model'].mean(),\n",
    "            'Weight BAX ULDs in Comp 2_model': comparison_full['Weight BAX ULDs in Comp 2_model'].mean(),\n",
    "            'Number of ULDs in Comp 3_model': comparison_full['Number of ULDs in Comp 3_model'].mean(),\n",
    "            'Number of BAX ULDs in Comp 3_model': comparison_full['Number of BAX ULDs in Comp 3_model'].mean(),\n",
    "            'Weight ULDs in Comp 3_model': comparison_full['Weight ULDs in Comp 3_model'].mean(),\n",
    "            'Weight BAX ULDs in Comp 3_model': comparison_full['Weight BAX ULDs in Comp 3_model'].mean(),\n",
    "            'Number of ULDs in Comp 4_model': comparison_full['Number of ULDs in Comp 4_model'].mean(),\n",
    "            'Number of BAX ULDs in Comp 4_model': comparison_full['Number of BAX ULDs in Comp 4_model'].mean(),\n",
    "            'Weight ULDs in Comp 4_model': comparison_full['Weight ULDs in Comp 4_model'].mean(),\n",
    "            'Weight BAX ULDs in Comp 4_model': comparison_full['Weight BAX ULDs in Comp 4_model'].mean(),\n",
    "            'Fuel Deviation Percentage_baseline': comparison_full['Fuel Deviation Percentage_baseline'].mean(),\n",
    "            'Fuel Deviation_baseline': comparison_full['Fuel Deviation_baseline'].mean(),\n",
    "            'ULDs Built by Model_baseline': comparison_full['ULDs Built by Model_baseline'].mean(),\n",
    "            'ULDs Actually Used_baseline': comparison_full['ULDs Actually Used_baseline'].mean(),\n",
    "            '%MAC ZFW_baseline': comparison_full['%MAC ZFW_baseline'].mean(),\n",
    "            'Total Run Time_baseline': comparison_full['Total Run Time_baseline'].mean(),\n",
    "            'Number of BAX ULDs_baseline': comparison_full['Number of BAX ULDs_baseline'].mean(),\n",
    "            'Number of BUP ULDs_baseline': comparison_full['Number of BUP ULDs_baseline'].mean(),\n",
    "            'Number of T ULDs_baseline': comparison_full['Number of T ULDs_baseline'].mean(),\n",
    "            'Number of PAX A_baseline': comparison_full['Number of PAX A_baseline'].mean(),\n",
    "            'Number of PAX B_baseline': comparison_full['Number of PAX B_baseline'].mean(),\n",
    "            'Number of PAX C_baseline': comparison_full['Number of PAX C_baseline'].mean(),\n",
    "            'Number of PAX D_baseline': comparison_full['Number of PAX D_baseline'].mean(),\n",
    "            'Number of PAX E_baseline': comparison_full['Number of PAX E_baseline'].mean(),\n",
    "            'Number of PAX F_baseline': comparison_full['Number of PAX F_baseline'].mean(),\n",
    "            'Number of PAX G_baseline': comparison_full['Number of PAX G_baseline'].mean(),\n",
    "            'Total PAX_baseline': comparison_full['Total PAX_baseline'].mean(),\n",
    "            'Number of items_baseline': comparison_full['Number of items_baseline'].mean(),\n",
    "            'Weight in Comp 1_baseline': comparison_full['Weight in Comp 1_baseline'].mean(),\n",
    "            'Weight in Comp 2_baseline': comparison_full['Weight in Comp 2_baseline'].mean(),\n",
    "            'Weight in Comp 3_baseline': comparison_full['Weight in Comp 3_baseline'].mean(),\n",
    "            'Weight in Comp 4_baseline': comparison_full['Weight in Comp 4_baseline'].mean(),\n",
    "            'Number of ULDs in Comp 1_baseline': comparison_full['Number of ULDs in Comp 1_baseline'].mean(),\n",
    "            'Number of BAX ULDs in Comp 1_baseline': comparison_full['Number of BAX ULDs in Comp 1_baseline'].mean(),\n",
    "            'Weight ULDs in Comp 1_baseline': comparison_full['Weight ULDs in Comp 1_baseline'].mean(),\n",
    "            'Weight BAX ULDs in Comp 1_baseline': comparison_full['Weight BAX ULDs in Comp 1_baseline'].mean(),\n",
    "            'Number of ULDs in Comp 2_baseline': comparison_full['Number of ULDs in Comp 2_baseline'].mean(),\n",
    "            'Number of BAX ULDs in Comp 2_baseline': comparison_full['Number of BAX ULDs in Comp 2_baseline'].mean(),\n",
    "            'Weight ULDs in Comp 2_baseline': comparison_full['Weight ULDs in Comp 2_baseline'].mean(),\n",
    "            'Weight BAX ULDs in Comp 2_baseline': comparison_full['Weight BAX ULDs in Comp 2_baseline'].mean(),\n",
    "            'Number of ULDs in Comp 3_baseline': comparison_full['Number of ULDs in Comp 3_baseline'].mean(),\n",
    "            'Number of BAX ULDs in Comp 3_baseline': comparison_full['Number of BAX ULDs in Comp 3_baseline'].mean(),\n",
    "            'Weight ULDs in Comp 3_baseline': comparison_full['Weight ULDs in Comp 3_baseline'].mean(),\n",
    "            'Weight BAX ULDs in Comp 3_baseline': comparison_full['Weight BAX ULDs in Comp 3_baseline'].mean(),\n",
    "            'Number of ULDs in Comp 4_baseline': comparison_full['Number of ULDs in Comp 4_baseline'].mean(),\n",
    "            'Number of BAX ULDs in Comp 4_baseline': comparison_full['Number of BAX ULDs in Comp 4_baseline'].mean(),\n",
    "            'Weight ULDs in Comp 4_baseline': comparison_full['Weight ULDs in Comp 4_baseline'].mean(),\n",
    "            'Weight BAX ULDs in Comp 4_baseline': comparison_full['Weight BAX ULDs in Comp 4_baseline'].mean(),\n",
    "            'Fuel Deviation Percentage_optimized_actual': comparison_full['Fuel Deviation Percentage_optimized_actual'].mean(),\n",
    "            'Fuel Deviation_optimized_actual': comparison_full['Fuel Deviation_optimized_actual'].mean(),\n",
    "            'ULDs Built by Model_optimized_actual': comparison_full['ULDs Built by Model_optimized_actual'].mean(),\n",
    "            'ULDs Actually Used_optimized_actual': comparison_full['ULDs Actually Used_optimized_actual'].mean(),\n",
    "            '%MAC ZFW_optimized_actual': comparison_full['%MAC ZFW_optimized_actual'].mean(),\n",
    "            'Total Run Time_optimized_actual': comparison_full['Total Run Time_optimized_actual'].mean(),\n",
    "            'Number of BAX ULDs_optimized_actual': comparison_full['Number of BAX ULDs_optimized_actual'].mean(),\n",
    "            'Number of BUP ULDs_optimized_actual': comparison_full['Number of BUP ULDs_optimized_actual'].mean(),\n",
    "            'Number of T ULDs_optimized_actual': comparison_full['Number of T ULDs_optimized_actual'].mean(),\n",
    "            'Number of PAX A_optimized_actual': comparison_full['Number of PAX A_optimized_actual'].mean(),\n",
    "            'Number of PAX B_optimized_actual': comparison_full['Number of PAX B_optimized_actual'].mean(),\n",
    "            'Number of PAX C_optimized_actual': comparison_full['Number of PAX C_optimized_actual'].mean(),\n",
    "            'Number of PAX D_optimized_actual': comparison_full['Number of PAX D_optimized_actual'].mean(),\n",
    "            'Number of PAX E_optimized_actual': comparison_full['Number of PAX E_optimized_actual'].mean(),\n",
    "            'Number of PAX F_optimized_actual': comparison_full['Number of PAX F_optimized_actual'].mean(),\n",
    "            'Number of PAX G_optimized_actual': comparison_full['Number of PAX G_optimized_actual'].mean(),\n",
    "            'Total PAX_optimized_actual': comparison_full['Total PAX_optimized_actual'].mean(),\n",
    "            'Number of items_optimized_actual': comparison_full['Number of items_optimized_actual'].mean(),\n",
    "            'Weight in Comp 1_optimized_actual': comparison_full['Weight in Comp 1_optimized_actual'].mean(),\n",
    "            'Weight in Comp 2_optimized_actual': comparison_full['Weight in Comp 2_optimized_actual'].mean(),\n",
    "            'Weight in Comp 3_optimized_actual': comparison_full['Weight in Comp 3_optimized_actual'].mean(),\n",
    "            'Weight in Comp 4_optimized_actual': comparison_full['Weight in Comp 4_optimized_actual'].mean(),\n",
    "            'Number of ULDs in Comp 1_optimized_actual': comparison_full['Number of ULDs in Comp 1_optimized_actual'].mean(),\n",
    "            'Number of BAX ULDs in Comp 1_optimized_actual': comparison_full['Number of BAX ULDs in Comp 1_optimized_actual'].mean(),\n",
    "            'Weight ULDs in Comp 1_optimized_actual': comparison_full['Weight ULDs in Comp 1_optimized_actual'].mean(),\n",
    "            'Weight BAX ULDs in Comp 1_optimized_actual': comparison_full['Weight BAX ULDs in Comp 1_optimized_actual'].mean(),\n",
    "            'Number of ULDs in Comp 2_optimized_actual': comparison_full['Number of ULDs in Comp 2_optimized_actual'].mean(),\n",
    "            'Number of BAX ULDs in Comp 2_optimized_actual': comparison_full['Number of BAX ULDs in Comp 2_optimized_actual'].mean(),\n",
    "            'Weight ULDs in Comp 2_optimized_actual': comparison_full['Weight ULDs in Comp 2_optimized_actual'].mean(),\n",
    "            'Weight BAX ULDs in Comp 2_optimized_actual': comparison_full['Weight BAX ULDs in Comp 2_optimized_actual'].mean(),\n",
    "            'Number of ULDs in Comp 3_optimized_actual': comparison_full['Number of ULDs in Comp 3_optimized_actual'].mean(),\n",
    "            'Number of BAX ULDs in Comp 3_optimized_actual': comparison_full['Number of BAX ULDs in Comp 3_optimized_actual'].mean(),\n",
    "            'Weight ULDs in Comp 3_optimized_actual': comparison_full['Weight ULDs in Comp 3_optimized_actual'].mean(),\n",
    "            'Weight BAX ULDs in Comp 3_optimized_actual': comparison_full['Weight BAX ULDs in Comp 3_optimized_actual'].mean(),\n",
    "            'Number of ULDs in Comp 4_optimized_actual': comparison_full['Number of ULDs in Comp 4_optimized_actual'].mean(),\n",
    "            'Number of BAX ULDs in Comp 4_optimized_actual': comparison_full['Number of BAX ULDs in Comp 4_optimized_actual'].mean(),\n",
    "            'Weight ULDs in Comp 4_optimized_actual': comparison_full['Weight ULDs in Comp 4_optimized_actual'].mean(),\n",
    "            'Weight BAX ULDs in Comp 4_optimized_actual': comparison_full['Weight BAX ULDs in Comp 4_optimized_actual'].mean(),\n",
    "            'Fuel Deviation Percentage_bax_fixed': comparison_full['Fuel Deviation Percentage_bax_fixed'].mean(),\n",
    "            'Fuel Deviation_bax_fixed': comparison_full['Fuel Deviation_bax_fixed'].mean(),\n",
    "            'ULDs Built by Model_bax_fixed': comparison_full['ULDs Built by Model_bax_fixed'].mean(),\n",
    "            'ULDs Actually Used_bax_fixed': comparison_full['ULDs Actually Used_bax_fixed'].mean(),\n",
    "            '%MAC ZFW_bax_fixed': comparison_full['%MAC ZFW_bax_fixed'].mean(),\n",
    "            'Total Run Time_bax_fixed': comparison_full['Total Run Time_bax_fixed'].mean(),\n",
    "            'Number of BAX ULDs_bax_fixed': comparison_full['Number of BAX ULDs_bax_fixed'].mean(),\n",
    "            'Number of BUP ULDs_bax_fixed': comparison_full['Number of BUP ULDs_bax_fixed'].mean(),\n",
    "            'Number of T ULDs_bax_fixed': comparison_full['Number of T ULDs_bax_fixed'].mean(),\n",
    "            'Number of PAX A_bax_fixed': comparison_full['Number of PAX A_bax_fixed'].mean(),\n",
    "            'Number of PAX B_bax_fixed': comparison_full['Number of PAX B_bax_fixed'].mean(),\n",
    "            'Number of PAX C_bax_fixed': comparison_full['Number of PAX C_bax_fixed'].mean(),\n",
    "            'Number of PAX D_bax_fixed': comparison_full['Number of PAX D_bax_fixed'].mean(),\n",
    "            'Number of PAX E_bax_fixed': comparison_full['Number of PAX E_bax_fixed'].mean(),\n",
    "            'Number of PAX F_bax_fixed': comparison_full['Number of PAX F_bax_fixed'].mean(),\n",
    "            'Number of PAX G_bax_fixed': comparison_full['Number of PAX G_bax_fixed'].mean(),\n",
    "            'Total PAX_bax_fixed': comparison_full['Total PAX_bax_fixed'].mean(),\n",
    "            'Number of items_bax_fixed': comparison_full['Number of items_bax_fixed'].mean(),\n",
    "            'Weight in Comp 1_bax_fixed': comparison_full['Weight in Comp 1_bax_fixed'].mean(),\n",
    "            'Weight in Comp 2_bax_fixed': comparison_full['Weight in Comp 2_bax_fixed'].mean(),\n",
    "            'Weight in Comp 3_bax_fixed': comparison_full['Weight in Comp 3_bax_fixed'].mean(),\n",
    "            'Weight in Comp 4_bax_fixed': comparison_full['Weight in Comp 4_bax_fixed'].mean(),\n",
    "            'Number of ULDs in Comp 1_bax_fixed': comparison_full['Number of ULDs in Comp 1_bax_fixed'].mean(),\n",
    "            'Number of BAX ULDs in Comp 1_bax_fixed': comparison_full['Number of BAX ULDs in Comp 1_bax_fixed'].mean(),\n",
    "            'Weight ULDs in Comp 1_bax_fixed': comparison_full['Weight ULDs in Comp 1_bax_fixed'].mean(),\n",
    "            'Weight BAX ULDs in Comp 1_bax_fixed': comparison_full['Weight BAX ULDs in Comp 1_bax_fixed'].mean(),\n",
    "            'Number of ULDs in Comp 2_bax_fixed': comparison_full['Number of ULDs in Comp 2_bax_fixed'].mean(),\n",
    "            'Number of BAX ULDs in Comp 2_bax_fixed': comparison_full['Number of BAX ULDs in Comp 2_bax_fixed'].mean(),\n",
    "            'Weight ULDs in Comp 2_bax_fixed': comparison_full['Weight ULDs in Comp 2_bax_fixed'].mean(),\n",
    "            'Weight BAX ULDs in Comp 2_bax_fixed': comparison_full['Weight BAX ULDs in Comp 2_bax_fixed'].mean(),\n",
    "            'Number of ULDs in Comp 3_bax_fixed': comparison_full['Number of ULDs in Comp 3_bax_fixed'].mean(),\n",
    "            'Number of BAX ULDs in Comp 3_bax_fixed': comparison_full['Number of BAX ULDs in Comp 3_bax_fixed'].mean(),\n",
    "            'Weight ULDs in Comp 3_bax_fixed': comparison_full['Weight ULDs in Comp 3_bax_fixed'].mean(),\n",
    "            'Weight BAX ULDs in Comp 3_bax_fixed': comparison_full['Weight BAX ULDs in Comp 3_bax_fixed'].mean(),\n",
    "            'Number of ULDs in Comp 4_bax_fixed': comparison_full['Number of ULDs in Comp 4_bax_fixed'].mean(),\n",
    "            'Number of BAX ULDs in Comp 4_bax_fixed': comparison_full['Number of BAX ULDs in Comp 4_bax_fixed'].mean(),\n",
    "            'Weight ULDs in Comp 4_bax_fixed': comparison_full['Weight ULDs in Comp 4_bax_fixed'].mean(),\n",
    "            'Weight BAX ULDs in Comp 4_bax_fixed': comparison_full['Weight BAX ULDs in Comp 4_bax_fixed'].mean()\n",
    "        }\n",
    "\n",
    "\n",
    "        average_data_general_MAC = pd.DataFrame([average_data_general_MAC])\n",
    "        average_data_fuel_deviation = pd.DataFrame([average_data_fuel_deviation])\n",
    "        sum_data_fuel_deviation = pd.DataFrame([sum_data_fuel_deviation])\n",
    "        sum_data_full = pd.DataFrame([sum_data_full])\n",
    "        average_data_full = pd.DataFrame([average_data_full])\n",
    "\n",
    "        self.combined_results = pd.concat([comparison_full, sum_data_full, average_data_full], ignore_index = True)\n",
    "        self.combined_results_MAC = pd.concat([comparison_MAC, average_data_general_MAC], ignore_index=True)\n",
    "        self.combined_results_fuel_deviation = pd.concat([comparison_fuel_deviation, average_data_fuel_deviation, sum_data_fuel_deviation], ignore_index=True)\n",
    "\n",
    "        return self.combined_results_MAC, self.combined_results_fuel_deviation, self.combined_results        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Analysis():\n",
    "    def __init__(self):\n",
    "        self.piece_information_csv = 'Inputfiles/PieceInformationSpotfire.csv'  # Changed from Windows path\n",
    "        self.buildup_information_csv = 'Inputfiles/BuildUpInformationSpotfire.csv'  # Changed from Windows path\n",
    "        self.loadlocation_information_csv = 'Inputfiles/LoadLocationsSpotfire.csv'  # Changed from Windows path\n",
    "       \n",
    "    def custom_date_parser(self, date_string):\n",
    "        \"\"\"\n",
    "        Parses date strings that are in either 'd/m/YYYY' or 'd-m-YYYY' format.\n",
    "\n",
    "        Args:\n",
    "            date_string (str): The date string to parse.\n",
    "        \"\"\"\n",
    "        for fmt in ('%d/%m/%Y', '%d-%m-%Y', '%Y-%m-%d'):\n",
    "            try:\n",
    "                return datetime.strptime(date_string, fmt)\n",
    "            except ValueError:\n",
    "                continue\n",
    "        return\n",
    "        \n",
    "    def format_date(self, date):\n",
    "        \"\"\"\n",
    "        Formats a datetime object to 'dd MMM YYYY' in uppercase.\n",
    "\n",
    "        Args:\n",
    "            date (datetime): The date to format.\n",
    "        \"\"\"\n",
    "        return date.strftime('%d %b %y').upper()\n",
    "\n",
    "    def dimensions_proportions_per_commodity(self, destination, commodity_code, proportion_type):\n",
    "        \"\"\"\n",
    "        Fetch the average dimension proportion (height, width, or length) for a given commodity code.\n",
    "        \n",
    "        Args:\n",
    "            commodity_code (str): The commodity code to filter by.\n",
    "            proportion_type (str): The type of proportion to return ('HeightProportion', 'WidthProportion', 'LengthProportion').\n",
    "        \"\"\"\n",
    "        piece_information_data = pd.read_csv(self.piece_information_csv)\n",
    "        filtered_df = piece_information_data[(piece_information_data['BookingLinePieceIsInformational'] == True) & (piece_information_data['BookingDestinationStationCode'] == destination)].copy()\n",
    "        filtered_df['BookingLinePieceHeight'] = filtered_df['BookingLinePieceHeight'].str.replace(',', '.').astype(float)\n",
    "        filtered_df['BookingLinePieceWidth'] = filtered_df['BookingLinePieceWidth'].str.replace(',', '.').astype(float)\n",
    "        filtered_df['BookingLinePieceLength'] = filtered_df['BookingLinePieceLength'].str.replace(',', '.').astype(float)\n",
    "\n",
    "        # Calculate total dimensions to normalize each dimension as a proportion\n",
    "        filtered_df['TotalDimensions'] = filtered_df['BookingLinePieceHeight'] + filtered_df['BookingLinePieceWidth'] + filtered_df['BookingLinePieceLength']\n",
    "        filtered_df['HeightProportion'] = filtered_df['BookingLinePieceHeight'] / filtered_df['TotalDimensions']\n",
    "        filtered_df['WidthProportion'] = filtered_df['BookingLinePieceWidth'] / filtered_df['TotalDimensions']\n",
    "        filtered_df['LengthProportion'] = filtered_df['BookingLinePieceLength'] / filtered_df['TotalDimensions']\n",
    "\n",
    "        # Group by BookingCommodityCode and calculate the average proportion for each dimension\n",
    "        grouped_data = filtered_df.groupby('BookingCommodityCode').agg({\n",
    "            'HeightProportion': 'mean',\n",
    "            'WidthProportion': 'mean',\n",
    "            'LengthProportion': 'mean'\n",
    "        }).reset_index()\n",
    "\n",
    "        proportion = grouped_data.set_index('BookingCommodityCode').loc[commodity_code, proportion_type]\n",
    "\n",
    "        return proportion\n",
    "    \n",
    "    def threshold_volume_in_AKE(self):\n",
    "        \"\"\"  \n",
    "        Find the volume threshold for items placed in AKE ULDs\n",
    "        \"\"\"\n",
    "        buildup_information_data = pd.read_csv(self.buildup_information_csv)\n",
    "        filtered_buildup_df = buildup_information_data[buildup_information_data['ULD'].astype(str).str[0:3] == 'AKE'].copy()\n",
    "        serialnumbers_in_AKE = filtered_buildup_df['AirWaybillNumber'].unique()\n",
    "        \n",
    "        piece_information_data = pd.read_csv(self.piece_information_csv)\n",
    "        volume_per_piece_in_AKE = piece_information_data[piece_information_data['BookingAirWaybillNumber'].isin(serialnumbers_in_AKE)].copy()\n",
    "        volume_per_piece_in_AKE = volume_per_piece_in_AKE['BookingLinePieceVolume'].str.replace(',', '.').astype(float)\n",
    "        \n",
    "        Q1 = volume_per_piece_in_AKE.quantile(0.25)\n",
    "        Q3 = volume_per_piece_in_AKE.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        normal_volume_data = volume_per_piece_in_AKE[(volume_per_piece_in_AKE >= lower_bound) &\n",
    "                                                        (volume_per_piece_in_AKE <= upper_bound)]\n",
    "        \n",
    "        volume_threshold = normal_volume_data.quantile(0.75)\n",
    "\n",
    "        return volume_threshold\n",
    "    \n",
    "    def weight_distribution_actual(self):\n",
    "        \"\"\"  \n",
    "        Extract the weight distribution of BAX and ULDs in each compartment\n",
    "        \"\"\"\n",
    "        loadlocations_data = pd.read_csv(self.loadlocation_information_csv)\n",
    "\n",
    "        data = loadlocations_data[(loadlocations_data['DeadloadType'] == 'B') | (loadlocations_data['DeadloadType'] == 'C')][[\n",
    "            'FlightLegDepartureKey', 'LoadLocation', 'UldGrossWeight', 'DeadloadType', 'SerialNumber']]\n",
    "        \n",
    "        data = data.drop_duplicates(subset=['FlightLegDepartureKey', 'LoadLocation', 'DeadloadType', 'SerialNumber'])\n",
    "        data = data.drop('SerialNumber', axis=1)\n",
    "        \n",
    "        data['Flight Number'] = data['FlightLegDepartureKey'].apply(lambda x: 'KL' + str(int(x.split('|')[2])))\n",
    "        data['Flight Date'] = pd.to_datetime(data['FlightLegDepartureKey'].apply(lambda x: x.split('|')[0])).dt.strftime('%d %b %y').str.upper()\n",
    "        data = data.drop('FlightLegDepartureKey', axis=1)\n",
    "        data['Compartment'] = data['LoadLocation'].str.extract('(\\d)').astype(int)  # Extract the first digit and convert to integer\n",
    "\n",
    "        # Grouping and summing weights by category\n",
    "        grouped_data = data.groupby(['Flight Number', 'Flight Date', 'DeadloadType', 'Compartment']).agg({'UldGrossWeight': 'sum'}).reset_index()\n",
    "\n",
    "        # Creating pivot tables for BAX and ULD, filling missing values with 0 for non-existent compartments\n",
    "        pivot_bax = grouped_data[grouped_data['DeadloadType'] == 'B'].pivot_table(index=['Flight Number', 'Flight Date'],\n",
    "                         columns='Compartment', values='UldGrossWeight', aggfunc='sum', fill_value=0)\n",
    "        pivot_bax.columns = [f'Weight BAX ULDs in Comp {int(col)}_actual' for col in pivot_bax.columns]\n",
    "\n",
    "        pivot_uld = grouped_data[grouped_data['DeadloadType'] == 'C'].pivot_table(index=['Flight Number', 'Flight Date'],\n",
    "                         columns='Compartment', values='UldGrossWeight', aggfunc='sum', fill_value=0)\n",
    "        pivot_uld.columns = [f'Weight ULDs in Comp {int(col)}_actual' for col in pivot_uld.columns]\n",
    "\n",
    "        # Joining the pivoted tables back into a single DataFrame, ensuring all columns are included\n",
    "        result_data = pd.merge(pivot_bax.reset_index(), pivot_uld.reset_index(), on=['Flight Number', 'Flight Date'], how='outer').fillna(0)\n",
    "        result_data = result_data.drop(['Weight ULDs in Comp 0_actual', 'Weight ULDs in Comp 5_actual', 'Weight BAX ULDs in Comp 5_actual'], axis = 1)\n",
    "\n",
    "        result_data['Weight in Comp 1_actual'] = result_data['Weight BAX ULDs in Comp 1_actual'] + result_data['Weight ULDs in Comp 1_actual']\n",
    "        result_data['Weight in Comp 2_actual'] = result_data['Weight BAX ULDs in Comp 2_actual'] + result_data['Weight ULDs in Comp 2_actual']\n",
    "        result_data['Weight in Comp 3_actual'] = result_data['Weight BAX ULDs in Comp 3_actual'] + result_data['Weight ULDs in Comp 3_actual']\n",
    "        result_data['Weight in Comp 4_actual'] = result_data['Weight BAX ULDs in Comp 4_actual'] + result_data['Weight ULDs in Comp 4_actual']\n",
    "\n",
    "        return result_data\n",
    "    \n",
    "    def COL_and_CRT_analysis(self):\n",
    "        \"\"\"    \n",
    "        Find if COL and CRT are present in the flight\n",
    "        \"\"\"\n",
    "        piece_information_data = pd.read_csv(self.piece_information_csv)\n",
    "        loadlocations_data = pd.read_csv(self.loadlocation_information_csv)\n",
    "\n",
    "        data_pieces = piece_information_data.copy()\n",
    "        data_pieces_grouped = data_pieces.groupby(['BookingDestinationStationCode', 'BookingSegmentFlightDateLT'])[['IsCOL', 'IsCRT']].sum().reset_index()\n",
    "        list_of_destinations = ['LAX', 'SIN', 'ICN', 'IAH']\n",
    "        data_pieces_grouped = data_pieces_grouped[data_pieces_grouped['BookingDestinationStationCode'].isin(list_of_destinations)]\n",
    "\n",
    "        data_pieces_grouped['IsCOL'] = data_pieces_grouped['IsCOL'] >= 1\n",
    "        data_pieces_grouped['IsCRT'] = data_pieces_grouped['IsCRT'] >= 1\n",
    "        data_pieces_grouped['IsCOLandCRT'] = (data_pieces_grouped['IsCOL']) & (data_pieces_grouped['IsCRT'])\n",
    "\n",
    "        data_pieces_grouped['BookingSegmentFlightDateLT'] = data_pieces_grouped['BookingSegmentFlightDateLT'].apply(self.custom_date_parser)\n",
    "        data_pieces_grouped['BookingSegmentFlightDateLT'] = data_pieces_grouped['BookingSegmentFlightDateLT'].apply(self.format_date)\n",
    "        replacements = {'LAX': 'KL601', 'SIN': 'KL835', 'ICN': 'KL855', 'IAH': 'KL661'}\n",
    "        data_pieces_grouped['BookingDestinationStationCode'] = data_pieces_grouped['BookingDestinationStationCode'].replace(replacements)\n",
    "\n",
    "        data_pieces_grouped = data_pieces_grouped.rename(columns={'BookingDestinationStationCode': 'Flight Number', 'BookingSegmentFlightDateLT': 'Flight Date'})\n",
    "\n",
    "        data_loadlocations = loadlocations_data.copy()\n",
    "        data_loadlocations['Flight Date'] = data_loadlocations['FlightLegDepartureKey'].apply(lambda x: x.split('|')[0])\n",
    "        data_loadlocations['Flight Number'] = data_loadlocations['FlightLegDepartureKey'].apply(lambda x: 'KL' + x.split('|')[2][1:4])\n",
    "        destinations = ['KL601', 'KL835', 'KL855', 'KL661']\n",
    "        data_loadlocations = data_loadlocations[data_loadlocations['Flight Number'].isin(destinations)]\n",
    "        data_loadlocations_grouped = data_loadlocations.groupby(['Flight Number', 'Flight Date'])['SpecialHandlingCode'].agg(list).reset_index()\n",
    "        \n",
    "        data_loadlocations_grouped['Flight Date'] = data_loadlocations_grouped['Flight Date'].apply(self.custom_date_parser)\n",
    "        data_loadlocations_grouped['Flight Date'] = data_loadlocations_grouped['Flight Date'].apply(self.format_date)\n",
    "        data_loadlocations_grouped['IsCOL'] = data_loadlocations_grouped['SpecialHandlingCode'].apply(lambda x: 'COL' in x)\n",
    "        data_loadlocations_grouped['IsCRT'] = data_loadlocations_grouped['SpecialHandlingCode'].apply(lambda x: 'CRT' in x)\n",
    "        data_loadlocations_grouped['IsCOLandCRT'] = data_loadlocations_grouped['IsCOL'] & data_loadlocations_grouped['IsCRT']\n",
    "        data_loadlocations_grouped = data_loadlocations_grouped.drop(['SpecialHandlingCode'], axis=1)\n",
    "\n",
    "        df_COL_CRT = pd.merge(data_pieces_grouped, data_loadlocations_grouped, on=['Flight Number', 'Flight Date'], how='outer')\n",
    "        df_COL_CRT['IsCOL'] = df_COL_CRT['IsCOL_x'].fillna(False) | df_COL_CRT['IsCOL_y'].fillna(False)\n",
    "        df_COL_CRT['IsCRT'] = df_COL_CRT['IsCRT_x'].fillna(False) | df_COL_CRT['IsCRT_y'].fillna(False)\n",
    "        df_COL_CRT['IsCOLandCRT'] = df_COL_CRT['IsCOLandCRT_x'].fillna(False) | df_COL_CRT['IsCOLandCRT_y'].fillna(False)\n",
    "        df_COL_CRT = df_COL_CRT.drop(columns=['IsCOL_x', 'IsCOL_y', 'IsCRT_x', 'IsCRT_y', 'IsCOLandCRT_x', 'IsCOLandCRT_y'])\n",
    "\n",
    "        return df_COL_CRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
